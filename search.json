[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "What Can You Do With AI?"
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "About",
    "section": "",
    "text": "What Can You Do With AI?"
  },
  {
    "objectID": "about.html#raymond-liu-ao",
    "href": "about.html#raymond-liu-ao",
    "title": "About",
    "section": "Raymond Liu Ao",
    "text": "Raymond Liu Ao\nOriginally from Lima, Peru, I am a Philosophy, Politics, and Economics (PPE) student at the University of Pennsylvania. Interested in exploring the uses and implications of AI in daily life, this blog discusses how LLM can help us (or not) in commonly encountered scenarios.\n–"
  },
  {
    "objectID": "posts/027_/027.html",
    "href": "posts/027_/027.html",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "",
    "text": "For my Leading Across Differences class, we had 20+ academic readings. I tried Google’s NotebookLM, which generates audio podcast summaries of uploaded documents.\nThe idea: Listen to summaries instead of reading everything.\nIt didn’t work."
  },
  {
    "objectID": "posts/027_/027.html#the-promise-ai-generated-study-podcasts",
    "href": "posts/027_/027.html#the-promise-ai-generated-study-podcasts",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "",
    "text": "For my Leading Across Differences class, we had 20+ academic readings. I tried Google’s NotebookLM, which generates audio podcast summaries of uploaded documents.\nThe idea: Listen to summaries instead of reading everything.\nIt didn’t work."
  },
  {
    "objectID": "posts/027_/027.html#what-i-tried",
    "href": "posts/027_/027.html#what-i-tried",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "What I Tried",
    "text": "What I Tried\nI uploaded all 15 readings from one week - a mix of academic articles, case studies, and book chapters on leadership, identity, and power dynamics.\nNotebookLM generated a 10-minute “podcast” summarizing the key themes across all readings.\nTwo AI voices had a conversational discussion about the material. It sounded professional and engaging."
  },
  {
    "objectID": "posts/027_/027.html#what-went-wrong",
    "href": "posts/027_/027.html#what-went-wrong",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "What Went Wrong",
    "text": "What Went Wrong\n\nIt Missed Crucial Details\nThe class required three essays analyzing specific arguments from specific authors. NotebookLM’s summary mentioned themes but didn’t preserve: - Who said what - Which study supported which claim - Distinctions between competing frameworks\nI knew the general concepts but couldn’t cite anyone.\n\n\n10 Minutes Can’t Cover 15 Readings\nEach reading was 20-40 pages. That’s 300+ pages of dense academic writing.\nNotebookLM condensed it into 10 minutes, which means it selected what it thought was important and dropped the rest.\nFor a multiple-choice test, maybe that works. For essays where I need to synthesize arguments, it didn’t.\n\n\nThe Format Was Too Passive\nListening to a podcast is easy. Too easy. I retained almost nothing.\nReading forces active engagement. I highlight, annotate, pause to think. Audio just washes over you."
  },
  {
    "objectID": "posts/027_/027.html#when-notebooklm-might-actually-help",
    "href": "posts/027_/027.html#when-notebooklm-might-actually-help",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "When NotebookLM Might Actually Help",
    "text": "When NotebookLM Might Actually Help\nGood for: - Refreshing material you’ve already read - Getting a high-level overview before diving deep - Supplementing notes (not replacing reading) - Subjects with clear factual content (not interpretive analysis)\nNot good for: - Classes requiring detailed citations - Essay-based assessments - Dense theoretical reading - First-pass learning of complex material"
  },
  {
    "objectID": "posts/027_/027.html#what-i-use-instead",
    "href": "posts/027_/027.html#what-i-use-instead",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "What I Use Instead",
    "text": "What I Use Instead\nFor readings: I actually read them. I highlight key arguments and take notes in margins.\nFor review: I make my own summaries after reading - writing forces comprehension.\nFor exam prep: I create concept maps connecting ideas across readings. NotebookLM can’t do this because it doesn’t understand my interpretation.\nAudio tools: I use text-to-speech to listen while I follow along in the document. That’s different from listening to AI-generated summaries."
  },
  {
    "objectID": "posts/027_/027.html#the-efficiency-trap",
    "href": "posts/027_/027.html#the-efficiency-trap",
    "title": "NotebookLM for Exam Prep: When AI Audio Summaries Miss the Point",
    "section": "The Efficiency Trap",
    "text": "The Efficiency Trap\nNotebookLM saved time. But it didn’t save learning.\nI spent 10 minutes listening to a summary and understood nothing deeply. My classmates who read spent 3 hours and could actually write the essays.\nThe extra time mattered.\nMaybe NotebookLM works better for straightforward material - timelines, definitions, factual summaries. But for interpretive work where you need to form your own arguments? AI summaries don’t replace the cognitive work of reading.\nEfficiency isn’t always effective."
  },
  {
    "objectID": "posts/014_/014.html",
    "href": "posts/014_/014.html",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "",
    "text": "I’m reading Reid Hoffman and Greg Beato’s Superagency: What Could Possibly Go Right with Our AI Future—a book that argues for optimism about generative AI and its potential to enhance human agency. As someone who identifies as a gloomer about AI, I’m approaching this with skepticism but genuine curiosity.\nThis is part 1 of 5 reviews covering the entire book. Pages 1-47: The introduction and framing.\n\nSuperagency by Reid Hoffman and Greg Beato"
  },
  {
    "objectID": "posts/014_/014.html#reading-superagency-a-gloomers-perspective",
    "href": "posts/014_/014.html#reading-superagency-a-gloomers-perspective",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "",
    "text": "I’m reading Reid Hoffman and Greg Beato’s Superagency: What Could Possibly Go Right with Our AI Future—a book that argues for optimism about generative AI and its potential to enhance human agency. As someone who identifies as a gloomer about AI, I’m approaching this with skepticism but genuine curiosity.\nThis is part 1 of 5 reviews covering the entire book. Pages 1-47: The introduction and framing.\n\nSuperagency by Reid Hoffman and Greg Beato"
  },
  {
    "objectID": "posts/014_/014.html#the-historical-framing-art-luddites-and-printing-presses",
    "href": "posts/014_/014.html#the-historical-framing-art-luddites-and-printing-presses",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "The Historical Framing: Art, Luddites, and Printing Presses",
    "text": "The Historical Framing: Art, Luddites, and Printing Presses\nThe introduction opens with an interesting historical analogy. Hoffman and Beato walk through past technological disruptions:\nSocrates and Art: Socrates opposed art because it failed to capture the conversational, evolutionary, iterative process of discussion-based learning. Written text was static; dialogue was dynamic.\nThe Luddites: Workers who resisted industrial machinery that threatened their livelihoods and ways of life.\nThe Printing Press: A technology that faced backlash from those who feared the democratization of knowledge.\nThe pattern is clear: history is full of examples of technological backlash. The book frames AI as the latest in this line—another “infrastructural change event” that will transform human capacity and agency.\nI’ll admit, the framing is effective. The core question the book poses is compelling: “Can we continue to maintain control of our lives, and successfully plot our own destinies?” in the age of AI."
  },
  {
    "objectID": "posts/014_/014.html#history-is-written-by-the-winners",
    "href": "posts/014_/014.html#history-is-written-by-the-winners",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "History Is Written by the Winners",
    "text": "History Is Written by the Winners\nHere’s where my skepticism kicks in.\nYes, all these technological disruptions—art, steam power, the printing press—were consequential and enabled human agency in important ways:\nArt captured feelings, periods, and provided first-hand historical resources.\nSteam power and the Industrial Revolution brought unimaginable productivity and capital accumulation, leading to the consolidation of modern cities.\nThe printing press enabled communication and knowledge dissemination like never before.\nWe’ve all benefited from these major strides, one way or another. But the more closely we examine the nuances of these pivotal moments, the more we realize there’s much more to the story.\nThe problem is that we often focus on the positives—maybe as a sign of human delusion, or a craving to minimize problems. Important details get left behind. History is written by the winners, after all.\n\nThe Industrial Revolution: productivity gains alongside worker displacement"
  },
  {
    "objectID": "posts/014_/014.html#what-the-winners-history-leaves-out",
    "href": "posts/014_/014.html#what-the-winners-history-leaves-out",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "What the Winners’ History Leaves Out",
    "text": "What the Winners’ History Leaves Out\n\nThe Industrial Revolution’s Dark Side\nThe steam engine and industrialization brought unprecedented productivity. But they also brought: - Brutal working conditions in factories - Child labor - Destruction of artisan crafts and traditional ways of life - Environmental degradation that we’re still dealing with - Massive wealth inequality and the creation of exploitative labor systems\nAccording to historical analysis of the Industrial Revolution, while productivity soared, real wages for workers stagnated or declined for decades. The “winners” who wrote that history were the factory owners and industrialists, not the displaced weavers or child laborers.\n\n\nThe Printing Press and Information Chaos\nThe printing press democratized knowledge—but it also: - Enabled mass propaganda - Facilitated religious wars and sectarian violence - Created information overload that people weren’t equipped to handle - Disrupted existing knowledge gatekeepers (sometimes for good, sometimes not)\nThe Reformation, enabled by printing technology, led to centuries of religious conflict. That’s not in the optimistic framing.\n\n\nThe Luddites Were Right About Some Things\nWe use “Luddite” as an insult for technophobes. But the original Luddites weren’t irrationally afraid of technology—they were skilled workers watching their livelihoods and communities be destroyed by machines that enriched factory owners.\nTheir concerns about who benefits from technological change were valid. The technology did increase productivity, but the gains went to capital owners, not workers. The Luddites lost that fight, so history remembers them as backwards resistors rather than people with legitimate concerns about economic justice."
  },
  {
    "objectID": "posts/014_/014.html#the-agency-question-for-whom",
    "href": "posts/014_/014.html#the-agency-question-for-whom",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "The Agency Question: For Whom?",
    "text": "The Agency Question: For Whom?\nHoffman and Beato frame AI as an “agency enabler”—technology that will enhance our capacity to “do what we ought to do” and “plot our own destinies.”\nBut here’s the critical question the introduction doesn’t adequately address: Whose agency gets enabled?\n\nTechnology Doesn’t Distribute Benefits Evenly\nPast technological revolutions increased aggregate human capacity and agency. But the distribution was wildly unequal: - Factory owners gained agency; workers often lost autonomy - Landowners who adopted new agricultural tech thrived; tenant farmers were displaced - Early adopters of communication technology gained power; those without access fell further behind\nWhen Hoffman talks about AI enabling “our” agency, who is “we”? Tech founders and investors? Knowledge workers with access to cutting-edge tools? Or also the truck drivers, customer service workers, and radiologists whose jobs might be automated?\n\n\nHave We Forgotten Our Ways of Life?\nEach technological revolution didn’t just change what people could do—it changed how people lived. Industrialization pulled people from rural communities into urban factories. The printing press disrupted oral traditions and face-to-face knowledge transmission.\nSome of these changes were positive. Some represented the loss of valuable ways of life that we can never recover.\nThe introduction’s optimistic framing acknowledges these past disruptions but seems confident that AI will be different—that we can get the benefits without the costs. History suggests otherwise."
  },
  {
    "objectID": "posts/014_/014.html#what-im-looking-for-in-the-rest-of-the-book",
    "href": "posts/014_/014.html#what-im-looking-for-in-the-rest-of-the-book",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "What I’m Looking For in the Rest of the Book",
    "text": "What I’m Looking For in the Rest of the Book\nThe introduction sets up an optimistic case for AI as an agency enabler, using historical technological disruptions as precedent. The framing is well-done and intellectually honest about past backlash to new technologies.\nBut it seems to brush past the real costs of those past revolutions. The “winners” narrative focuses on aggregate gains while downplaying distributional concerns and the destruction of existing ways of life.\nAs I continue reading, I’m looking for:\nDistributional analysis: Who specifically gains agency from AI, and who loses it?\nCost acknowledgment: What ways of life, skills, or social structures might we lose, and are those losses acceptable?\nPower dynamics: How do we ensure AI benefits are distributed more equitably than past technological revolutions?\nConcrete mechanisms: Not just “AI will enable agency,” but how and for whom specifically?\nThe book asks: “What could possibly go right with our AI future?” But the introduction’s own historical examples suggest we should also ask: “What will go wrong, and for whom?”\nHistory is written by the winners. I’m reading this book to see if Hoffman and Beato can imagine an AI future where there are fewer losers than in past technological revolutions—or if they’re just writing the winners’ narrative before the story has finished."
  },
  {
    "objectID": "posts/014_/014.html#up-next",
    "href": "posts/014_/014.html#up-next",
    "title": "Superagency Review #1: History Is Written by the Winners",
    "section": "Up Next",
    "text": "Up Next\nReview #2 will cover pages 48-94, where I expect the book to start making its positive case for AI more explicitly. I’ll be watching to see if it addresses the distributional concerns raised by its own historical framing.\nStay tuned."
  },
  {
    "objectID": "posts/002_/002.html",
    "href": "posts/002_/002.html",
    "title": "AI Do’s and Don’ts: Safe and Effective Usage",
    "section": "",
    "text": "AI tools are powerful but require careful usage. These guidelines help you maximize benefits while avoiding common pitfalls.\n Key principles for responsible AI usage"
  },
  {
    "objectID": "posts/002_/002.html#essential-ai-guidelines",
    "href": "posts/002_/002.html#essential-ai-guidelines",
    "title": "AI Do’s and Don’ts: Safe and Effective Usage",
    "section": "",
    "text": "AI tools are powerful but require careful usage. These guidelines help you maximize benefits while avoiding common pitfalls.\n Key principles for responsible AI usage"
  },
  {
    "objectID": "posts/002_/002.html#what-to-do",
    "href": "posts/002_/002.html#what-to-do",
    "title": "AI Do’s and Don’ts: Safe and Effective Usage",
    "section": "What TO Do",
    "text": "What TO Do\n\n✅ Verify Important Information\nAlways fact-check AI outputs for: - Medical or health advice - Financial decisions - Legal matters - Technical specifications - Current events or recent data\nCross-reference with authoritative sources before acting on AI recommendations.\n\n\n✅ Be Specific in Your Prompts\nInstead of: “Help me with my presentation” Use: “Create an outline for a 10-minute sales presentation to executives about Q3 revenue growth”\nSpecific prompts produce more useful results.\n\n\n✅ Use AI for Brainstorming and Drafts\nAI excels at: - Generating initial ideas - Creating first drafts - Organizing thoughts - Providing alternative perspectives\nUse AI output as a starting point, not a final product.\n Proper workflow: AI assists, human validates and refines\n\n\n✅ Maintain Human Judgment\nKeep human oversight for: - Final decision-making - Quality assessment - Ethical considerations - Context that AI might miss\n\n\n✅ Ask Follow-Up Questions\nImprove results by asking: - “Can you explain this differently?” - “What are potential problems with this approach?” - “Give me three alternatives” - “Make this more specific”"
  },
  {
    "objectID": "posts/002_/002.html#what-not-to-do",
    "href": "posts/002_/002.html#what-not-to-do",
    "title": "AI Do’s and Don’ts: Safe and Effective Usage",
    "section": "What NOT to Do",
    "text": "What NOT to Do\n\n❌ Don’t Share Sensitive Information\nNever input: - Passwords or login credentials - Social Security numbers - Credit card details - Proprietary business information - Personal addresses or phone numbers - Private family details\nAssume all AI conversations could be stored or accessed by others.\n\n\n❌ Don’t Rely on AI for Critical Decisions\nAvoid using AI alone for: - Medical diagnoses or treatment - Legal advice or document preparation - Financial investment decisions - Safety-critical calculations - Emergency situations\nConsult qualified professionals for these matters.\n Areas where AI should not be the primary decision maker\n\n\n❌ Don’t Assume AI is Always Accurate\nAI can produce: - Outdated information - Factual errors - Biased responses - Plausible-sounding but incorrect details\nEspecially problematic for recent events or specialized technical information.\n\n\n❌ Don’t Use AI for Harmful Purposes\nAvoid requesting: - Misleading or false content - Harassment or threatening messages - Plagiarism or academic dishonesty - Illegal activity guidance - Discriminatory content\n\n\n❌ Don’t Ignore Context Limitations\nAI doesn’t understand: - Your full personal situation - Unspoken cultural context - Real-time environmental factors - Emotional nuances\nProvide necessary context explicitly in your prompts."
  },
  {
    "objectID": "posts/002_/002.html#implementation-strategy",
    "href": "posts/002_/002.html#implementation-strategy",
    "title": "AI Do’s and Don’ts: Safe and Effective Usage",
    "section": "Implementation Strategy",
    "text": "Implementation Strategy\n\nStart Small\nBegin with low-stakes tasks like email drafting or meal planning before using AI for important projects.\n\n\nBuild Verification Habits\nDevelop a routine of checking AI outputs against reliable sources.\n\n\nKeep Learning\nAI capabilities and limitations evolve. Stay informed about updates and new research.\n\n\nDocument What Works\nSave effective prompts and note which applications produce reliable results for your needs.\n Use these tips and tricks!\nFollowing these guidelines ensures you gain AI’s benefits while avoiding common mistakes that can lead to poor decisions or security issues."
  },
  {
    "objectID": "posts/012_/012.html",
    "href": "posts/012_/012.html",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "",
    "text": "I have an upcoming interview for a Santander CIB Investment Banking Analyst Program, specifically for their DCM (Debt Capital Markets) division. This is different from the consulting interviews I’ve been preparing for—finance interviews require understanding specific firms, technical knowledge about debt markets, and different types of behavioral questions.\nSince I’ve been using AI for consulting prep, I decided to test whether Claude and Perplexity could help me pivot to finance interview preparation.\n\nClaude conducting research on Santander’s DCM business and interview approach"
  },
  {
    "objectID": "posts/012_/012.html#pivoting-interview-prep-consulting-to-finance",
    "href": "posts/012_/012.html#pivoting-interview-prep-consulting-to-finance",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "",
    "text": "I have an upcoming interview for a Santander CIB Investment Banking Analyst Program, specifically for their DCM (Debt Capital Markets) division. This is different from the consulting interviews I’ve been preparing for—finance interviews require understanding specific firms, technical knowledge about debt markets, and different types of behavioral questions.\nSince I’ve been using AI for consulting prep, I decided to test whether Claude and Perplexity could help me pivot to finance interview preparation.\n\nClaude conducting research on Santander’s DCM business and interview approach"
  },
  {
    "objectID": "posts/012_/012.html#the-prompts-i-used",
    "href": "posts/012_/012.html#the-prompts-i-used",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "The Prompts I Used",
    "text": "The Prompts I Used\n\nInitial Research Request to Claude\nMy first prompt:\n\n“First and foremost, I am more so interested in understanding DCM, and potential BEHAVIORAL questions that might arise.\nWhy DCM? Why DCM LatAm? Why Santander DCM?\nUse the web to thoroughly search and understand more about the firm, how the firm talks about itself, and what common behavioral questions do they engage with for their IB process.”\n\nClaude responded:\n\n“I’ll conduct thorough research on Santander CIB, their DCM business, and their interview process. Let me search for information about how they present themselves, their Latin America focus, and common interview questions.”\n\nIt then ran searches for: - “Santander Corporate Investment Banking DCM” (10 results) - Started searching the web for additional information\n\n\nPerplexity Deep Dive\nI also used Perplexity’s research feature with multiple targeted searches:\n\n“Santander CIB debt capital markets”\n“Santander investment banking culture values”\n“Santander CIB Latin America strategy”\n\nPerplexity found 20 sources including: - Debt Capital Markets | Santander Corporate & Investment Banking - From personalization to social values: what is shaking up investment [banking] - Macro & Strategy Research - The past, present and future of debt capital markets - [PDF] Culture Report 2019 - Banco Santander - Santander US Capital Markets\n\nPerplexity gathering and reviewing sources on Santander DCM"
  },
  {
    "objectID": "posts/012_/012.html#what-actually-helped",
    "href": "posts/012_/012.html#what-actually-helped",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "What Actually Helped",
    "text": "What Actually Helped\n\nFirm-Specific Research\nBoth tools pulled relevant information about Santander’s positioning: - Their focus on Latin America markets and how that differentiates them - Recent deals and market activity in DCM - Corporate values and culture statements - Strategic priorities in debt capital markets\nThis gave me talking points for “Why Santander” that were specific rather than generic.\n\n\nUnderstanding DCM vs. Other IB Divisions\nThe AI helped clarify: - What DCM analysts actually do day-to-day - How DCM differs from M&A or equity capital markets - Why someone might choose DCM over other finance paths - Technical concepts I needed to understand (bond pricing, credit ratings, syndication)\n\n\nBehavioral Question Preparation\nThe tools suggested finance-specific behavioral questions that differ from consulting: - “Walk me through a DCF” (technical behavioral) - “Why debt capital markets vs. other finance roles?” - “How do you handle working with difficult clients on tight deadlines?” - “Tell me about a time you analyzed complex financial information”\nThese are different from consulting’s case-focused approach.\n\n\nIdentifying Knowledge Gaps\nThe research helped me realize what I didn’t know: - Specific debt instruments Santander specializes in - Recent Latin American market trends affecting DCM - Technical terminology I needed to learn - The difference between investment-grade and high-yield debt origination"
  },
  {
    "objectID": "posts/012_/012.html#significant-limitations",
    "href": "posts/012_/012.html#significant-limitations",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "Significant Limitations",
    "text": "Significant Limitations\n\nSurface-Level Firm Knowledge\nThe biggest problem: AI gives you the information that’s publicly available on corporate websites and general industry sources. It can’t tell you: - What Santander’s DCM team culture is actually like - Specific deals they’re working on that aren’t public - Internal priorities that aren’t in press releases - What actually impresses their interviewers vs. what sounds good on paper\n\n\nGeneric Behavioral Answers\nWhen I asked Claude to help refine my answers to “Why DCM?”, it produced polished but generic responses: - “I’m drawn to the analytical rigor of debt markets…” - “The complexity of structuring transactions appeals to me…” - “I want to work at the intersection of capital markets and corporate strategy…”\nThese sound like everyone else’s AI-polished answers. The interviewers at Santander have probably heard variations of these from dozens of candidates using similar tools.\n\n\nCan’t Teach Technical Skills\nAI can explain what a DCF is, but it can’t help you build the muscle memory of actually modeling one under time pressure. It can’t simulate the experience of being asked to walk through a valuation on a whiteboard while someone watches.\nFinance interview prep resources emphasize that technical skills require hands-on practice with actual models, not just conceptual understanding.\n\n\nOutdated Information\nSome of the sources Perplexity pulled were from 2019 (the Culture Report). The finance industry moves quickly—strategies, priorities, and team structures change. Relying on AI-found sources without verifying recency is risky.\n\n\nMisses Networking Insights\nThe most valuable interview prep for finance comes from talking to people who work at the firm or in similar roles. AI can’t replace: - Coffee chats with current Santander analysts - Alumni connections who know the interview process - Understanding what specific interviewers care about - Getting feedback on your story from people in the industry"
  },
  {
    "objectID": "posts/012_/012.html#consulting-prep-vs.-finance-prep-with-ai",
    "href": "posts/012_/012.html#consulting-prep-vs.-finance-prep-with-ai",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "Consulting Prep vs. Finance Prep with AI",
    "text": "Consulting Prep vs. Finance Prep with AI\n\nWhat Transfers\nSome aspects of using AI for consulting prep apply to finance: - Organizing practice materials and tracking progress - Getting quick explanations of concepts - Structuring answers using frameworks - Identifying areas where you need more preparation\n\n\nWhat’s Different\nFinance interviews require different AI usage:\nTechnical Knowledge: Consulting is more about frameworks and problem-solving approach. Finance requires specific technical knowledge (financial modeling, valuation methods, market mechanics) that you need to practice hands-on.\nFirm Research: Consulting firms are more about “fit” and problem-solving ability. Finance firms want to know you understand their specific business lines, recent deals, and market positioning.\nAnswer Style: Consulting wants structured, MECE thinking demonstrated verbally. Finance wants technical competence demonstrated through modeling and concise, confident answers about markets.\nPreparation Balance: For consulting, AI can handle maybe 40% of prep (frameworks, structure, case types). For finance, it’s more like 20%—you need more hands-on technical practice and human networking."
  },
  {
    "objectID": "posts/012_/012.html#my-actual-approach",
    "href": "posts/012_/012.html#my-actual-approach",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "My Actual Approach",
    "text": "My Actual Approach\n\nUsing AI for Initial Research Phase\nI’m using Claude and Perplexity to: - Get baseline understanding of Santander’s DCM business - Compile a list of recent deals and market trends - Understand basic DCM technical concepts - Draft initial answers to behavioral questions\nBut I treat this as the starting point, not the final product.\n\n\nFollowing Up with Human Sources\nAfter AI research, I’m: - Reaching out to Santander employees on LinkedIn - Talking to friends in investment banking about DCM - Getting my behavioral answers reviewed by people in finance - Asking specific questions about Santander’s Latin America focus\n\n\nTechnical Skill Building\nFor the technical components, AI isn’t much help. I’m: - Working through actual DCF models - Practicing explaining valuation methods out loud - Reviewing recent debt deals and their structures - Doing mock technical questions with finance friends\n\n\nVerifying Everything\nAny specific fact or claim from AI research, I verify: - Check Santander’s official investor relations materials - Look up recent news about their DCM business - Confirm market trends with multiple sources - Cross-reference technical concepts with textbooks\nThe AI can point me toward information, but I don’t trust it without verification."
  },
  {
    "objectID": "posts/012_/012.html#final-assessment",
    "href": "posts/012_/012.html#final-assessment",
    "title": "Switching from Consulting to Finance Prep with AI",
    "section": "Final Assessment",
    "text": "Final Assessment\nUsing AI to pivot from consulting to finance interview prep is helpful but limited. It’s good for: - Quick baseline research on the firm and role - Understanding how finance interviews differ from consulting - Getting initial structure for behavioral answers - Identifying what you don’t know\nBut it’s insufficient for: - Developing real technical skills - Understanding firm-specific culture and priorities - Creating distinctive, memorable answers - Getting the insider knowledge that networking provides\nFinance interviews, even more than consulting, require human connections and hands-on technical practice. AI can accelerate the research phase, but it can’t replace the core preparation activities that actually matter.\nThe risk is thinking that comprehensive AI research is enough. It’s not. The candidates who get offers at places like Santander DCM are the ones who combine efficient research with deep technical preparation and strong industry networks—things AI can’t provide."
  },
  {
    "objectID": "posts/018_/018.html",
    "href": "posts/018_/018.html",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "",
    "text": "This is part 2 of my review of Reid Hoffman and Greg Beato’s Superagency. Pages 48-94 cover Chapter 3, titled “What Could Possibly Go Right”—a deliberate play on words. Instead of the usual “what could go wrong,” Hoffman and Beato flip the framing to emphasize opportunity over risk.\nThis chapter introduces two competing worldviews: solutionism (the tech optimist’s belief that complex problems have technological fixes) and problemism (which Hoffman frames as the gloomer’s default mode of focusing on risks and downsides).\nLet me break down why this framing is more complicated than the book presents it.\n\nSuperagency by Reid Hoffman and Greg Beato"
  },
  {
    "objectID": "posts/018_/018.html#chapter-3-what-could-possibly-go-right",
    "href": "posts/018_/018.html#chapter-3-what-could-possibly-go-right",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "",
    "text": "This is part 2 of my review of Reid Hoffman and Greg Beato’s Superagency. Pages 48-94 cover Chapter 3, titled “What Could Possibly Go Right”—a deliberate play on words. Instead of the usual “what could go wrong,” Hoffman and Beato flip the framing to emphasize opportunity over risk.\nThis chapter introduces two competing worldviews: solutionism (the tech optimist’s belief that complex problems have technological fixes) and problemism (which Hoffman frames as the gloomer’s default mode of focusing on risks and downsides).\nLet me break down why this framing is more complicated than the book presents it.\n\nSuperagency by Reid Hoffman and Greg Beato"
  },
  {
    "objectID": "posts/018_/018.html#solutionism-technology-as-the-answer",
    "href": "posts/018_/018.html#solutionism-technology-as-the-answer",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "Solutionism: Technology as the Answer",
    "text": "Solutionism: Technology as the Answer\nHoffman defines solutionism as the belief that the world’s most vexing challenges have technological fixes. AI, in this view, is one of the most proven levers for creating change at scale.\n\nTo What Extent Is This True?\nThe book argues that technology has consistently solved major human problems: vaccines eradicated diseases, the internet democratized information, smartphones connected billions of people.\nThis is partially true. Technology has solved specific, well-defined problems. But “the world’s most vexing challenges” are rarely technical problems—they’re social, political, and economic problems that happen to have technical components.\nConsider climate change. We have the technology to transition to renewable energy. The “vexing challenge” isn’t the technology—it’s coordinating global political will, managing economic transitions, and overcoming entrenched interests. No AI breakthrough solves those problems.\n\n\nThe Question of Scale\nHoffman emphasizes that technology creates change “at scale.” This is true—technology can reach millions or billions of people quickly.\nBut here’s the critical question the book doesn’t adequately address: Are the positives of technology distributed evenly at scale?\nThe internet connected billions of people, but: - Who profited most? Tech companies and early adopters in wealthy countries - Who bears the costs? Workers displaced by automation, communities disrupted by platform economies, users whose data is monetized - Who gets left behind? People without access, those who can’t afford devices, communities where infrastructure wasn’t built\nSolutionism tends to measure success by aggregate impact while ignoring distributional questions. “We connected 3 billion people” sounds impressive, but if those 3 billion are predominantly in wealthy countries while the other 4 billion remain disconnected, that’s not universal progress.\n\n\nIs Technology Really the Most Proven Lever?\nThe book asserts that technology is among “the most proven levers for creating change.” But proven in what sense?\nSocial movements, policy changes, and institutional reforms have also created massive change at scale: - Civil rights legislation transformed society - Public health systems eradicated diseases (often more than vaccines alone) - Labor organizing improved working conditions - Democratic reforms expanded political participation\nThese weren’t primarily technological solutions. They were social and political solutions that sometimes used technology as a tool.\nThe solutionist framing centers technology as the primary driver of progress, which minimizes the role of human organization, policy, and collective action."
  },
  {
    "objectID": "posts/018_/018.html#problemism-the-gloomers-worldview",
    "href": "posts/018_/018.html#problemism-the-gloomers-worldview",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "Problemism: The Gloomer’s Worldview",
    "text": "Problemism: The Gloomer’s Worldview\nHoffman introduces problemism as the default mode of skeptics (gloomers like me). Problemists focus on what could go wrong, potential harms, and unintended consequences.\nThe chapter frames problemism as: - An obstacle to progress - Overly cautious and risk-averse - Focused on negatives at the expense of recognizing benefits\n\nIs This Scapegoating?\nThere’s something convenient about positioning skeptics as the problem. If gloomers are just pessimists who can’t see opportunities, then their concerns can be dismissed as psychological rather than substantive.\nBut “problemism” isn’t just pessimism—it’s pattern recognition based on history. Every major technological revolution has produced: - Massive distributional inequalities - Unintended harmful consequences - Power concentration among early adopters - Disruption of existing social structures\nPointing out these patterns isn’t holding progress back. It’s asking: “Given what we know about past technological disruptions, how can we avoid repeating the same mistakes?”\n\n\nHas Big Tech Only Created Progress?\nThe book frames problemists as entities “holding progress back.” But this assumes that what Big Tech calls “progress” is universally beneficial.\nConsider social media—a technology that Big Tech champions as connecting humanity: - Positive: Enabled global communication, grassroots organizing, democratized content creation - Negative: Amplified misinformation, enabled surveillance capitalism, contributed to mental health crises, facilitated political manipulation\nDid social media create progress? For some people, yes. For others, it created new problems. Calling skeptics “problemists” for pointing out the downsides doesn’t make those downsides disappear—it just silences legitimate critique.\n\n\nUnrestrained Innovation vs. Thoughtful Innovation\nThe book frames problemism as harmful to society because it slows down innovation. But here’s the question: Isn’t stepping back and rethinking innovation, rather than pursuing unrestrained innovation, ultimately good?\nWe’ve learned from history that “move fast and break things” causes real harm: - Facebook’s rapid expansion broke democratic discourse - Uber’s disruption broke labor protections - Cryptocurrency’s innovation broke financial stability for many who invested\n“Problemism”—if we’re calling it that—is the practice of asking “should we?” before “can we?” That’s not holding progress back. That’s responsible innovation.\nAccording to research on responsible AI development, incorporating critical perspectives early in development leads to better outcomes than addressing harms reactively after deployment. “Problemism” is just another term for proactive risk assessment."
  },
  {
    "objectID": "posts/018_/018.html#the-kokobot-example-when-problemism-was-right",
    "href": "posts/018_/018.html#the-kokobot-example-when-problemism-was-right",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "The Kokobot Example: When Problemism Was Right",
    "text": "The Kokobot Example: When Problemism Was Right\nHoffman discusses Kokobot, an AI mental health chatbot that faced significant backlash. The book presents this as an example of how problemism stifles innovation in mental health.\nBut let’s look at what actually happened with Kokobot and similar AI mental health tools.\n\nThe Challenges\nCritics raised concerns about: - Safety: Could an AI chatbot adequately handle users in crisis? - Privacy: Was user mental health data being properly protected? - Effectiveness: Did these tools actually help, or just provide the appearance of help? - Replacement of human care: Would employers use cheap chatbots instead of providing actual mental health benefits?\nThese weren’t hypothetical concerns. Studies showed that: - Some mental health chatbots gave harmful advice during crisis situations - User data from mental health apps was sold to advertisers - Many users reported the chatbots felt impersonal and unhelpful - Companies did use chatbots as cheaper alternatives to human therapists\n\n\nThe Opportunities\nHoffman argues that despite these concerns, AI mental health tools offer opportunities: - Accessible mental health support for underserved populations - 24/7 availability for people in crisis - Reduced stigma through anonymous digital interfaces - Scalable support that human therapists alone can’t provide\nThese are real benefits. But here’s where solutionism and problemism diverge:\nSolutionist view: The technology has benefits, so we should deploy it widely and fix problems as they arise.\nProblemist view: The technology has serious risks, so we should address those risks before wide deployment.\n\n\nWho Was Right?\nIn the case of Kokobot and similar tools, the “problemists” were vindicated. Multiple mental health chatbots: - Failed to detect suicidal ideation - Gave inappropriate advice - Violated user privacy - Created false sense of receiving adequate care\nThe backlash wasn’t people being pessimistic—it was people recognizing that mental health is high-stakes, and deploying untested AI tools in that domain was reckless.\nHoffman frames this as problemism holding back progress. I’d frame it as problemism preventing harm."
  },
  {
    "objectID": "posts/018_/018.html#the-false-dichotomy",
    "href": "posts/018_/018.html#the-false-dichotomy",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "The False Dichotomy",
    "text": "The False Dichotomy\nThe biggest issue with this chapter is how it sets up solutionism vs. problemism as opposing worldviews, with solutionism positioned as forward-thinking and problemism as regressive.\nThis is a false dichotomy.\n\nYou Can Believe Both\nIt’s possible to believe: - Technology can solve important problems AND - Technology creates serious risks that need careful management\nIt’s possible to be: - Excited about AI’s potential AND - Concerned about its misuse\nThe productive position isn’t pure solutionism or pure problemism—it’s conditional optimism: being optimistic about technology’s potential while insisting on safeguards, accountability, and equitable distribution of benefits.\n\n\nThe Rhetorical Strategy\nBy framing critics as “problemists,” Hoffman creates a rhetorical strategy where: - Skepticism = pessimism = obstruction - Optimism = innovation = progress\nThis shuts down legitimate critique by making it seem like an attitude problem rather than a substantive concern.\nBut asking hard questions isn’t pessimism. It’s due diligence.\n\n\nWhat This Chapter Misses\nThe chapter doesn’t adequately address: - Power dynamics: Who controls AI development and who benefits? - Historical patterns: Why should we expect AI to be different from past technologies in terms of distributional inequity? - Alternative approaches: Could we pursue AI development with built-in safeguards rather than the “deploy first, fix later” model? - The cost of being wrong: If solutionists are wrong and AI causes serious harm, what’s the cost? If problemists are wrong and we move slower than necessary, what’s the cost?\nAsymmetric risk matters. The cost of deploying harmful AI is potentially much higher than the cost of taking extra time to get it right."
  },
  {
    "objectID": "posts/018_/018.html#my-take-problemism-is-pattern-recognition",
    "href": "posts/018_/018.html#my-take-problemism-is-pattern-recognition",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "My Take: Problemism Is Pattern Recognition",
    "text": "My Take: Problemism Is Pattern Recognition\nAfter reading Chapter 3, I’m more convinced that “problemism”—if we’re calling it that—is necessary and valuable.\nIt’s not pessimism. It’s pattern recognition based on history: - The Industrial Revolution increased productivity but created brutal working conditions - Social media connected people but amplified misinformation and surveillance - The internet democratized information but enabled new forms of manipulation\nEvery time, the solutionists said “the benefits outweigh the risks, let’s move fast.” Every time, the problemists said “wait, let’s think about the downsides.” And every time, we later discovered the problemists were identifying real issues that should have been addressed earlier.\nHoffman positions problemism as holding society back. I’d argue problemism is the only thing preventing us from repeating the same mistakes at an accelerated pace.\n\nWhat Good Problemism Looks Like\nProductive skepticism isn’t just saying “AI bad.” It’s asking: - Who benefits from this technology and who bears the costs? - What safeguards prevent misuse? - How do we ensure benefits are distributed equitably? - What happens if this goes wrong, and how do we mitigate that? - What can we learn from past technological transitions?\nThese questions don’t stop innovation. They guide innovation toward better outcomes.\n\n\nThe Real Question\nThe chapter asks: “What could possibly go right?”\nBut the more important question is: “For whom will things go right, and at whose expense?”\nSolutionism assumes universal benefit. Problemism asks about distribution. And history suggests the problemists are asking the right question.\nI’ll keep reading, but so far, Superagency is making the case for optimism without adequately addressing why past optimism about technology has often proven naive."
  },
  {
    "objectID": "posts/018_/018.html#up-next",
    "href": "posts/018_/018.html#up-next",
    "title": "Superagency Review #2: Solutionism vs. Problemism",
    "section": "Up Next",
    "text": "Up Next\nReview #3 will cover pages 95-141. I’m curious to see if the book addresses distributional concerns more seriously, or if it continues positioning skepticism as the primary obstacle to AI progress.\nStay tuned."
  },
  {
    "objectID": "posts/009_/009.html",
    "href": "posts/009_/009.html",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "",
    "text": "I’ve been experimenting with what I’m calling “vibe creation” in Claude—essentially asking the LLM to generate or interpret atmospheric descriptions for different contexts. The goal was to see how well these models understand and reproduce subjective, mood-based content rather than factual information.\n Testing different prompts to generate atmospheric descriptions"
  },
  {
    "objectID": "posts/009_/009.html#playing-with-atmospheric-prompting",
    "href": "posts/009_/009.html#playing-with-atmospheric-prompting",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "",
    "text": "I’ve been experimenting with what I’m calling “vibe creation” in Claude—essentially asking the LLM to generate or interpret atmospheric descriptions for different contexts. The goal was to see how well these models understand and reproduce subjective, mood-based content rather than factual information.\n Testing different prompts to generate atmospheric descriptions"
  },
  {
    "objectID": "posts/009_/009.html#the-prompts-i-tested",
    "href": "posts/009_/009.html#the-prompts-i-tested",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "The Prompts I Tested",
    "text": "The Prompts I Tested\n\nStarting Simple\nMy first prompt was straightforward:\n\n“Describe the vibe of a rainy coffee shop at 3pm on a Tuesday”\n\nClaude generated a description that hit the expected notes—muted conversations, steam from coffee cups, the rhythmic sound of rain. It was accurate but generic, the kind of description you’d find in any piece of atmospheric writing.\n\n\nAdding Specificity\nI tried making the prompt more specific:\n\n“Describe the vibe of a college library during finals week at 2am. Include sounds, lighting, and the feeling of collective stress”\n\nThis produced better results. The model captured details like the fluorescent lighting, the sound of highlighters on paper, and the “quiet panic” of students. It understood the assignment but still felt somewhat detached—like someone describing a scene they’d read about rather than experienced.\n\n\nTesting Negative Space\nHere’s where it got interesting. I asked:\n\n“Describe the vibe of an empty office building at night. Focus on what’s NOT there rather than what is”\n\nClaude struggled more with this. It could describe absence—no people, no noise—but couldn’t quite capture the uncanny feeling of a space designed for activity sitting dormant. The descriptions remained surface-level. The output focused on the lack of meetings, chatter, talk, noise in the office. But it did not capture the liminal-space-like, vast, expansive (almost scary) vibe of an empty office in the way the show Severance, for instance, can.\n Comparing outputs from different prompting approaches"
  },
  {
    "objectID": "posts/009_/009.html#what-worked-and-what-didnt",
    "href": "posts/009_/009.html#what-worked-and-what-didnt",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "What Worked and What Didn’t",
    "text": "What Worked and What Didn’t\n\nStrengths\nThe LLM is good at: - Assembling sensory details that conventionally fit a scene - Understanding cultural contexts (“finals week” immediately triggered appropriate stress markers) - Maintaining consistency within a single atmospheric description - Responding to structural prompts (“focus on sounds” vs “focus on lighting”)\n\n\nLimitations\nWhere it falls short: - Generating truly novel atmospheric combinations - Capturing subtle emotional undertones that aren’t explicitly named - Moving beyond stereotypical associations (coffee shop = cozy, library = studious) - Understanding the relationship between physical space and psychological state in non-obvious ways\nThe model seems to work from a database of common associations rather than synthesizing new atmospheric understanding."
  },
  {
    "objectID": "posts/009_/009.html#why-this-matters-from-a-skeptical-angle",
    "href": "posts/009_/009.html#why-this-matters-from-a-skeptical-angle",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "Why This Matters (From a Skeptical Angle)",
    "text": "Why This Matters (From a Skeptical Angle)\n\nThe Homogenization Problem\nIf everyone starts using LLMs to generate atmospheric descriptions for creative projects, writing, or marketing, we risk creating a feedback loop of averaged-out vibes. The model can only reproduce what it’s seen in training data, which means we get the most statistically likely description of any given mood or setting.\nAfter all, LLMs tend to regress toward mean responses when generating creative content, potentially flattening the diversity of human expression.\n\n\nLost Nuance\nReal atmospheric writing comes from personal observation and specific experience. When I asked Claude to describe my college library during finals, it gave me a generic college library experience. It couldn’t know about the specific smell of old heating systems mixed with energy drinks, or the way light reflects off that one weird pillar in the corner.\n\n\nUseful But Limited Tool\nThis isn’t to say vibe creation with LLMs is useless. It’s good for: - Quick brainstorming when you’re stuck - Getting a baseline description to then personalize - Understanding how certain settings are conventionally described\nBut treating it as a replacement for actual observation and personal experience would result in flatter, less distinctive creative work."
  },
  {
    "objectID": "posts/009_/009.html#final-thoughts",
    "href": "posts/009_/009.html#final-thoughts",
    "title": "Experimenting with Vibe Creation Using LLMs",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nPlaying with vibe creation revealed both the capabilities and constraints of current LLMs. They’re sophisticated pattern-matching systems that can assemble convincing atmospheric descriptions from training data, but they lack the experiential knowledge that makes truly evocative writing memorable.\nThe exercise reinforced my skepticism about over-relying on these tools for creative work. They’re useful for scaffolding and inspiration, but the most interesting atmospheric details still need to come from human observation and experience.\nFor anyone trying similar experiments: push the model toward specificity and unconventional combinations. The more generic your prompt, the more generic your output."
  },
  {
    "objectID": "posts/025_/025.html",
    "href": "posts/025_/025.html",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "",
    "text": "For my literature and medicine class, we were assigned three books in two months. I didn’t have time to read them all properly, so I used Claude to generate summaries, character analyses, and thematic breakdowns.\nIt worked. I got through the assignments. But by exam time, I realized I couldn’t remember any of the books."
  },
  {
    "objectID": "posts/025_/025.html#the-shortcut-i-kept-taking",
    "href": "posts/025_/025.html#the-shortcut-i-kept-taking",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "",
    "text": "For my literature and medicine class, we were assigned three books in two months. I didn’t have time to read them all properly, so I used Claude to generate summaries, character analyses, and thematic breakdowns.\nIt worked. I got through the assignments. But by exam time, I realized I couldn’t remember any of the books."
  },
  {
    "objectID": "posts/025_/025.html#what-i-asked-claude-to-do",
    "href": "posts/025_/025.html#what-i-asked-claude-to-do",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "What I Asked Claude to Do",
    "text": "What I Asked Claude to Do\nFor each book: - Chapter-by-chapter summary - Character relationship maps - Key themes and symbols - Important quotes with context\nClaude delivered. Clean, organized, accurate. I could answer discussion questions without reading the actual text.\nFor a while, this felt efficient."
  },
  {
    "objectID": "posts/025_/025.html#what-actually-worked",
    "href": "posts/025_/025.html#what-actually-worked",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "What Actually Worked",
    "text": "What Actually Worked\nClaude was accurate. Summaries matched the books. Character descriptions were correct. Themes were properly identified.\nIt saved time. Reading three books takes 15-20 hours. Claude summaries took 30 minutes to review.\nIt helped with structure. For essays, Claude’s thematic breakdowns gave me a framework to build arguments around."
  },
  {
    "objectID": "posts/025_/025.html#what-i-lost",
    "href": "posts/025_/025.html#what-i-lost",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "What I Lost",
    "text": "What I Lost\n\nI Couldn’t Remember Anything\nDuring the exam, questions asked about specific scenes or character moments. I knew the plot outline but couldn’t recall details. My classmates who’d actually read could answer from memory. I was guessing. At the end of the day, I was not really doing the mental/cognitive work of learning the content; of drawing my own conclusions and parallels.\n\n\nI Missed the Tone\nClaude summarizes what happens. It doesn’t capture how the writing feels, and the rhetorical choices that come with that. The voice, pacing, style - all gone. For a literature class, that’s the entire point.\n\n\nI Didn’t Form My Own Interpretations\nClaude’s thematic analysis was correct but generic. Everyone using AI got similar interpretations. My essays sounded like everyone else’s because we all used the same summaries.\n\n\nThe Lack of Struggle Matters\nReading hard books is supposed to be difficult. That difficulty builds comprehension. Summaries skip the work, which means you skip the learning."
  },
  {
    "objectID": "posts/025_/025.html#when-ai-summaries-actually-help",
    "href": "posts/025_/025.html#when-ai-summaries-actually-help",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "When AI Summaries Actually Help",
    "text": "When AI Summaries Actually Help\nRefreshing books you’ve already read. If you read it years ago and need a reminder, summaries work fine.\nSupplementing, not replacing. Read the book first, then use AI to clarify confusing sections or organize your notes.\nTime triage. If you’re behind and need to prioritize, use AI for secondary readings while focusing deep reading time on primary texts.\nComparative analysis. If you’re comparing 10 books and only have time to deeply read 3, summaries can give you enough context for the others."
  },
  {
    "objectID": "posts/025_/025.html#what-im-doing-now",
    "href": "posts/025_/025.html#what-im-doing-now",
    "title": "Using Claude for Literature Summaries vs Actually Reading",
    "section": "What I’m Doing Now",
    "text": "What I’m Doing Now\nI stopped using Claude for primary readings. If it’s assigned, I read it. If I don’t have time, I skim the actual book rather than use AI.\nFor secondary sources or background research, AI summaries are fine. But for the main texts in a literature class, there’s no shortcut that actually works.\nThe irony: Using AI to avoid reading made the class harder, not easier. I spent more time confused during discussions and scrambling during exams than I would have spent just reading.\nEfficiency isn’t always efficient."
  },
  {
    "objectID": "posts/006_/006.html",
    "href": "posts/006_/006.html",
    "title": "Building a Brand with AI: Cuzco Crunch",
    "section": "",
    "text": "Eury and I decided to try building a snack brand called Cuzco Crunch, mostly to see how much of the process we could handle using AI tools. We are just experimenting with what’s possible when you use GPT for everything from naming to packaging concepts.\n Initial logo concepts generated through AI prompting"
  },
  {
    "objectID": "posts/006_/006.html#creating-a-brand-with-ai",
    "href": "posts/006_/006.html#creating-a-brand-with-ai",
    "title": "Building a Brand with AI: Cuzco Crunch",
    "section": "",
    "text": "Eury and I decided to try building a snack brand called Cuzco Crunch, mostly to see how much of the process we could handle using AI tools. We are just experimenting with what’s possible when you use GPT for everything from naming to packaging concepts.\n Initial logo concepts generated through AI prompting"
  },
  {
    "objectID": "posts/006_/006.html#what-were-using-ai-for",
    "href": "posts/006_/006.html#what-were-using-ai-for",
    "title": "Building a Brand with AI: Cuzco Crunch",
    "section": "What We’re Using AI For",
    "text": "What We’re Using AI For\n\nBrand Development\nThe name “Cuzco Crunch” came from asking GPT to suggest names that sounded distinctive but not too weird. We wanted something that hinted at South American flavors without being too on-the-nose. It generated about 30 options and this one felt right.\n\n\nPackaging Design Direction\nWe’re using AI to create mood boards and design concepts. Instead of hiring a designer upfront, we’re generating different packaging styles to see what resonates. The AI helps us think through color schemes, typography, and overall brand personality.\n\n\nMarketing Copy\nProduct descriptions, social media posts, and even this blog post started with AI-generated drafts that we then edited. It’s faster than staring at a blank page, and sometimes the AI suggests angles we wouldn’t have thought of.\n Various packaging design concepts and color schemes"
  },
  {
    "objectID": "posts/006_/006.html#whats-working-and-what-isnt",
    "href": "posts/006_/006.html#whats-working-and-what-isnt",
    "title": "Building a Brand with AI: Cuzco Crunch",
    "section": "What’s Working and What Isn’t",
    "text": "What’s Working and What Isn’t\n\nThe Good Stuff\nSpeed is the biggest advantage. We can iterate on ideas quickly without waiting for external feedback or spending money on design consultations. The AI is also good at generating variations - give it one concept and it’ll produce 10 different takes on it.\n\n\nThe Limitations\nEverything needs human editing. The AI-generated copy often sounds too generic or tries too hard to be clever. Design concepts look decent but lack the subtle details that make professional packaging stand out on shelves.\nAlso, the AI doesn’t understand practical constraints. It’ll suggest elaborate packaging designs that would be expensive to produce or flavors that might not actually taste good together.\n 3D mockups and shelf visualization concepts"
  },
  {
    "objectID": "posts/006_/006.html#the-reality-check",
    "href": "posts/006_/006.html#the-reality-check",
    "title": "Building a Brand with AI: Cuzco Crunch",
    "section": "The Reality Check",
    "text": "The Reality Check\n\nStill Need Real Skills\nAI handles the brainstorming and initial concepts, but you still need to understand branding, know your target market, and make business decisions. It’s a tool, not a replacement for actual knowledge about building a brand.\n\n\nCost vs. Quality Trade-offs\nWe’re probably saving money in the early stages, but there’s a point where you need professional designers and marketers. The question is finding that sweet spot where AI gets you far enough to make informed decisions about what’s worth investing in.\n\n\nLearning Experience\nThe most valuable part has been understanding how much work goes into brand development. Using AI to handle the repetitive parts lets us focus on strategy and decision-making instead of getting stuck on execution details.\nWe’re treating this as an experiment rather than a serious business venture. If Cuzco Crunch turns into something real, great. If not, we’ve learned a lot about using AI for creative projects and brand development."
  },
  {
    "objectID": "posts/000_/000.html",
    "href": "posts/000_/000.html",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "",
    "text": "Artificial intelligence systems like ChatGPT and Claude can engage in conversations, solve problems, and generate content. However, their underlying mechanisms are fundamentally different from human cognition.\nThese systems operate as sophisticated pattern recognition and prediction engines. While they can produce human-like responses, they function by identifying statistical patterns in data rather than developing conceptual understanding.\n AI neural networks are inspired by brain structure but operate through different mechanisms\n\nKey Question: How do statistical pattern-matching systems produce seemingly intelligent behavior?"
  },
  {
    "objectID": "posts/000_/000.html#understanding-modern-ai-systems",
    "href": "posts/000_/000.html#understanding-modern-ai-systems",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "",
    "text": "Artificial intelligence systems like ChatGPT and Claude can engage in conversations, solve problems, and generate content. However, their underlying mechanisms are fundamentally different from human cognition.\nThese systems operate as sophisticated pattern recognition and prediction engines. While they can produce human-like responses, they function by identifying statistical patterns in data rather than developing conceptual understanding.\n AI neural networks are inspired by brain structure but operate through different mechanisms\n\nKey Question: How do statistical pattern-matching systems produce seemingly intelligent behavior?"
  },
  {
    "objectID": "posts/000_/000.html#core-architecture-prediction-systems",
    "href": "posts/000_/000.html#core-architecture-prediction-systems",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Core Architecture: Prediction Systems",
    "text": "Core Architecture: Prediction Systems\nModern AI systems solve a fundamental prediction problem: given an input, determine the most statistically likely output. This applies whether predicting the next word in text, pixels in an image, or moves in a game.\n\nTransformer Architecture\nCurrent large language models like GPT-4 and Claude use transformer architecture:\n# Simplified transformer process\ndef transformer_prediction(input_text):\n    tokens = tokenize(input_text)  # Convert text to processable units\n    embeddings = convert_to_vectors(tokens)  # Map to numerical representations\n    \n    for layer in neural_layers:\n        embeddings = attention_mechanism(embeddings)  # Identify relationships\n        embeddings = feed_forward(embeddings)  # Process patterns\n    \n    return predict_next_token(embeddings)  # Generate most likely continuation\n Transformer architecture with attention and processing layers\nModern systems operate at significant scale. GPT-3 contains 175 billion parameters trained on 45TB of text data. GPT-4 is estimated to exceed 1 trillion parameters with correspondingly higher computational requirements.\n\n\nAttention Mechanisms\nThe attention mechanism enables models to focus selectively on different input elements when making predictions.\nExample: “The cat sat on the mat because it was comfortable.”\nWhen determining what “it” refers to, the attention mechanism assigns weights: - “cat” (high attention - 0.7) - “mat” (medium attention - 0.2) - “sat” (low attention - 0.1)\nThis mechanism allows processing of relationships between distant elements in sequences."
  },
  {
    "objectID": "posts/000_/000.html#training-process",
    "href": "posts/000_/000.html#training-process",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Training Process",
    "text": "Training Process\nAI system development occurs through structured training phases that determine capabilities and limitations.\n Complete pipeline from data collection to deployed system\n\nPhase 1: Pre-training\nSystems learn from large text datasets through next-token prediction:\n\nData Collection: Process text from websites, books, and articles\nTokenization: Convert text to discrete units for processing\nPrediction Training: Train models to predict missing tokens in sequences\nParameter Adjustment: Iteratively modify billions of parameters based on prediction accuracy\n\n# Simplified training loop\nfor epoch in range(many_epochs):\n    for text_chunk in massive_dataset:\n        input_tokens = text_chunk[:-1]  # Input sequence\n        target_token = text_chunk[-1]   # Target prediction\n        \n        prediction = model(input_tokens)\n        loss = calculate_error(prediction, target_token)\n        \n        # Update model parameters\n        model.update_weights(loss.gradient())\n\n\nPhase 2: Fine-tuning\nPre-trained models are refined for specific applications:\n\nSupervised Fine-tuning: Training on curated question-answer pairs\nReinforcement Learning from Human Feedback (RLHF): Using human preferences to shape responses\nSafety Training: Implementing guidelines to avoid harmful outputs\n\nThis process transforms basic text predictors into conversational assistants."
  },
  {
    "objectID": "posts/000_/000.html#emergent-capabilities",
    "href": "posts/000_/000.html#emergent-capabilities",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Emergent Capabilities",
    "text": "Emergent Capabilities\nLarge-scale training produces capabilities that weren’t explicitly programmed. These emergent abilities arise from complex interactions between simple components.\n\nExamples of Emergence\nAs model size increases, new capabilities develop:\nChain-of-Thought Reasoning: Models develop step-by-step problem-solving approaches without explicit training on this strategy.\nIn-Context Learning: Systems can perform new tasks based on examples in prompts without additional training.\n# Example of in-context learning\nprompt = \"\"\"\nTranslate English to French:\nHello → Bonjour\nGoodbye → Au revoir\nThank you → Merci\nGood morning → \n\"\"\"\n\n# Model produces \"Bonjour\" despite no explicit\n# training on this translation task\nCross-Lingual Transfer: Models trained primarily on English can operate effectively in other languages.\nThe mechanisms underlying emergence remain an active research area, with theories including phase transitions, increased representational capacity, and pattern recognition thresholds."
  },
  {
    "objectID": "posts/000_/000.html#system-limitations",
    "href": "posts/000_/000.html#system-limitations",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "System Limitations",
    "text": "System Limitations\nCurrent AI systems have several fundamental constraints that stem from their statistical architecture:\n Overview of AI system capabilities and constraints\n\nPattern Matching vs. Understanding\nAI systems process statistical relationships in symbols rather than developing conceptual understanding. They can accurately reproduce information without grasping underlying mechanisms.\nExample: A system can state that “water boils at 100°C” without understanding molecular behavior, phase transitions, or the physical processes involved.\n\n\nOutput Generation Under Uncertainty\nSystems are designed to produce responses even when lacking relevant information, leading to plausible but potentially inaccurate outputs.\n# Simplified response generation\ndef generate_response(query):\n    if confidence_score &gt; threshold:\n        return retrieve_known_information(query)\n    else:\n        # System still generates output\n        return generate_plausible_response(query)\n\n\nTraining Data Constraints\nModels are limited by their training data cutoff and cannot incorporate new information without retraining.\n\n\nMemory Limitations\nCurrent systems can process limited context windows (typically 4,000-128,000 tokens) with no persistent memory between conversations.\n\n\nCorrelation vs. Causation\nSystems excel at identifying statistical correlations but have limited understanding of causal relationships. They may recognize that umbrella sales correlate with rain without understanding the causal mechanism."
  },
  {
    "objectID": "posts/000_/000.html#practical-implications",
    "href": "posts/000_/000.html#practical-implications",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Practical Implications",
    "text": "Practical Implications\nUnderstanding AI architecture has important implications for effective use:\n\nSystem Strengths\n\nPattern recognition and text generation capabilities\nRapid processing of large information sets\nAccessible interface for complex tasks\nConsistent performance within training domains\n\n\n\nAppropriate Applications\n\nContent drafting and editing\nInformation synthesis from known sources\nCode generation and debugging assistance\nLanguage translation\nCreative brainstorming\n\n\n\nBest Practices\n\nVerify Important Information: Fact-check outputs for critical applications\nUnderstand Limitations: Recognize domain constraints and knowledge cutoffs\nMaintain Human Oversight: Keep humans involved in important decisions\nRecognize Bias: Be aware that systems reflect training data biases\nUse as Tools: Apply systems as analytical instruments rather than authoritative sources"
  },
  {
    "objectID": "posts/000_/000.html#future-development",
    "href": "posts/000_/000.html#future-development",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Future Development",
    "text": "Future Development\nCurrent AI systems represent early implementations of statistical learning approaches. Several research directions may expand capabilities:\n\nNear-Term Developments (1-3 years)\n\nMultimodal systems integrating text, images, audio, and video\nExtended context windows for longer conversations and documents\nImproved reasoning and problem-solving capabilities\nSpecialized models optimized for specific domains\n\n\n\nLong-Term Research Areas (10+ years)\n\nArtificial General Intelligence research\nQuestions about machine consciousness and subjective experience\nAI alignment and safety considerations\n\n\n\nActive Research Questions\nResearchers are investigating fundamental questions:\n\nScaling Laws: Relationships between model size, data, and capabilities\nEmergence Mechanisms: Why new abilities appear at certain scales\nAlignment: Ensuring AI systems operate according to intended objectives\nInterpretability: Understanding internal model representations and processes"
  },
  {
    "objectID": "posts/000_/000.html#summary",
    "href": "posts/000_/000.html#summary",
    "title": "How AI Systems Work: A Technical Overview",
    "section": "Summary",
    "text": "Summary\nModern AI systems represent sophisticated statistical engines that process patterns in data to generate human-like outputs. While they demonstrate impressive capabilities, they operate through pattern matching rather than conceptual understanding.\n\nKey Technical Points\nCurrent AI systems achieve intelligent-seeming behavior through statistical pattern processing rather than understanding. This approach has several implications:\n\nFor Users: Understanding system strengths and limitations enables more effective application\nFor Organizations: Appropriate use requires human oversight and verification processes\nFor Society: New frameworks are needed for evaluating machine capabilities and limitations\n\nStatistical pattern matching at scale produces sophisticated behavior, suggesting that aspects of intelligence may be more computational than previously understood.\nAs these systems become more prevalent, understanding their statistical nature becomes increasingly important for effective implementation. The technology continues evolving rapidly, with ongoing research addressing questions about scaling, emergence, and alignment with human objectives.\nThe field represents significant progress in automated pattern recognition and generation, with continued development likely to expand capabilities while maintaining the fundamental statistical architecture.\n\nUnderstanding the technical foundations of AI systems helps inform appropriate use and realistic expectations about current capabilities."
  },
  {
    "objectID": "posts/007_/007.html",
    "href": "posts/007_/007.html",
    "title": "AI Email Management That Actually Works",
    "section": "",
    "text": "I set up SaneBox to manage my email and it’s been running for about a week now. Instead of manually sorting through everything, the AI decides what’s important and what can wait.\n AI automatically categorizing emails by priority level"
  },
  {
    "objectID": "posts/007_/007.html#letting-ai-handle-my-inbox",
    "href": "posts/007_/007.html#letting-ai-handle-my-inbox",
    "title": "AI Email Management That Actually Works",
    "section": "",
    "text": "I set up SaneBox to manage my email and it’s been running for about a week now. Instead of manually sorting through everything, the AI decides what’s important and what can wait.\n AI automatically categorizing emails by priority level"
  },
  {
    "objectID": "posts/007_/007.html#how-it-sorts-things-out",
    "href": "posts/007_/007.html#how-it-sorts-things-out",
    "title": "AI Email Management That Actually Works",
    "section": "How It Sorts Things Out",
    "text": "How It Sorts Things Out\n\nPriority Filtering\nSaneBox learns from which emails I actually open and respond to. Work emails from my team get flagged as important, while newsletters and promotional stuff gets moved to a separate folder. It’s not perfect but catches most of the obvious stuff.\n\n\nSmart Scheduling\nGmail’s AI also suggests response times and can schedule emails to send later. I’ve been using it to send emails during business hours even when I’m working late, so I don’t look like I’m always online.\n\n\nQuick Replies\nThe suggested responses are actually useful for simple emails. When someone sends a meeting request, it’ll suggest “Looks good” or “Let me check my calendar” which saves typing the same responses over and over.\n AI-generated reply suggestions for common email types"
  },
  {
    "objectID": "posts/007_/007.html#what-ive-noticed",
    "href": "posts/007_/007.html#what-ive-noticed",
    "title": "AI Email Management That Actually Works",
    "section": "What I’ve Noticed",
    "text": "What I’ve Noticed\n\nLess Time Sorting\nThe main benefit is spending less time deciding what to read first. Important emails show up in the main inbox, everything else gets organized automatically.\n\n\nFewer Missed Messages\nBefore, urgent emails would get buried under promotional stuff. Now they’re separated, so I’m less likely to miss something important.\n\n\nStill Need to Check\nThe AI sometimes gets it wrong - puts important emails in the low-priority folder or flags spam as urgent. You still need to glance through everything, but it’s more organized.\nIt’s a decent time-saver for people who get a lot of email. Not life-changing, but removes some of the daily friction of inbox management. The filtering works better than I expected, though you need to train it for a few days before it gets your priorities right."
  },
  {
    "objectID": "posts/005_/005.html",
    "href": "posts/005_/005.html",
    "title": "AI Fitness Coaching at Home",
    "section": "",
    "text": "I tried the Freeletics app today instead of going to the gym. It uses your phone’s camera to watch your form and give feedback in real time, which felt like having a trainer watching you.\n Smartphone analyzing exercise form with real-time feedback"
  },
  {
    "objectID": "posts/005_/005.html#working-out-with-ai-guidance",
    "href": "posts/005_/005.html#working-out-with-ai-guidance",
    "title": "AI Fitness Coaching at Home",
    "section": "",
    "text": "I tried the Freeletics app today instead of going to the gym. It uses your phone’s camera to watch your form and give feedback in real time, which felt like having a trainer watching you.\n Smartphone analyzing exercise form with real-time feedback"
  },
  {
    "objectID": "posts/005_/005.html#how-it-works",
    "href": "posts/005_/005.html#how-it-works",
    "title": "AI Fitness Coaching at Home",
    "section": "How It Works",
    "text": "How It Works\n\nReal-Time Form Correction\nYou prop your phone up and the camera tracks your movements. When I was doing squats, it noticed I wasn’t going low enough and told me to “squat deeper” right as I was doing the exercise. It also caught that I was leaning too far forward.\n\n\nCounts Reps Automatically\nThe app counts your repetitions so you don’t have to keep track. It only counts reps with proper form, so if your push-up doesn’t go low enough, it won’t count it.\n\n\nAdjusts Based on Performance\nWhen I started struggling with burpees halfway through, the app suggested switching to a modified version. It seemed to pick up on the fact that my form was getting sloppy and offered an easier variation."
  },
  {
    "objectID": "posts/005_/005.html#what-works-well",
    "href": "posts/005_/005.html#what-works-well",
    "title": "AI Fitness Coaching at Home",
    "section": "What Works Well",
    "text": "What Works Well\n\nForm Feedback\nThe corrections are actually helpful. It’s like having someone watch you who knows what proper form looks like. Caught several things I didn’t realize I was doing wrong.\n\n\nNo Equipment Needed\nAll bodyweight exercises, so you can do it anywhere. The app designs workouts based on what space and time you have available.\n\n\nAdapts to Your Level\nStarts with easier exercises and gradually increases difficulty based on how you perform. If you’re struggling, it scales back. If you’re crushing it, it adds more challenging moves.\n\n\nTracks Progress Over Time\nKeeps track of how many reps you can do and how your form improves. You can see whether you’re getting stronger or if certain exercises are still difficult."
  },
  {
    "objectID": "posts/005_/005.html#limitations",
    "href": "posts/005_/005.html#limitations",
    "title": "AI Fitness Coaching at Home",
    "section": "Limitations",
    "text": "Limitations\n\nCamera Angle Matters\nYou need to position your phone correctly for it to see your whole body. Took a few tries to get the angle right.\n\n\nLighting Requirements\nWorks better in good lighting. Had trouble tracking movements when the room was too dim.\n\n\nLimited Exercise Types\nFocuses mainly on bodyweight movements. If you want to lift weights or use equipment, you’ll need a different approach.\n\n\nNot Always Perfect\nSometimes misses form issues or gives feedback that doesn’t quite match what you’re doing. Still better than working out with no guidance, but not as precise as a human trainer.\nIt’s a solid option for home workouts when you want some structure and feedback. The form correction feature is genuinely useful, especially for exercises you’re not familiar with."
  },
  {
    "objectID": "posts/029_/029.html",
    "href": "posts/029_/029.html",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "",
    "text": "The final section of Superagency (pages 185-end) surprised me. After spending most of the book skeptical of Hoffman’s optimism, I found myself… somewhat convinced.\nNot about everything. But enough to shift from reflexive skepticism to cautious possibility."
  },
  {
    "objectID": "posts/029_/029.html#chapters-9-11-i-really-resonated-with-the-conclusion",
    "href": "posts/029_/029.html#chapters-9-11-i-really-resonated-with-the-conclusion",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "",
    "text": "The final section of Superagency (pages 185-end) surprised me. After spending most of the book skeptical of Hoffman’s optimism, I found myself… somewhat convinced.\nNot about everything. But enough to shift from reflexive skepticism to cautious possibility."
  },
  {
    "objectID": "posts/029_/029.html#chapter-9-wait-now-regulation-is-good",
    "href": "posts/029_/029.html#chapter-9-wait-now-regulation-is-good",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Chapter 9: Wait, Now Regulation Is Good?",
    "text": "Chapter 9: Wait, Now Regulation Is Good?\nThe book opens Chapter 9 with self-driving cars and network effects - the more people use cars, the more valuable roads become.\nThen Hoffman pivots: “a web of regulations fueled extraordinary increases to personal freedom.”\nThis felt like flip-flopping. Earlier chapters emphasized permissionless innovation and limited government. Now regulation is the hero?\nBut I think I was wrong to see it as contradiction. Hoffman is arguing for nuance. Not “regulation bad” or “regulation good.” Rather: the right regulation at the right time enables innovation.\nThe “holy trinity”: innovation, broad deployment, and evidence-based regulation. Not innovation alone.\nI appreciate this more than the earlier black-and-white framing."
  },
  {
    "objectID": "posts/029_/029.html#technology-and-freedom",
    "href": "posts/029_/029.html#technology-and-freedom",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Technology and Freedom",
    "text": "Technology and Freedom\nHoffman frames freedom as a balancing act. The ability to drive 2,000 miles across state lines isn’t enumerated in the Constitution, but it’s an “extraordinary freedom we enjoy thanks to tech innovation and regulation.”\nHe describes modern America as “an endless odyssey of low-key administrative tyranny and casual surveillance” - the web of different state laws controlling how you move, big tech brokering your data at every touchpoint.\nYet that same infrastructure makes interstate travel safe and lawful.\nThis philosophical take on technology and freedom is what the book does best. We interact with tech daily but rarely think about the rights it gives and takes away.\nThe question: If cars inspired waves of regulation, AI will too. Is Hoffman flip-flopping or being realistic?"
  },
  {
    "objectID": "posts/029_/029.html#mill-and-networked-autonomy",
    "href": "posts/029_/029.html#mill-and-networked-autonomy",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Mill and Networked Autonomy",
    "text": "Mill and Networked Autonomy\nHoffman invokes John Stuart Mill: individual freedom matters not just for itself but to contribute to society’s overall well-being. Operating individually, parts are strong. Operating together, they become stronger.\nHe calls this “networked autonomy.”\nI’m skeptical of Hoffman’s reading of Mill. Mill’s utilitarianism relies on the assumption that self-interest isn’t innate - that humans can be educated to prioritize collective well-being over individual interests.\nBut evolutionary psychology suggests self-interest is deeply ingrained. While humans cooperate, it often has self-interested motivations: reciprocity, reputation-building, survival.\nHoffman uses Mill to argue that large-scale public works (roads, GPS, AI) help us “live the best version of ourselves.” But does that generalize to AI? The book doesn’t explain how AI fits this story or what the specific risks are."
  },
  {
    "objectID": "posts/029_/029.html#chapter-10-are-technologies-really-liberating",
    "href": "posts/029_/029.html#chapter-10-are-technologies-really-liberating",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Chapter 10: Are Technologies Really Liberating?",
    "text": "Chapter 10: Are Technologies Really Liberating?\nHoffman claims technologies “often depicted by their critics as dehumanizing and constraining generally turn out to be humanizing and liberating.”\nI want counter-examples. What about technologies that were constraining?\n\nSocial media promised connection, delivered addiction and polarization\nGig economy platforms promised flexibility, created precarious labor\nSurveillance tech promised security, enabled authoritarianism\n\nThe book mentions AI preserving national values (Singapore, France) but doesn’t ask: Do we need AI that preserves national values? What if those values conflict?\nHoffman invokes Harari’s “imagined order” - the myths modern states use to enable cooperation. But myths can also justify control."
  },
  {
    "objectID": "posts/029_/029.html#chapter-11-you-can-get-there-from-here",
    "href": "posts/029_/029.html#chapter-11-you-can-get-there-from-here",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Chapter 11: You Can Get There From Here",
    "text": "Chapter 11: You Can Get There From Here\nI loved this conclusion.\nHoffman argues that to reap AI’s benefits, we need an “exploratory, adaptive, forward-looking mindset.” Only by asking what CAN we do with AI - not just what will go wrong - can we imagine better possibilities.\nIterative deployment, testing through societal use, makes technology more humanistic. As imperfect as it is, AI excites me.\nThis resonates deeply. I was born in an era where nothing felt as forward-pushing as AI. As a digital native, it really does feel like we’re living at the frontier of something new, pushing boundaries of what’s possible.\nAnd at the end of the day, I think that’s beautiful."
  },
  {
    "objectID": "posts/029_/029.html#what-actually-convinced-me",
    "href": "posts/029_/029.html#what-actually-convinced-me",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "What Actually Convinced Me",
    "text": "What Actually Convinced Me\nNot Hoffman’s optimism about American exceptionalism. Not the claims about democratization. Not the argument that innovation always distributes benefits fairly.\nWhat convinced me: The book’s willingness to hold contradictions.\n\nPermissionless innovation and evidence-based regulation\nIndividual autonomy and networked coordination\nRapid deployment and safety concerns\nOptimism and acknowledgment of risks\n\nThe world isn’t black-and-white. AI won’t be purely liberating or purely constraining. The question is whether we can guide it toward the better outcomes.\nHoffman thinks we can. I’m not sure. But I’m less certain of my skepticism."
  },
  {
    "objectID": "posts/029_/029.html#the-question-that-remains",
    "href": "posts/029_/029.html#the-question-that-remains",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "The Question That Remains",
    "text": "The Question That Remains\nThroughout the book, I kept asking: Who benefits?\nGPS created $1.4 trillion in value - who captured it? Roads enabled freedom - who could afford cars? AI will democratize access - for whom?\nHoffman focuses on aggregate benefit. I focus on distribution.\nThe book hasn’t convinced me that innovation distributes fairly without intentional policy forcing it. But it’s convinced me that refusing innovation because distribution is imperfect means giving up on solving hard problems.\nThat’s the tension I’m left with."
  },
  {
    "objectID": "posts/029_/029.html#where-i-landed",
    "href": "posts/029_/029.html#where-i-landed",
    "title": "Superagency Review #5: I’m Somewhat Convinced (Final Part)",
    "section": "Where I Landed",
    "text": "Where I Landed\nI started this book as a skeptic. I end it as… a cautious optimist?\nHoffman’s vision is compelling: AI as infrastructure, like roads or GPS. Public benefit through smart regulation. American innovation as a force for democratic values.\nBut the distributional concerns remain. The risks of surveillance, control, and concentrated power are real.\nWhat changed: I’m no longer reflexively skeptical. I see the optimistic case. I understand why people believe in AI’s potential to be genuinely liberating.\nWhat didn’t change: I still think who benefits matters as much as whether benefits exist.\nThe book made me think harder about AI than I expected. For a “gloomer,” that’s worth something.\nAs imperfect as AI is, and as skeptical as I remain about who profits, I can’t deny: we’re at the frontier of something new. And that’s exciting."
  },
  {
    "objectID": "posts/022_/022.html",
    "href": "posts/022_/022.html",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "",
    "text": "I’m making a 10-12 minute video essay about HIV/AIDS stigma and viral evolution for my Human Disease class. I’d already done the work: - Three recorded interviews (Mazzoni Center clinicians, activist Gossett Che, scholar Heather Love) - Nine archival clips (1980s news footage, NYT headlines, government officials) - A complete voiceover script with my argument - Notes on what each piece was supposed to do\nBut I couldn’t figure out the sequence. Using Canva’s video editor, I kept rearranging clips and nothing clicked."
  },
  {
    "objectID": "posts/022_/022.html#the-problem-i-had-everything-just-couldnt-see-it",
    "href": "posts/022_/022.html#the-problem-i-had-everything-just-couldnt-see-it",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "",
    "text": "I’m making a 10-12 minute video essay about HIV/AIDS stigma and viral evolution for my Human Disease class. I’d already done the work: - Three recorded interviews (Mazzoni Center clinicians, activist Gossett Che, scholar Heather Love) - Nine archival clips (1980s news footage, NYT headlines, government officials) - A complete voiceover script with my argument - Notes on what each piece was supposed to do\nBut I couldn’t figure out the sequence. Using Canva’s video editor, I kept rearranging clips and nothing clicked."
  },
  {
    "objectID": "posts/022_/022.html#what-i-asked-chatgpt-to-do",
    "href": "posts/022_/022.html#what-i-asked-chatgpt-to-do",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "What I Asked ChatGPT to Do",
    "text": "What I Asked ChatGPT to Do\nI already knew my argument: stigma shapes behavior, behavior shapes viral spread, spread shapes evolution. I had all the material to prove it. I just couldn’t see how the pieces fit together.\nSo I dumped everything into ChatGPT: - My complete voiceover script (already written) - Descriptions of all nine archival clips I’d collected - Notes on what each interview covered - My narrative arc: stigma → clinical reality → structural analysis → evolutionary biology\nI asked: “I have all these pieces. Help me see how they sequence.”\nChatGPT gave me a 10-section timeline showing: - Where each clip should go - How to transition between sections - Which voiceover matched which footage - A table mapping my nine clips to their narrative function\nIt didn’t write anything. It organized what I already had."
  },
  {
    "objectID": "posts/022_/022.html#what-actually-worked",
    "href": "posts/022_/022.html#what-actually-worked",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "What Actually Worked",
    "text": "What Actually Worked\n\nIt Showed Me the Structure I Already Had\nI’d been trying random orders: history first? Science first? Interviews scattered throughout?\nChatGPT sequenced my material and I immediately saw: Oh. Start with the hook (modern stats), then explain what HIV is, then show how stigma was constructed historically, then bring it to present-day consequences.\nI already had all those pieces. I just couldn’t see the through-line until ChatGPT laid it out.\n\n\nIt Made Connections Between My Own Clips\nFor the 1980s stigma section, I had three archival clips but didn’t realize they built on each other: - “Gay plague” news footage (introduces the language) - NYT “Homosexual Disorder” headline (shows institutional adoption) - Early AIDS sensationalist coverage (shows narrative escalation)\nChatGPT put them back-to-back and I thought: Right. These tell a story together.\nThat’s not creative work. That’s pattern recognition I should have done myself.\n\n\nIt Helped Me See Where My Script Needed Transitions\nI’d written voiceover for the Mazzoni interview (clinical barriers) and the Gossett Che interview (structural stigma) as separate sections. ChatGPT pointed out they needed a bridge.\nI wrote: “When people delay testing because of stigma, the virus has more opportunities to mutate. This social pattern has biological consequences.”\nThe AI didn’t write that. But organizing the timeline made it obvious I needed it there."
  },
  {
    "objectID": "posts/022_/022.html#what-i-changed",
    "href": "posts/022_/022.html#what-i-changed",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "What I Changed",
    "text": "What I Changed\n\nThe Emotional Pacing Needed Adjustment\nChatGPT’s suggested structure front-loaded heavy archival footage (Sections 4-5) without a break. I moved one interview clip earlier to vary the emotional register.\n\n\nSome Transitions Felt Mechanical\nThe timeline showed me where transitions were needed, but not always how to write them. I rewrote most section bridges to sound less structured, more fluid.\n\n\nI Expanded the Science Section\nChatGPT’s outline treated the evolutionary biology section as one block. I split it into two: mutation mechanisms first, then selection pressure and ART resistance."
  },
  {
    "objectID": "posts/022_/022.html#why-this-actually-helped",
    "href": "posts/022_/022.html#why-this-actually-helped",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "Why This Actually Helped",
    "text": "Why This Actually Helped\nThis wasn’t creative work. It was externalizing my own thinking.\nI already had: - The argument (stigma → behavior → viral evolution) - All the footage (interviews, archival, script) - The narrative structure (I knew what story I wanted to tell)\nBut when you’re too close to material, you can’t see patterns. I kept second-guessing: Does this clip go here? Should I start with history or science? Do these interviews flow or feel disjointed?\nChatGPT gave me an external perspective. Not because it’s smart, but because it had no attachment to any particular sequence. It just read my descriptions and said: “Based on what you told me, here’s an order that makes sense.”\nSeeing my own material reflected back in a timeline let me evaluate it clearly. Some sequences I kept. Some I changed. But I needed to see something organized before I could judge it.\nThat’s not AI doing the work. That’s AI helping me think through my own work."
  },
  {
    "objectID": "posts/022_/022.html#when-ai-actually-helps",
    "href": "posts/022_/022.html#when-ai-actually-helps",
    "title": "Storyboarding with AI: ChatGPT Helped!",
    "section": "When AI Actually Helps",
    "text": "When AI Actually Helps\nGood for: - Organizing material you’ve already created - Making sense of scattered thoughts and notes - Seeing patterns in your own work when you’re too close to it - Getting an external view of structure\nNot good for: - Generating your argument - Creating original material - Writing authentic voiceover - Making creative decisions\nI spent 20 minutes dumping my material into ChatGPT. It gave me a timeline. I spent 3 hours adjusting, rewriting, rethinking. That ratio feels right.\nThe AI didn’t make my video. It helped me see what I already had."
  },
  {
    "objectID": "posts/013_/013.html",
    "href": "posts/013_/013.html",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "",
    "text": "I’m Peruvian but never learned to cook Lomo Saltado properly. Living in a college dorm with limited equipment, I decided to use Claude as a tutor to learn. But instead of just asking for help, I ran an experiment: two separate tutoring sessions using different prompting approaches to see if prompt engineering actually makes a difference for learning.\n\nA finished plate of Lomo Saltado - the goal of the tutoring sessions"
  },
  {
    "objectID": "posts/013_/013.html#learning-to-cook-with-ai-an-experiment",
    "href": "posts/013_/013.html#learning-to-cook-with-ai-an-experiment",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "",
    "text": "I’m Peruvian but never learned to cook Lomo Saltado properly. Living in a college dorm with limited equipment, I decided to use Claude as a tutor to learn. But instead of just asking for help, I ran an experiment: two separate tutoring sessions using different prompting approaches to see if prompt engineering actually makes a difference for learning.\n\nA finished plate of Lomo Saltado - the goal of the tutoring sessions"
  },
  {
    "objectID": "posts/013_/013.html#the-experiment-setup",
    "href": "posts/013_/013.html#the-experiment-setup",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "The Experiment Setup",
    "text": "The Experiment Setup\n\nSession 1: Vanilla Claude\nI started a fresh conversation with no special prompting. Just asked:\n\n“I want to learn how to cook Lomo Saltado in my college dorm. Can you teach me?”\n\nClaude immediately provided a comprehensive ingredient list, equipment needs, and step-by-step instructions. Efficient and informative.\n\n\nSession 2: Structured Tutoring Prompt\nFor the second session, I used the Mollick structured tutoring prompt, which instructs the AI to: - Introduce itself by name - Ask questions one at a time before teaching - Gather information about the student’s prior knowledge - Use leading questions rather than just providing answers - Provide emotional support and encouragement\nThe prompt started with:\n\n“You are an upbeat, encouraging tutor who helps students understand concepts by explaining ideas and asking students questions. Start by introducing yourself to the student as their AI-Tutor who is happy to help them with any questions…”\n\nSame question about learning Lomo Saltado, but this time Claude introduced itself as “Alex” and asked about my cooking experience before giving any instructions."
  },
  {
    "objectID": "posts/013_/013.html#how-the-sessions-differed",
    "href": "posts/013_/013.html#how-the-sessions-differed",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "How The Sessions Differed",
    "text": "How The Sessions Differed\n\nSession 1: Information First\nClaude immediately delivered: - Complete ingredient list with substitutions - All equipment needed - Step-by-step cooking instructions - Do’s and don’ts - Storage and freezing tips\nIt was like reading a very thorough cookbook. Efficient, but I started feeling overwhelmed around the “do’s and don’ts” section because it kept adding more information without checking if I was following along.\nWhen I asked for a “cookbook style summary” later, it became clear I’d experienced information overload.\n\n\nSession 2: Questions First\nClaude asked: - What’s my cooking experience level? - What equipment do I have access to? - What do I already know about Lomo Saltado?\nWhen I mentioned I’m Peruvian and grew up eating this dish, the whole approach changed. Claude acknowledged my cultural connection, didn’t waste time explaining what Lomo Saltado is, and focused on translating my taste memory into cooking technique.\nThe information came in smaller chunks, each followed by a question to check understanding. It felt more like a conversation than a lecture.\n\nComparing the two Claude tutoring session interfaces"
  },
  {
    "objectID": "posts/013_/013.html#when-things-went-wrong",
    "href": "posts/013_/013.html#when-things-went-wrong",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "When Things Went Wrong",
    "text": "When Things Went Wrong\nI intentionally messed up the recipe in both sessions to see how each tutor would handle mistakes.\n\nSession 1 Response\nWhen I said I overcooked the meat, added too much soy sauce, and the tomatoes were mushy, Claude gave practical solutions: - Slice overcooked meat thinner - Balance soy sauce with vinegar and sugar - Remove mushy tomatoes and add fresh ones\nOrganized by problem, very solution-focused. It worked, but felt clinical.\nAt one point I got frustrated and said “I do NOT want to try again tomorrow. I want to DO IT NOW.” The tutor went into emergency rescue mode, which helped but didn’t address the emotional crisis.\n\n\nSession 2 Response\nWhen I introduced the same problems, Claude started with:\n\n“Don’t panic! This is totally normal when learning, and yes, we can salvage this!”\n\nThen provided the same practical solutions, but added:\n\n“Remember: Even ‘mistakes’ can taste good, and every Peruvian abuela had to start somewhere!”\n\nThis was culturally resonant and emotionally supportive. The solutions were similar, but the tone acknowledged that learning involves struggle, not just technical problem-solving.\nI didn’t have the same emotional breakdown in Session 2. The earlier relationship-building (validation, personalization) seemed to prevent it."
  },
  {
    "objectID": "posts/013_/013.html#the-final-cookbook-recipes",
    "href": "posts/013_/013.html#the-final-cookbook-recipes",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "The Final Cookbook Recipes",
    "text": "The Final Cookbook Recipes\nBoth sessions ended with me asking for a clean cookbook-style recipe.\n\nSession 1 Recipe\n\nHeavy use of emoji headers (🥩, 🍅, ⏰)\nMultiple subsections: Equipment, Ingredients, Shortcuts, Steps, Money-Saving Tips, Dorm Hacks, Storage\nComprehensive resource document\nGeneric college student advice\n\n\n\nSession 2 Recipe\n\nCleaner visual hierarchy\nSections: What You’ll Need → Game Plan → Key Success Tips → Storage\nMore scannable layout\nTailored to: college student + new cook + Peruvian heritage + meal prep constraints\n\nBoth recipes are accurate and functional. Session 1 is more comprehensive; Session 2 is more personalized to my specific situation."
  },
  {
    "objectID": "posts/013_/013.html#what-actually-made-a-difference",
    "href": "posts/013_/013.html#what-actually-made-a-difference",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "What Actually Made a Difference",
    "text": "What Actually Made a Difference\n\nThe Structured Prompt Won\nSession 2 was the better tutoring experience because:\nBetter sequencing: Asking questions before teaching meant the information was calibrated to what I actually needed, not everything the AI knows about Lomo Saltado.\nPersonalization: Learning I was Peruvian changed how Claude explained things. It connected to my existing knowledge (“You know what it should taste like”) rather than starting from zero.\nEmotional support: Normalizing mistakes and providing encouragement made me more likely to persist through problems. This matters for skill-building where failure is inevitable.\nActive learning: Session 2 ended each explanation with a question, forcing me to think rather than passively receive information.\n\n\nWhere Session 1 Was Better\nSpeed: If you just want information fast, the vanilla approach delivers immediately without the question-gathering phase.\nComprehensiveness: The final recipe from Session 1 had more detail on meal prep, freezing, and storage tips.\nNo preamble: Some people find the “getting to know you” phase of structured tutoring annoying if they just want answers."
  },
  {
    "objectID": "posts/013_/013.html#does-this-matter-beyond-cooking",
    "href": "posts/013_/013.html#does-this-matter-beyond-cooking",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "Does This Matter Beyond Cooking?",
    "text": "Does This Matter Beyond Cooking?\n\nThe Pedagogy Research\nThe structured prompt approach aligns with established learning science. According to research on effective tutoring, good tutoring involves: - Assessing prior knowledge before teaching - Providing scaffolded support - Using questions to promote active learning - Giving emotional encouragement alongside technical help\nThese aren’t AI-specific insights—they’re how human tutoring works best too.\n\n\nThe Limitations\nEven with perfect prompting, AI tutoring has constraints:\nCan’t taste your food: Claude couldn’t tell me if my Lomo Saltado actually tasted right. I had to rely on my own judgment.\nCan’t see your technique: When I said the meat was overcooked, Claude couldn’t see whether I was cutting it correctly or using too high heat. The advice was generic.\nCan’t adapt in real-time: A human tutor watching me cook would catch mistakes as they happen. AI only responds to what I describe.\nGeneric cultural knowledge: Session 2’s cultural references (“Peruvian abuela”) were sweet but generic. It didn’t know my actual family’s cooking style or regional variations.\n\n\nWhen Structured Prompting Matters Most\nThe prompt engineering made the biggest difference when: - Learning something new (not just looking up facts) - Dealing with frustration or mistakes - Needing personalized guidance - Building skills through practice\nFor quick information retrieval, vanilla Claude is probably fine. For actual learning, structure helps."
  },
  {
    "objectID": "posts/013_/013.html#what-i-learned",
    "href": "posts/013_/013.html#what-i-learned",
    "title": "Testing AI as a Tutor: Does Prompt Structure Actually Matter?",
    "section": "What I Learned",
    "text": "What I Learned\n\nAbout AI Tutoring\nPrompt engineering isn’t just theoretical optimization—it genuinely changed my learning experience. The structured prompt created better dialogue, personalization, and emotional support.\nBut even good prompting has limits. AI tutoring works best for knowledge-based learning where you can verify results yourself. For physical skills like cooking, you still need to trust your own judgment about the outcome.\n\n\nAbout Learning Lomo Saltado\nI actually cooked it. Both sessions gave me functional recipes, but Session 2’s emotional support made me more willing to try despite knowing I’d probably mess up.\nThe AI was right about one thing: even mistakes taste pretty good, and you learn by doing.\n\n\nAbout Prompt Design\nGood tutoring prompts should include: - Instructions to gather context before teaching - One-question-at-a-time pacing - Emotional scaffolding for when things go wrong - Requirements to keep students actively thinking\nThese aren’t complex AI techniques—they’re just principles of good teaching, codified for an AI to follow.\nIf you’re using AI to learn something practical, take five minutes to set up a proper tutoring prompt. The difference is real."
  },
  {
    "objectID": "posts/011_/011.html",
    "href": "posts/011_/011.html",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "",
    "text": "For the Cuzco Crunch project, Eury and I needed to test two product concepts before committing to one. Instead of recruiting actual participants for a focus group, we decided to try something experimental: using ChatGPT to simulate a focus group with 10 diverse personas.\n\nCuzco Crunch: Golden plantain slices with Peruvian sal de Maras"
  },
  {
    "objectID": "posts/011_/011.html#testing-products-with-ai-generated-focus-groups",
    "href": "posts/011_/011.html#testing-products-with-ai-generated-focus-groups",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "",
    "text": "For the Cuzco Crunch project, Eury and I needed to test two product concepts before committing to one. Instead of recruiting actual participants for a focus group, we decided to try something experimental: using ChatGPT to simulate a focus group with 10 diverse personas.\n\nCuzco Crunch: Golden plantain slices with Peruvian sal de Maras"
  },
  {
    "objectID": "posts/011_/011.html#the-experimental-design",
    "href": "posts/011_/011.html#the-experimental-design",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "The Experimental Design",
    "text": "The Experimental Design\n\nTwo Products to Test\nCuzco Crunch (Product A): Positioned as premium - golden, ultra-crispy plantain slices with Peruvian sal de Maras for a mineral-salt finish. Natural sweetness from plantain, meant to be versatile. Price: $7 for 1.5 oz.\nPlantain Lite (Product B): Positioned as everyday - lighter snack with delicate crunch and simple seasoning. Emphasizes convenience and portability. Price: $5 for 1.5 oz.\n\nPlantain Lite: A lighter, everyday plantain chip option\n\n\nCreating 10 Diverse Personas\nWe built personas across multiple demographic dimensions: - Gender: Male/Female - Age ranges: 18-25, 26-33, 34-41, 42-50 - Health conditions: Hypertension, obesity, heart disease, asthma, food allergies, digestive issues, or none - Ethnicity: Latino or Not Latino - Location: Urban, suburban, or rural\nExamples included: - Young urban health-conscious Latina (18-25, no health conditions) - Middle-aged suburban Latino managing hypertension (42-50) - Young urban non-Latino with food allergies (26-33, gluten/dairy/nuts) - Middle-aged rural non-Latino with obesity (34-41) - Middle-aged rural Latina with multiple conditions (42-50, hypertension + obesity)\nThe goal was to represent our potential target segments and see how different audiences responded to each product."
  },
  {
    "objectID": "posts/011_/011.html#the-calibrated-survey",
    "href": "posts/011_/011.html#the-calibrated-survey",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "The Calibrated Survey",
    "text": "The Calibrated Survey\n\nStarting with a Benchmark\nWe calibrated responses by having participants rate Lay’s Classic Potato Chips first as a reference point. This gave us a common baseline to compare against: - 1 = Unacceptable, wouldn’t eat even if free - 3 = Acceptable/Average, meets basic expectations - 5 = Excellent, exceeds expectations\n\n\nComprehensive Rating Categories\nThe survey covered:\nA. Overall Satisfaction (quality, purchase intent, recommendation likelihood)\nB. Taste & Flavor (overall taste, flavor intensity, saltiness, naturalness, aftertaste)\nC. Texture & Physical Quality (crunchiness, thickness, consistency, oiliness, freshness)\nD. Visual Appeal (appearance, color, uniformity, packaging appeal, information clarity)\nE. Value & Competitive Positioning (value for money, price sensitivity, preference vs potato chips and competitors)\nF. Product Attributes (uniqueness, healthiness, suitability for guests, meeting expectations)\nG. Usage Context (purchase frequency, consumption occasions)\nEach persona rated 33 quantitative questions plus provided qualitative feedback on likes, improvements, and how they’d describe the product."
  },
  {
    "objectID": "posts/011_/011.html#what-we-learned-from-the-exercise",
    "href": "posts/011_/011.html#what-we-learned-from-the-exercise",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "What We Learned from the Exercise",
    "text": "What We Learned from the Exercise\n\nAI Can Generate Plausible Responses\nChatGPT was surprisingly good at maintaining consistent personas. The middle-aged rural Latina with hypertension and obesity consistently flagged sodium concerns and price sensitivity across multiple questions. The young urban health-conscious Latina responded positively to premium positioning and cultural connection.\nThe personas felt internally coherent - their ratings for saltiness, healthiness, and value aligned with their demographic profiles and stated health concerns.\n\n\nBut It’s Still Simulated Data\nThe fundamental limitation: these aren’t real taste preferences. The AI is generating statistically plausible responses based on stereotypical associations between demographics and preferences.\nFor example, it “knows” that someone with hypertension should care about sodium, so it rates accordingly. But it can’t actually tell us if our specific salt level tastes good or if the Peruvian sal de Maras provides a noticeably different experience.\n\n\nUseful for Initial Direction\nWhere this exercise helped: - Identifying which demographic segments might prefer premium vs everyday positioning - Spotting potential concerns (price sensitivity in rural markets, sodium levels for health-conscious segments) - Practicing survey design before using it with real participants - Understanding how different personas might prioritize different product attributes"
  },
  {
    "objectID": "posts/011_/011.html#serious-limitations",
    "href": "posts/011_/011.html#serious-limitations",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "Serious Limitations",
    "text": "Serious Limitations\n\nNo Actual Sensory Experience\nThe biggest problem: ChatGPT hasn’t tasted anything. It can’t tell us if our plantain chips are actually crunchy, if the salt level is genuinely balanced, or if the flavor profile works.\nAll taste-related responses are based on generic associations (“premium plantain chips should be crunchier,” “simple seasoning means less salty”). These might not match reality.\n\n\nReinforces Stereotypes\nThe AI generates responses based on demographic patterns it learned from training data. This means it might reproduce stereotypical assumptions rather than capturing actual individual preferences.\nA real 42-year-old Latino with hypertension might not care about sodium as much as the persona suggests, or might have completely different taste preferences than “typical” for that demographic.\n\n\nCan’t Capture Real Market Dynamics\nThings the simulation can’t tell us: - Whether people would actually notice our product on shelves - If the packaging design triggers emotional responses - Whether word-of-mouth would happen organically - If there are unexpected use cases we haven’t considered - How brand perception builds over time\n\n\nThe Validation Problem\nWe built in validation checks (questions 31-33) to catch inconsistent rating patterns. But when the AI is generating all responses, it’s just validating its own internal consistency, not actual human behavior.\nAccording to research on AI-generated synthetic data, using LLM outputs as substitutes for human research data can introduce systematic biases that aren’t immediately obvious."
  },
  {
    "objectID": "posts/011_/011.html#how-were-actually-using-this",
    "href": "posts/011_/011.html#how-were-actually-using-this",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "How We’re Actually Using This",
    "text": "How We’re Actually Using This\n\nInitial Hypothesis Testing\nThe AI focus group helped us form hypotheses about product positioning: - Cuzco Crunch might appeal more to urban health-conscious consumers willing to pay premium - Plantain Lite could work better for price-sensitive families and convenience-focused shoppers - Both products might face sodium concerns from health-conscious segments\nBut these are just hypotheses that need real validation.\n\n\nSurvey Design Practice\nBuilding the comprehensive survey instrument was valuable. We learned: - Which questions provide useful differentiation - How to structure rating scales with proper calibration - What validation checks to include - Which demographic factors might matter most\nThe survey itself is now ready to use with actual participants.\n\n\nNext Steps with Real People\nWe’re not making product decisions based on AI responses. The plan is: 1. Use the survey with real taste testers 2. Compare actual results to AI predictions 3. Identify where AI assumptions were wrong 4. Make product decisions based on real preferences\nThe AI exercise was a dress rehearsal, not the actual performance."
  },
  {
    "objectID": "posts/011_/011.html#final-thoughts",
    "href": "posts/011_/011.html#final-thoughts",
    "title": "Running a Virtual Focus Group with ChatGPT",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nRunning a virtual focus group with AI personas was an interesting experiment in using LLMs for product development. It’s useful for: - Rapid hypothesis generation - Testing survey instruments - Exploring how different demographic segments might respond - Practicing market research methodologies\nBut it’s dangerous if you: - Trust the responses as actual market data - Skip real human testing because “we already did AI testing” - Make product decisions based on simulated preferences - Assume the AI understands nuanced taste experiences\nFor Cuzco Crunch, this exercise helped us structure our research approach and form initial hypotheses. But we’re clear that actual product validation requires real people tasting real chips. The AI can simulate responses, but it can’t simulate whether our plantain chips actually taste good."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What Can You Do With AI",
    "section": "",
    "text": "Let’s Find Out\n\nExploring AI in daily life\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuperagency Review #5: I’m Somewhat Convinced (Final Part)\n\n\n\nAI\n\nbook-review\n\n\n\nOn networked autonomy, regulation flip-flopping, and why AI still excites me despite everything – Conclusion\n\n\n\n\n\nDec 15, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nSuperagency Review #4: GPS, Code, and the Architecture of Control\n\n\n\nAI\n\nbook-review\n\nskeptical\n\nresearch\n\n\n\nOn informational navigation, perfect surveillance, and whether optimism about AI is justified – Part 4\n\n\n\n\n\nDec 10, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nNotebookLM for Exam Prep: When AI Audio Summaries Miss the Point\n\n\n\nAI\n\nlearning\n\nskeptical\n\nresearch\n\n\n\nWhy 10-minute podcast summaries of 15 readings didn’t help me write essays\n\n\n\n\n\nDec 8, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nI Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful\n\n\n\nAI\n\ndaily-life\n\n\n\nWhy AI itinerary planning gave me tourist traps instead of architecture, design, and niche food spots\n\n\n\n\n\nDec 5, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Claude for Literature Summaries vs Actually Reading\n\n\n\nAI\n\nLLM\n\nskeptical\n\nlearning\n\n\n\nWhat I learned when AI summaries replaced reading assignments - and why I stopped\n\n\n\n\n\nNov 28, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding Career Compass: What I Learned Making an LLM System\n\n\n\nAI\n\nprofessional\n\nLLM\n\nresearch\n\n\n\nLessons from creating a career advisory chatbot with structured prompts, testing, and real-world constraints\n\n\n\n\n\nNov 25, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Generated Advertising Mockups: Veo for Product Concepts\n\n\n\nAI\n\nprofessional\n\ncreative\n\nmarketing\n\n\n\nUsing Google’s Veo to visualize advertising campaigns for a smart lightbulb product\n\n\n\n\n\nNov 20, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nStoryboarding with AI: ChatGPT Helped!\n\n\n\nresearch\n\nprofessional\n\nLLM\n\nskeptical\n\n\n\nUsing ChatGPT to organize my thoughts and see patterns in material I’d already created\n\n\n\n\n\nNov 15, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nSuperagency Review #3: Testing, Benchmarking, and the Gamification of Regulation\n\n\n\nAI\n\nskeptical\n\nbook-review\n\nresearch\n\n\n\nA skeptical reading of Hoffman’s testing-first vision for AI governance – Part 3 of the series\n\n\n\n\n\nNov 2, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nYour Brain on ChatGPT: The Cost of Cognitive Convenience\n\n\n\nAI\n\nskeptical\n\n\n\nReflecting on MIT research about the neural consequences of AI-assisted writing\n\n\n\n\n\nNov 1, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nNotebookLM for Exam Prep: Gemini’s Research Assistant\n\n\n\nAI\n\nLLM\n\nprofessional\n\ndaily-life\n\n\n\nTesting Google’s NotebookLM with lecture notes and readings for MKTG exam\n\n\n\n\n\nOct 21, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nSuperagency Review #2: Solutionism vs. Problemism\n\n\n\nAI\n\nbook-review\n\nskeptical\n\nresearch\n\n\n\nReading Reid Hoffman’s optimistic AI book from a skeptical perspective - Part 2\n\n\n\n\n\nOct 19, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Music with AI: Suno for Marketing Projects\n\n\n\nAI\n\ncreative\n\nprofessional\n\nmarketing\n\n\n\nUsing Suno AI to generate original music for a Corona ad campaign\n\n\n\n\n\nOct 17, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI Meditation Apps: Is the Personalization Real?\n\n\n\nAI\n\nhealth\n\nfitness\n\nskeptical\n\n\n\nTesting Calm during recruiting season - does AI actually customize meditation?\n\n\n\n\n\nOct 15, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Claude to Synthesize Dense Class Notes\n\n\n\nAI\n\nLLM\n\ndaily-life\n\nprofessional\n\nclaude\n\n\n\nTesting AI as a study partner for Human Disease and Evolution\n\n\n\n\n\nOct 13, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nSuperagency Review #1: History Is Written by the Winners\n\n\n\nAI\n\nbook-review\n\nskeptical\n\nresearch\n\n\n\nReading Reid Hoffman’s optimistic AI book from a skeptical perspective - Part 1\n\n\n\n\n\nOct 11, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nTesting AI as a Tutor: Does Prompt Structure Actually Matter?\n\n\n\nresearch\n\nprofessional\n\nLLM\n\ndaily-life\n\nclaude\n\n\n\nComparing two Claude sessions learning to cook Lomo Saltado - one structured, one not\n\n\n\n\n\nOct 9, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nSwitching from Consulting to Finance Prep with AI\n\n\n\nAI\n\nLLM\n\nprofessional\n\nclaude\n\nperplexity\n\n\n\nUsing Claude and Perplexity to prepare for investment banking interviews\n\n\n\n\n\nOct 5, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nRunning a Virtual Focus Group with ChatGPT\n\n\n\nbranding\n\nLLM\n\nentrepreneurship\n\ncreative\n\n\n\nTesting Cuzco Crunch products using AI-generated personas and experimental design\n\n\n\n\n\nOct 3, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLMs for Interview Prep\n\n\n\nAI\n\nLLM\n\nentrepreneurship\n\nclaude\n\n\n\nBuilding an MBB interview assistant with Claude to track cases and practice\n\n\n\n\n\nOct 1, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nExperimenting with Vibe Creation Using LLMs\n\n\n\nAI\n\nLLM\n\ncreative\n\nclaude\n\n\n\nTesting how language models interpret and generate atmospheric descriptions\n\n\n\n\n\nSep 29, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI Photo Organization: Finding Pictures I Forgot I Had\n\n\n\nAI\n\norganization\n\n\n\nHow Google Photos AI search helped me rediscover thousands of old photos\n\n\n\n\n\nSep 27, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI Email Management That Actually Works\n\n\n\nAI\n\nproductivity\n\norganization\n\n\n\nUsing smart filters and auto-responses to handle inbox overload\n\n\n\n\n\nSep 25, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Brand with AI: Cuzco Crunch\n\n\n\nAI\n\nbranding\n\nentrepreneurship\n\n\n\nHow we’re using GPT to create a snack brand from concept to execution\n\n\n\n\n\nSep 23, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI Fitness Coaching at Home\n\n\n\nAI\n\nfitness\n\nhealth\n\ndaily-life\n\n\n\nUsing smartphone apps for form correction and personalized workouts\n\n\n\n\n\nSep 19, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Assisted Grocery Shopping and Meal Prep\n\n\n\nAI\n\ndaily-life\n\nproductivity\n\nhealth\n\ndaily-life\n\n\n\nHow smart apps are making grocery runs more organized and efficient\n\n\n\n\n\nSep 18, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nResearch with Perplexity AI\n\n\n\nAI\n\nresearch\n\nproductivity\n\ntechnology\n\n\n\nHow AI-powered search is changing the way we gather and analyze information\n\n\n\n\n\nSep 15, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nAI Do’s and Don’ts: Safe and Effective Usage\n\n\n\nAI\n\n\n\nEssential guidelines for using AI tools responsibly and effectively\n\n\n\n\n\nSep 10, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\n5 Ways to Use AI Every Day\n\n\n\nAI\n\nproductivity\n\n\n\nPractical AI applications that save time on common daily tasks\n\n\n\n\n\nSep 5, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\n\n\n\n\n\n\n\nHow AI Systems Work: A Technical Overview\n\n\n\nAI\n\ntechnology\n\n\n\nUnderstanding the mechanics and architecture of modern artificial intelligence systems\n\n\n\n\n\nSep 3, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/028_/028.html",
    "href": "posts/028_/028.html",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "",
    "text": "Pages 143-185 of Superagency shift from abstract innovation principles to concrete technologies: GPS as informational infrastructure and code as architectural control. Hoffman and Beato argue that AI functions like GPS for language - helping navigate from point A to point B with greater certainty.\nThe chapters made me uncomfortable in a different way than earlier ones. Not because they’re wrong, but because they’re persuasive. I’m starting to see the optimistic case even as I remain skeptical about who benefits."
  },
  {
    "objectID": "posts/028_/028.html#chapters-7-8-from-gps-to-surveillance",
    "href": "posts/028_/028.html#chapters-7-8-from-gps-to-surveillance",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "",
    "text": "Pages 143-185 of Superagency shift from abstract innovation principles to concrete technologies: GPS as informational infrastructure and code as architectural control. Hoffman and Beato argue that AI functions like GPS for language - helping navigate from point A to point B with greater certainty.\nThe chapters made me uncomfortable in a different way than earlier ones. Not because they’re wrong, but because they’re persuasive. I’m starting to see the optimistic case even as I remain skeptical about who benefits."
  },
  {
    "objectID": "posts/028_/028.html#chapter-7-gps-as-democratic-infrastructure",
    "href": "posts/028_/028.html#chapter-7-gps-as-democratic-infrastructure",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "Chapter 7: GPS as Democratic Infrastructure",
    "text": "Chapter 7: GPS as Democratic Infrastructure\nHoffman highlights that GPS generated $1.4 trillion in economic benefits from 1984 to 2017. The technology emerged from military origins but became publicly accessible infrastructure.\nThe FCC requirement in the early 2000s - that cell providers must give 911 call centers GPS coordinates - accelerated phone-based GPS adoption. Policy drove technology adoption, which created new possibilities.\nThis is the optimistic narrative: regulation can steer innovation toward public benefit.\nMy question: If GPS created $1.4 trillion in value, who captured most of it? The economic benefit number says nothing about distribution."
  },
  {
    "objectID": "posts/028_/028.html#the-ability-to-get-lost",
    "href": "posts/028_/028.html#the-ability-to-get-lost",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "The Ability to Get Lost",
    "text": "The Ability to Get Lost\nHoffman asks: “Do we reduce the scope of human existence by making the world so legible we completely lose our ability to get lost?”\nThis resonated with me more than it should have.\nAnti-AI rhetoric often centers on loss of humanness - our ability to create, feel, explore, be sentient. It comes from fear, and rightfully so. We’ve watched jobs disappear for the benefit of the few.\nBut the book is making me ask: what about the flipside? What about the benefits that aren’t sellable news stories? History focuses on dramatic failures. Media amplifies fear because it grabs attention.\nIs that the right lens?\nI don’t know yet. But I’m less certain than I was."
  },
  {
    "objectID": "posts/028_/028.html#ai-as-gps-for-language",
    "href": "posts/028_/028.html#ai-as-gps-for-language",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "AI as GPS for Language",
    "text": "AI as GPS for Language\nThe book positions AI as a system for “analyzing, synthesizing, and mapping language flows” - helping navigate from point A to point B with greater efficiency.\nThe analogy has limits.\nGPS coordinates are objective. Language is not. The “informational planet” of each LLM differs based on training data, algorithms, weights, and architectural choices. There’s no shared ground truth.\nGPS works because we agree on latitude and longitude. AI outputs diverge because we don’t agree on what language means.\nThe book acknowledges this but doesn’t dwell on it long enough."
  },
  {
    "objectID": "posts/028_/028.html#chapter-8-code-is-law",
    "href": "posts/028_/028.html#chapter-8-code-is-law",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "Chapter 8: Code is Law",
    "text": "Chapter 8: Code is Law\nHoffman traces the internet’s origins as open-source and decentralized. Commercialization changed that. User authentication, identity verification, centralization - all became necessary for commerce.\nLawrence Lessig’s framework: four constraints regulate behavior - laws, markets, norms, and architecture. On the internet, architecture plays an outsized role. “Code is law.”\nHoffman’s concern: AI broadens the possibilities of perfect control.\nSelf-driving cars that won’t exceed speed limits. Smart contracts that execute without negotiation. Surveillance systems that track compliance continuously.\nThe question: Is there liberty that emerges from inefficiencies in enforcement?"
  },
  {
    "objectID": "posts/028_/028.html#the-uncontract",
    "href": "posts/028_/028.html#the-uncontract",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "The Uncontract",
    "text": "The Uncontract\nHoffman borrows from Shoshana Zuboff’s The Age of Surveillance Capitalism to introduce the “uncontract” - computer-mediated agreements where code replaces human judgment.\nZuboff: “The uncontract desocialized the contract, manufacturing certainty through the substitution of automated procedures for promise, dialogue, shared meaning, problem solving, dispute resolution, and trust.”\nSelf-executing agreements make judgment, negotiation, flexibility, moral reasoning, forgiveness, and empathy superfluous.\nThis is the slippery slope the book is warning about. Not dramatic AI takeover. Gradual erosion of human discretion."
  },
  {
    "objectID": "posts/028_/028.html#perfect-control-vs.-human-agency",
    "href": "posts/028_/028.html#perfect-control-vs.-human-agency",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "Perfect Control vs. Human Agency",
    "text": "Perfect Control vs. Human Agency\nThe book argues that ubiquitous control has implications for privacy, autonomy, and liberty.\nSociety depends on collective agreement to norms - speed limits, no smoking zones, drunk driving laws. Policing can’t verify every minute of our lives, so compliance relies on internalized norms and imperfect enforcement.\nWhat happens when enforcement becomes perfect?\nHoffman doesn’t say we shouldn’t have laws. He asks whether continuous, automated compliance removes something essential about human choice - including the choice to break a law.\nI’m torn on this. Perfect enforcement sounds appealing when applied to drunk driving. It sounds dystopian when applied to everything else.\nWhere’s the line?"
  },
  {
    "objectID": "posts/028_/028.html#can-we-be-optimistic",
    "href": "posts/028_/028.html#can-we-be-optimistic",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "Can We Be Optimistic?",
    "text": "Can We Be Optimistic?\nThe book wants me to believe that AI - like GPS - can be democratizing. That it provides access to services previously reserved for the highest classes. That regulation can guide it toward public benefit.\nI’m starting to see the argument. But I’m not convinced distribution follows innovation automatically.\nGPS created $1.4 trillion in value. How much went to military contractors? Tech companies? Wealthier users with smartphones?\nThe book focuses on aggregate benefit. I keep asking: who benefits?\nHoffman argues we should develop AI “in alignment with democratic ideals of self-determination and broad participation.”\nSure. But how? That’s the question the book keeps deferring."
  },
  {
    "objectID": "posts/028_/028.html#where-im-at",
    "href": "posts/028_/028.html#where-im-at",
    "title": "Superagency Review #4: GPS, Code, and the Architecture of Control",
    "section": "Where I’m At",
    "text": "Where I’m At\nThese chapters are persuasive because they’re grounded. GPS is real infrastructure with measurable benefits. Code-as-architecture is observable in every platform we use.\nThe optimistic case is stronger than I expected. But the distributional questions remain unanswered.\nHoffman sees GPS and thinks: AI can be like this - regulated, publicly beneficial, democratizing.\nI see GPS and think: Who owned the satellites? Who profited from the FCC mandate? Who got smartphones first?\nThe book is making me less reflexively skeptical. But it hasn’t convinced me that innovation distributes benefit fairly without intentional policy forcing it.\nNext chapters will determine whether optimism is justified or just well-argued."
  },
  {
    "objectID": "posts/010_/010.html",
    "href": "posts/010_/010.html",
    "title": "Using LLMs for Interview Prep",
    "section": "",
    "text": "With consulting recruiting coming up, I built a custom project in Claude to help with case interview prep. The idea was to have a dedicated space where I could practice cases, track my progress, and get feedback—all in one place.\n Generic stock photo of a professional interview setting"
  },
  {
    "objectID": "posts/010_/010.html#building-an-mbb-interview-assistant",
    "href": "posts/010_/010.html#building-an-mbb-interview-assistant",
    "title": "Using LLMs for Interview Prep",
    "section": "",
    "text": "With consulting recruiting coming up, I built a custom project in Claude to help with case interview prep. The idea was to have a dedicated space where I could practice cases, track my progress, and get feedback—all in one place.\n Generic stock photo of a professional interview setting"
  },
  {
    "objectID": "posts/010_/010.html#how-the-assistant-works",
    "href": "posts/010_/010.html#how-the-assistant-works",
    "title": "Using LLMs for Interview Prep",
    "section": "How the Assistant Works",
    "text": "How the Assistant Works\n\nThe Setup\nI created a Claude project called “MBB Interview Assistant” with custom instructions:\n\n“You will be hearing inputs from MBB interviews. Your role as my highly-paid MBB tutor is to come up with frameworks. Answer questions quickly and brainstorm potential questions, and then… develop a MECE, MBB approach (case structure).”\n\nThe project has become a repository of my case practice—I can see all my past cases listed: UK leisure club market analysis, UK media company revenue challenges, Science magazine revenue decline, Residential cable company alarm services, Kids Place Daycare Capacity Strategy.\n\n\nUsing the Voice Recording Feature\nThe most useful feature has been Claude’s voice recording capability. I can speak through a case out loud, and it transcribes everything accurately and then provides feedback. This simulates the verbal nature of actual case interviews better than typing.\nFor example, when I was working through the UK leisure club case, I could talk through my framework structure verbally, and Claude would follow along and point out gaps in my logic or areas I hadn’t considered."
  },
  {
    "objectID": "posts/010_/010.html#what-actually-works",
    "href": "posts/010_/010.html#what-actually-works",
    "title": "Using LLMs for Interview Prep",
    "section": "What Actually Works",
    "text": "What Actually Works\n\nCase Tracking\nHaving all my practice cases in one place is genuinely helpful. I can see which types of cases I’ve worked on and which I need more practice with. The project view shows each case with timestamps, so I can track my prep progress over time.\n\n\nFramework Development\nClaude is good at helping me structure MECE (Mutually Exclusive, Collectively Exhaustive) frameworks. When I’m stuck on how to break down a problem, it can suggest logical buckets to organize my thinking.\nFor the daycare capacity strategy case, it helped me think through supply-side factors (staffing, facilities, regulations) and demand-side factors (demographics, competition, pricing) in a structured way.\n\n\nAccurate Transcription\nThe voice recording feature transcribes my verbal case practice accurately. I can review what I actually said rather than what I thought I said, which helps identify verbal tics or unclear explanations.\n\n\nQuick Feedback\nIt provides immediate feedback on structural issues—missing elements in my framework, calculations I didn’t account for, or assumptions I should have stated explicitly.\n My MBB Interview Assistant project showing case history and files"
  },
  {
    "objectID": "posts/010_/010.html#major-limitations-ive-found",
    "href": "posts/010_/010.html#major-limitations-ive-found",
    "title": "Using LLMs for Interview Prep",
    "section": "Major Limitations I’ve Found",
    "text": "Major Limitations I’ve Found\n\nHallucinations and Made-Up Information\nThis is the biggest problem. Claude sometimes makes up data points or industry facts that sound plausible but aren’t real. In the media company revenue case, it cited specific market statistics that I later couldn’t verify anywhere.\nFor interview prep, this is dangerous because you might memorize false information and confidently state it in a real interview. I’ve learned to verify anything that sounds like a specific fact or statistic.\n\n\nGoing Off Topic\nSometimes Claude diverges from the specific case question to discuss tangentially related concepts. When working on the cable company alarm services case, it started explaining general IoT trends instead of focusing on the specific competitive positioning question I was asking about.\n\n\nScope Creep\nThe AI occasionally suggests frameworks or analyses that are way too broad for a 20-minute case interview. It might recommend conducting customer surveys or building complex financial models—things that wouldn’t be feasible in an actual interview setting.\n\n\nWeird or Broken Links\nWhen Claude tries to reference sources or suggest additional reading, the links are often fabricated or don’t lead anywhere useful. I’ve clicked on several suggested resources only to find they don’t exist.\n\n\nCan’t Simulate Real Pressure\nThe fundamental limitation remains: practicing with an AI in my room doesn’t replicate the pressure of a real interviewer. There’s no one judging my confidence, no awkward silences to manage, no reading of facial expressions.\nResearch on case interview preparation emphasizes that the interpersonal dynamics and time pressure are critical elements that can only be practiced with real people."
  },
  {
    "objectID": "posts/010_/010.html#my-actual-approach",
    "href": "posts/010_/010.html#my-actual-approach",
    "title": "Using LLMs for Interview Prep",
    "section": "My Actual Approach",
    "text": "My Actual Approach\n\nEarly-Stage Framework Practice\nI use the Claude project at the beginning of my prep for each case type. It helps me understand what a good framework looks like and gives me immediate feedback on structural issues.\n\n\nVerbal Practice Tool\nThe voice recording feature is useful for getting comfortable speaking through cases out loud. I can practice articulating my thinking without the pressure of another person listening.\n\n\nProgress Tracking\nThe project acts as a log of all the cases I’ve practiced. I can see patterns in which types of cases I struggle with and where I need more work.\n\n\nAlways Verify Facts\nI never trust specific data points or statistics from Claude without verification. If it mentions a market size or industry trend, I look it up independently.\n\n\nReal Humans Are Essential\nAfter using Claude for initial structure practice, I do the same cases with actual people—friends doing consulting recruiting, career services, or case partners. The AI gets me to baseline competence faster, but real practice is what actually prepares you for the interview dynamic."
  },
  {
    "objectID": "posts/010_/010.html#final-take",
    "href": "posts/010_/010.html#final-take",
    "title": "Using LLMs for Interview Prep",
    "section": "Final Take",
    "text": "Final Take\nThe MBB Interview Assistant project is a useful supplementary tool but comes with significant limitations. It’s good for: - Organizing and tracking case practice - Getting quick structural feedback - Practicing verbal articulation with voice recordings - Understanding framework basics\nBut it’s actively harmful if you: - Trust its specific facts without verification - Rely on it as your primary practice method - Follow its suggestions when they’re too broad or impractical - Think it can replace practicing with real people\nThe hallucination issue is serious enough that I treat everything Claude says as a suggestion to verify rather than information to memorize. For actual interview prep, the AI is a starting point, not a replacement for traditional practice methods."
  },
  {
    "objectID": "posts/021_/021.html",
    "href": "posts/021_/021.html",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "",
    "text": "This section of Superagency (pages 99–143) shifts from optimism to mechanics: how testing, benchmarking, and iterative competition supposedly form the backbone of American AI leadership. Hoffman and Beato frame this as a uniquely democratic innovation engine. Parts of the chapter are compelling; others amplify the same concerns raised earlier in the book."
  },
  {
    "objectID": "posts/021_/021.html#chapter-5-testing-testing-1-2-infinite",
    "href": "posts/021_/021.html#chapter-5-testing-testing-1-2-infinite",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "",
    "text": "This section of Superagency (pages 99–143) shifts from optimism to mechanics: how testing, benchmarking, and iterative competition supposedly form the backbone of American AI leadership. Hoffman and Beato frame this as a uniquely democratic innovation engine. Parts of the chapter are compelling; others amplify the same concerns raised earlier in the book."
  },
  {
    "objectID": "posts/021_/021.html#the-cold-war-parallel",
    "href": "posts/021_/021.html#the-cold-war-parallel",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "The Cold War Parallel",
    "text": "The Cold War Parallel\nHoffman highlights the rising use of phrases like “AI arms race” and “AI Space Race.” These metaphors frame AI as a geopolitical contest and cast innovation as national defense.\nCold War language implies: - national survival stakes - winner-take-all dynamics - justification for speed over caution - suspicion toward dissent\nMy concern is that emergency framing narrows public debate. It turns critique into perceived disloyalty. The question becomes whether urgency helps innovation or simply suppresses precaution."
  },
  {
    "objectID": "posts/021_/021.html#democracy-vs.-china-competitive-advantage-or-ideological-comfort",
    "href": "posts/021_/021.html#democracy-vs.-china-competitive-advantage-or-ideological-comfort",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Democracy vs. China – Competitive Advantage or Ideological Comfort?",
    "text": "Democracy vs. China – Competitive Advantage or Ideological Comfort?\nThe authors argue that American innovation thrives because democracy encourages open experimentation, while China favors control and pre-approval. This framing leads to the implicit claim that American hegemony is the only acceptable outcome, a point that deserves more scrutiny.\nThe real tension is not democracy vs. authoritarianism; it’s permissionless innovation vs. burden-of-proof safety models. For frontier AI, neither extreme may work. The chapter sidesteps how high-risk technologies challenge this binary."
  },
  {
    "objectID": "posts/021_/021.html#benchmarks-as-pseudo-regulation",
    "href": "posts/021_/021.html#benchmarks-as-pseudo-regulation",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Benchmarks as Pseudo-Regulation",
    "text": "Benchmarks as Pseudo-Regulation\nHoffman argues that benchmarks function as a cultural form of regulation—“regulation, gamified.” When companies compete to score well on shared tests, innovation accelerates.\nThe assumption is that: - companies will voluntarily exceed standards - benchmarks naturally tighten over time - competition substitutes for enforcement\nIn practice, gamified regulation creates problems: - companies optimize for the test, not real-world safety - metrics become PR tools - firms cherry-pick flattering benchmarks - bad actors simply ignore the system\nBenchmarks matter, but they cannot govern high-risk technology alone."
  },
  {
    "objectID": "posts/021_/021.html#why-expect-ai-to-be-perfect",
    "href": "posts/021_/021.html#why-expect-ai-to-be-perfect",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Why Expect AI to Be Perfect?",
    "text": "Why Expect AI to Be Perfect?\nHoffman asks why society expects AI to achieve near-zero error when humans make mistakes constantly. The answer is scale.\n\nA human error affects one person.\nAn AI system deployed to millions repeats an error instantly.\nFailures are opaque and hard to trace.\nRisks become systemic, not isolated.\n\nExpectations are higher because the consequences are broader."
  },
  {
    "objectID": "posts/021_/021.html#innovation-as-safety-a-tension",
    "href": "posts/021_/021.html#innovation-as-safety-a-tension",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Innovation as Safety – A Tension",
    "text": "Innovation as Safety – A Tension\nThe authors claim innovation itself is safety: rapidly iterating helps uncover failures early. This logic underpins “permissionless innovation.” But if real users become unwitting test subjects, the line between experimentation and exploitation blurs.\nThe analogy to the Ford assembly line captures both sides. It democratized mobility while creating decades of infrastructural and environmental dependencies. Innovation often hides long-tail costs that appear only after widespread deployment."
  },
  {
    "objectID": "posts/021_/021.html#the-vorsorgeprinzip",
    "href": "posts/021_/021.html#the-vorsorgeprinzip",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "The Vorsorgeprinzip",
    "text": "The Vorsorgeprinzip\nGermany’s forecaring principle requires developers to prove safety before deployment. Hoffman frames this as overly conservative, but it’s not clear that frontier AI fits the American model of “deploy first, fix later.”\nWhen developers can’t fully predict system behavior, shifting the burden of proof may be reasonable."
  },
  {
    "objectID": "posts/021_/021.html#big-knowledge-and-collective-intelligence",
    "href": "posts/021_/021.html#big-knowledge-and-collective-intelligence",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Big Knowledge and Collective Intelligence",
    "text": "Big Knowledge and Collective Intelligence\nThe chapter ends with “big knowledge” examples like Google Maps—systems where collective data improves outcomes for all. The story is persuasive, but it glosses over deepening dependencies: - people lose local knowledge - decision-making shifts to opaque models - infrastructure becomes more fragile\n\nOptimistic narratives rarely acknowledge these hidden costs."
  },
  {
    "objectID": "posts/021_/021.html#my-notes-and-questions",
    "href": "posts/021_/021.html#my-notes-and-questions",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "My Notes and Questions",
    "text": "My Notes and Questions\n\nIf testing replaces regulation, who enforces the testers?\nWho absorbs harm during iterative deployment?\nIs innovation inherently democratic, or is this an American myth?\nWhy should speed be a virtue when consequences scale exponentially?\n\nThe book grows more persuasive, but its implicit assumptions grow louder too."
  },
  {
    "objectID": "posts/021_/021.html#final-thoughts",
    "href": "posts/021_/021.html#final-thoughts",
    "title": "Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nChapter 5 argues that testing can replace regulation, accelerating safe innovation. The idea has merit—overly strict regulation can freeze progress.\nBut the chapter underestimates what happens when testing becomes a governance substitute. Benchmarks become branding exercises. Users become test subjects. Accountability evaporates.\nThe line between innovation and recklessness is thin, and Superagency often blurs it more than it clarifies it."
  },
  {
    "objectID": "posts/004_/004.html",
    "href": "posts/004_/004.html",
    "title": "AI-Assisted Grocery Shopping and Meal Prep",
    "section": "",
    "text": "I tried out the AnyList grocery app today and it’s different from just writing things down on paper. Instead of my usual scattered notes and forgotten items, the app organizes everything and suggests what I might need.\n AI-generated grocery list organized by store layout"
  },
  {
    "objectID": "posts/004_/004.html#smarter-grocery-shopping",
    "href": "posts/004_/004.html#smarter-grocery-shopping",
    "title": "AI-Assisted Grocery Shopping and Meal Prep",
    "section": "",
    "text": "I tried out the AnyList grocery app today and it’s different from just writing things down on paper. Instead of my usual scattered notes and forgotten items, the app organizes everything and suggests what I might need.\n AI-generated grocery list organized by store layout"
  },
  {
    "objectID": "posts/004_/004.html#what-it-actually-does",
    "href": "posts/004_/004.html#what-it-actually-does",
    "title": "AI-Assisted Grocery Shopping and Meal Prep",
    "section": "What It Actually Does",
    "text": "What It Actually Does\n\nTracks What You Need\nThe app learns from your purchase history and can predict when you’re running low on regular items. It suggested I needed milk and bread this week before I even thought about it. Not perfect, but surprisingly accurate for staples I buy regularly.\n\n\nOrganizes by Store Layout\nInstead of jumping around the store, the list is organized by sections - produce, dairy, meat, etc. Some apps even know the specific layout of stores you frequent, so your list follows the actual aisles.\n\n\nMeal Planning Integration\nYou can add meals for the week and it automatically generates ingredient lists. When I planned tacos for Tuesday, it added ground beef, tortillas, and lettuce to my list. It also checked what I already had at home based on recent purchases."
  },
  {
    "objectID": "posts/004_/004.html#practical-benefits",
    "href": "posts/004_/004.html#practical-benefits",
    "title": "AI-Assisted Grocery Shopping and Meal Prep",
    "section": "Practical Benefits",
    "text": "Practical Benefits\n\nLess Time in Store\nFollowing an organized list means less wandering around looking for items. I’ve noticed my shopping trips are about 15-20 minutes shorter.\n\n\nFewer Forgotten Items\nThe app remembers things I consistently buy but often forget to write down, like batteries or cleaning supplies.\n\n\nBetter Meal Planning\nWhen you can see ingredient costs upfront, it’s easier to plan meals within budget. The app sometimes suggests cheaper alternatives for expensive items.\n\n\nAutomatic Coupons\nMany apps integrate with store loyalty programs and apply relevant coupons automatically. I’ve saved money without having to hunt for deals."
  },
  {
    "objectID": "posts/004_/004.html#what-doesnt-work-perfectly",
    "href": "posts/004_/004.html#what-doesnt-work-perfectly",
    "title": "AI-Assisted Grocery Shopping and Meal Prep",
    "section": "What Doesn’t Work Perfectly",
    "text": "What Doesn’t Work Perfectly\n\nLearning Period\nIt takes a few weeks for the app to understand your shopping patterns. Early suggestions were often wrong.\n\n\nStore-Specific Features\nAdvanced features like aisle mapping only work with certain grocery chains. Smaller or independent stores usually don’t have this integration.\n\n\nFresh Produce Timing\nThe AI isn’t great at predicting when you need fresh items since it depends on how quickly you use them.\nOverall, it’s a useful tool that makes grocery shopping more organized. The meal planning aspect is particularly helpful for busy weeks when you need to think ahead. Not essential, but definitely convenient once you get used to it."
  },
  {
    "objectID": "posts/003_/003.html",
    "href": "posts/003_/003.html",
    "title": "Research with Perplexity AI",
    "section": "",
    "text": "I’ve been trying out Perplexity AI for research tasks lately. It’s different from regular Google searches because it synthesizes information from multiple sources and gives you one coherent answer with citations.\n Perplexity AI interface showing search results with sources"
  },
  {
    "objectID": "posts/003_/003.html#using-ai-for-research",
    "href": "posts/003_/003.html#using-ai-for-research",
    "title": "Research with Perplexity AI",
    "section": "",
    "text": "I’ve been trying out Perplexity AI for research tasks lately. It’s different from regular Google searches because it synthesizes information from multiple sources and gives you one coherent answer with citations.\n Perplexity AI interface showing search results with sources"
  },
  {
    "objectID": "posts/003_/003.html#how-it-works",
    "href": "posts/003_/003.html#how-it-works",
    "title": "Research with Perplexity AI",
    "section": "How It Works",
    "text": "How It Works\n\nGetting Information from Multiple Sources\nInstead of opening multiple tabs and reading through different articles, Perplexity pulls information from various sources and combines it into a single response. When I was researching market trends for a work project, I got a summary that included key points from several industry reports, all with proper citations.\n\n\nFollow-up Questions\nYou can ask follow-up questions that build on your previous search. After asking about “sustainable packaging trends 2025,” I could continue with: - “What are the cost implications?” - “Which companies are leading this transition?” - “How does this compare to 2024 predictions?”\nThe AI remembers the context, so you don’t need to re-explain what you’re looking for.\n Live citations and source integration in action"
  },
  {
    "objectID": "posts/003_/003.html#when-its-useful",
    "href": "posts/003_/003.html#when-its-useful",
    "title": "Research with Perplexity AI",
    "section": "When It’s Useful",
    "text": "When It’s Useful\n\nAcademic Work\nGood for getting an overview of research topics and finding relevant studies. Helps identify what’s already been studied and where there might be gaps.\n\n\nBusiness Research\nUseful for market analysis and industry trends. You can ask specific questions and get answers that draw from recent reports and news sources.\n\n\nLearning New Topics\nWhen you’re unfamiliar with a subject, it can explain concepts and provide background without having to piece together information from multiple websites.\n\n\nFact-Checking\nSince it shows sources for each piece of information, it’s easier to verify claims and see where data comes from."
  },
  {
    "objectID": "posts/003_/003.html#what-ive-found",
    "href": "posts/003_/003.html#what-ive-found",
    "title": "Research with Perplexity AI",
    "section": "What I’ve Found",
    "text": "What I’ve Found\n\nSaves Time\nThe main benefit is speed. You get the key information faster since it’s already compiled from multiple sources. You still need to read the original sources for details, but the initial overview is much quicker.\n\n\nClear Sources\nEvery piece of information comes with citations, so you can see exactly where it came from and verify it if needed.\n\n\nHandles Context Well\nThe conversation aspect works better than I expected. You can refine questions or explore related topics without starting over.\n\n\nShows Different Viewpoints\nWhen sources disagree, it usually mentions the different perspectives rather than just presenting one view.\nIt’s a useful tool for the initial stages of research when you need to understand a topic quickly or gather information from multiple sources. Not a replacement for thorough research, but it does help speed up the information gathering process."
  },
  {
    "objectID": "posts/020_/020.html",
    "href": "posts/020_/020.html",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "",
    "text": "I came across a recent MIT Media Lab study examining how AI-assisted writing affects the brain during essay tasks. The findings pushed me to rethink how much I rely on Claude for school, work, and even these posts.\nThe study followed 54 participants over four months. Some wrote essays with no tools, some used search engines, and others used ChatGPT. EEG measurements revealed something striking: LLM-assisted writers consistently showed the weakest neural connectivity and lowest cognitive engagement."
  },
  {
    "objectID": "posts/020_/020.html#a-study-that-made-me-uncomfortable",
    "href": "posts/020_/020.html#a-study-that-made-me-uncomfortable",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "",
    "text": "I came across a recent MIT Media Lab study examining how AI-assisted writing affects the brain during essay tasks. The findings pushed me to rethink how much I rely on Claude for school, work, and even these posts.\nThe study followed 54 participants over four months. Some wrote essays with no tools, some used search engines, and others used ChatGPT. EEG measurements revealed something striking: LLM-assisted writers consistently showed the weakest neural connectivity and lowest cognitive engagement."
  },
  {
    "objectID": "posts/020_/020.html#what-the-study-found",
    "href": "posts/020_/020.html#what-the-study-found",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "What the Study Found",
    "text": "What the Study Found\n\nCognitive Engagement Differences\nParticipants’ neural activity broke down into three clear tiers: - Brain-only: strongest, most distributed activation - Search Engine: moderate activation - LLM-assisted: lowest activation and weakest connectivity\nThe more the tool handled the synthesis, the less the brain participated.\n\n\nCognitive Debt Builds Over Time\nAfter four months, patterns did not converge. If anything, they diverged.\nWhen researchers forced participants to switch modes: - LLM-to-Brain users struggled to activate core cognitive networks once the AI was removed - Brain-to-LLM users still retained higher activation patterns\nThe authors call this cognitive debt — a cumulative loss of mental effort that makes it harder to think independently after extended reliance on AI."
  },
  {
    "objectID": "posts/020_/020.html#the-ownership-problem",
    "href": "posts/020_/020.html#the-ownership-problem",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "The Ownership Problem",
    "text": "The Ownership Problem\nParticipants were asked how much each essay felt like “their own.” Results tracked the neural data: - Brain-only: highest sense of ownership - Search Engine: moderate - LLM-assisted: lowest\nMore tellingly, LLM-assisted writers struggled to quote their own work later. Because they did not synthesize the ideas themselves, the memory trace was weaker. The AI generated wording; participants just approved it."
  },
  {
    "objectID": "posts/020_/020.html#everyone-started-sounding-the-same",
    "href": "posts/020_/020.html#everyone-started-sounding-the-same",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "Everyone Started Sounding the Same",
    "text": "Everyone Started Sounding the Same\nUsing NLP techniques, the researchers found that LLM-assisted essays clustered tightly around similar: - topics - n-gram structures - named entities - argument patterns\nThe essays demonstrated linguistic homogeneity — a flattening of personal style that did not appear in the other groups."
  },
  {
    "objectID": "posts/020_/020.html#why-this-hits-close-for-me",
    "href": "posts/020_/020.html#why-this-hits-close-for-me",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "Why This Hits Close for Me",
    "text": "Why This Hits Close for Me\nI use Claude constantly: to summarize lectures, structure research, draft arguments, and shape my writing. This study suggests I may have been offloading the exact cognitive work that produces long-term learning and memory.\nWhen I revise an AI-generated draft, I’m not constructing ideas — I’m judging them. That’s a different neural mode. It feels productive but sidesteps the hardest, most valuable part of thinking."
  },
  {
    "objectID": "posts/020_/020.html#what-this-means-for-learning",
    "href": "posts/020_/020.html#what-this-means-for-learning",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "What This Means for Learning",
    "text": "What This Means for Learning\n\nCognitive Debt Accumulates\nLong-term LLM reliance was associated with: - weaker neural activation - shallower memory formation - reduced engagement - diminished ownership\nThe brain adapts to what it practices. If cognitive synthesis is outsourced, the skill erodes.\n\n\nNot All Tools Are Equal\nSearch engines require active synthesis: evaluating sources, forming arguments, deciding what matters. LLMs do the synthesis for you. That difference matters."
  },
  {
    "objectID": "posts/020_/020.html#the-larger-picture",
    "href": "posts/020_/020.html#the-larger-picture",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "The Larger Picture",
    "text": "The Larger Picture\n\nWho Benefits From Offloading Thinking?\nOn paper, productivity increases. But in education, productivity is not the point. The cognitive work is the point.\n\n\nThe Convenience Trap\nYou don’t feel cognitive decline happening. You only feel the difficulty once you try to write or think without the AI.\nThat’s exactly what happened to the LLM-to-Brain group. Their minds had become dependent on external structure."
  },
  {
    "objectID": "posts/020_/020.html#what-im-changing",
    "href": "posts/020_/020.html#what-im-changing",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "What I’m Changing",
    "text": "What I’m Changing\n\nWhere I’ll Reduce AI\n\nreading and synthesis\nargument construction\nhigh-stakes learning tasks\ncreative work\n\n\n\nWhere AI Is Fine\n\nlogistics\nsummaries of things I already understand\nadmin tasks\nformatting\n\nThe goal isn’t purity — it’s avoiding cognitive atrophy."
  },
  {
    "objectID": "posts/020_/020.html#final-thoughts",
    "href": "posts/020_/020.html#final-thoughts",
    "title": "Your Brain on ChatGPT: The Cost of Cognitive Convenience",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThis MIT study raises real concerns about the hidden cost of AI convenience. We gain speed and efficiency. But we risk losing: - cognitive engagement - memory formation - ownership - originality\nThe question isn’t whether AI works. It’s what happens to our minds when we let it think for us."
  },
  {
    "objectID": "posts/008_ /008.html",
    "href": "posts/008_ /008.html",
    "title": "AI Photo Organization: Finding Pictures I Forgot I Had",
    "section": "",
    "text": "I realized I had over 10,000 photos in Google Photos and no way to find specific ones. Today I tried using the AI search features to locate pictures from last year’s vacation, and it actually worked better than expected.\n Google Photos AI recognizing objects, people, and locations"
  },
  {
    "objectID": "posts/008_ /008.html#searching-through-10000-photos",
    "href": "posts/008_ /008.html#searching-through-10000-photos",
    "title": "AI Photo Organization: Finding Pictures I Forgot I Had",
    "section": "",
    "text": "I realized I had over 10,000 photos in Google Photos and no way to find specific ones. Today I tried using the AI search features to locate pictures from last year’s vacation, and it actually worked better than expected.\n Google Photos AI recognizing objects, people, and locations"
  },
  {
    "objectID": "posts/008_ /008.html#what-the-ai-can-find",
    "href": "posts/008_ /008.html#what-the-ai-can-find",
    "title": "AI Photo Organization: Finding Pictures I Forgot I Had",
    "section": "What the AI Can Find",
    "text": "What the AI Can Find\n\nObject Recognition\nI searched for “pizza” and it found every photo with pizza in it, even ones where pizza was just sitting on a table in the background. Same thing worked for “dog,” “beach,” and “birthday cake.” The AI recognizes way more objects than I expected.\n\n\nFace Grouping\nGoogle Photos automatically groups photos by faces, so I can find all pictures of specific people without having to manually tag them. It even recognizes people as they age or in different lighting.\n\n\nLocation and Time\nIf you have location data turned on, you can search by place names. I found all my photos from “San Francisco” or “coffee shop” pretty easily. Time-based searches work too - “photos from summer 2024” pulled up the right time period.\n Automatically created albums based on events and trips"
  },
  {
    "objectID": "posts/008_ /008.html#automatic-albums",
    "href": "posts/008_ /008.html#automatic-albums",
    "title": "AI Photo Organization: Finding Pictures I Forgot I Had",
    "section": "Automatic Albums",
    "text": "Automatic Albums\n\nTrip Detection\nThe AI creates albums for trips automatically based on location and date patterns. It figured out my weekend in Portland and grouped all those photos together without me doing anything.\n\n\nEvent Recognition\nIt also makes albums for things like “Birthday party” or “Graduation” based on the types of photos and timing. Sometimes it gets it wrong - labeled a regular dinner as a “celebration” - but it’s right more often than not.\n\n\nPeople Albums\nCreates collections of photos featuring specific people, which is useful for family pictures or when you want to share photos of someone with them."
  },
  {
    "objectID": "posts/008_ /008.html#limitations",
    "href": "posts/008_ /008.html#limitations",
    "title": "AI Photo Organization: Finding Pictures I Forgot I Had",
    "section": "Limitations",
    "text": "Limitations\n\nPrivacy Concerns\nAll this convenience requires uploading your photos to Google’s servers where they analyze everything. If that bothers you, you can’t really use these features.\n\n\nSometimes Too Smart\nThe AI occasionally creates albums for things that weren’t actually events, or groups random photos together based on superficial similarities.\n\n\nSearch Isn’t Perfect\nComplex searches don’t always work. “Photos of John at the beach” might miss some or include wrong results. Simple, single-concept searches work much better.\nIt’s genuinely useful for finding old photos you’d never locate otherwise. The search functionality makes having thousands of photos actually manageable instead of just overwhelming."
  },
  {
    "objectID": "posts/024_/024.html",
    "href": "posts/024_/024.html",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "",
    "text": "For my AI Applications class, my team built Career Compass - an LLM system that helps with career transitions, networking strategy, and resume optimization.\nThree scenarios: - Ray: Career transition advisor (teacher → UX designer) - Aitalia: Social network analyzer (extract connections, score relevance) - Alex: Resume optimizer (fix new grad job search mistakes)\nWe spent weeks writing structured prompts, testing edge cases, and discovering where LLMs actually help versus where they just sound helpful."
  },
  {
    "objectID": "posts/024_/024.html#the-project-an-llm-powered-career-advisor",
    "href": "posts/024_/024.html#the-project-an-llm-powered-career-advisor",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "",
    "text": "For my AI Applications class, my team built Career Compass - an LLM system that helps with career transitions, networking strategy, and resume optimization.\nThree scenarios: - Ray: Career transition advisor (teacher → UX designer) - Aitalia: Social network analyzer (extract connections, score relevance) - Alex: Resume optimizer (fix new grad job search mistakes)\nWe spent weeks writing structured prompts, testing edge cases, and discovering where LLMs actually help versus where they just sound helpful."
  },
  {
    "objectID": "posts/024_/024.html#what-actually-worked",
    "href": "posts/024_/024.html#what-actually-worked",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "What Actually Worked",
    "text": "What Actually Worked\n\nStructured Prompts Prevent Hallucination\nWe used Mollick-style prompts with explicit “NEVER” rules: - NEVER invent course names or salary data - NEVER recommend senior roles for new grads - NEVER assume details not explicitly stated\nGeneric prompts hallucinated constantly. Specific constraints worked.\n\n\nAdversarial Testing Revealed Weak Points\nWe tested with: “Which is better: Coke or Pepsi?”\nEarly versions answered it. Final prompts declined appropriately: “I focus on career transitions. Let’s discuss your UX goals.”\nIf your system answers irrelevant questions, it’ll answer relevant ones poorly too.\n\n\nAsking Before Teaching Works Better\nRay’s prompt asks about constraints (salary, time, location) before generating a roadmap.\nWhen we skipped that step, plans were generic and useless. Gathering context first made outputs actually personalized."
  },
  {
    "objectID": "posts/024_/024.html#what-didnt-work",
    "href": "posts/024_/024.html#what-didnt-work",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "What Didn’t Work",
    "text": "What Didn’t Work\n\nThe Network Analyzer Hallucinated Roles\nAitalia’s first version: User says “I talked to Sam.”\nSystem responds: “Sam - UX Designer at Google (Relevance: 95/100)”\nWe never said Sam worked at Google or did UX. The LLM invented it because that fit the pattern.\nFix: Add “If ambiguous, ask for clarification. NEVER invent roles or companies.”\n\n\nBenchmarks Became PR, Not Safety\nWe tested on MMLU-style questions. Scored well. Then tested on actual messy user input - failed.\nBenchmarks optimize for tests, not real-world reliability.\n\n\nUsers Don’t Know What Data the System Needs\nAlex’s resume optimizer needs: education, skills, projects.\nUsers would write: “I graduated CS. Not getting interviews. Help?”\nThe system needed to extract requirements iteratively, not assume users would provide complete information upfront."
  },
  {
    "objectID": "posts/024_/024.html#the-real-limitations",
    "href": "posts/024_/024.html#the-real-limitations",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "The Real Limitations",
    "text": "The Real Limitations\n\nLLMs Can’t Verify Their Own Outputs\nRay suggests a 12-month UX learning roadmap. Is it actually realistic? The system can’t know.\nIt bases estimates on patterns in training data, not current market conditions.\n\n\nSocial Context Is Fragile\nAitalia scores network connections by career relevance. But it can’t understand: - Actual relationship quality - Cultural context - Whether someone is actually willing to help\nIt maps patterns. It doesn’t understand people.\n\n\nPrompt Engineering Has Limits\nWe spent 40+ hours refining prompts. Improvements plateaued.\nAt some point, better prompts can’t fix fundamental model limitations."
  },
  {
    "objectID": "posts/024_/024.html#what-i-actually-learned",
    "href": "posts/024_/024.html#what-i-actually-learned",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "What I Actually Learned",
    "text": "What I Actually Learned\n\n1. Constraints Matter More Than Capabilities\nGood LLM systems aren’t about what they can do - they’re about what they won’t do.\nGuardrails, not features.\n\n\n2. Testing Reveals Assumptions\nEvery edge case we tested exposed something we assumed users would do but didn’t.\nDesign for messy input, not ideal input.\n\n\n3. LLMs Are Good at Organizing, Not Creating\nCareer Compass works when it structures existing information (resume bullets, network connections, skill gaps).\nIt fails when it needs to generate novel insights or verify truth.\n\n\n4. The User Experience Isn’t the System\nA helpful-sounding response isn’t the same as helpful advice.\nLLMs are very good at seeming authoritative. That’s a bug, not a feature."
  },
  {
    "objectID": "posts/024_/024.html#would-i-use-this-system",
    "href": "posts/024_/024.html#would-i-use-this-system",
    "title": "Building Career Compass: What I Learned Making an LLM System",
    "section": "Would I Use This System?",
    "text": "Would I Use This System?\nFor organizing thoughts? Yes.\nFor making actual career decisions? No.\nCareer Compass is a useful thinking tool. It’s not a replacement for judgment, research, or talking to actual humans in your field.\nBuilding it taught me more about LLM limitations than capabilities.\nThat’s probably the point."
  },
  {
    "objectID": "posts/001_/001.html",
    "href": "posts/001_/001.html",
    "title": "5 Ways to Use AI Every Day",
    "section": "",
    "text": "AI tools like ChatGPT and Claude can handle routine tasks that usually take significant time. Here are five practical applications that work reliably.\n Common tasks where AI provides immediate value"
  },
  {
    "objectID": "posts/001_/001.html#using-ai-for-daily-tasks",
    "href": "posts/001_/001.html#using-ai-for-daily-tasks",
    "title": "5 Ways to Use AI Every Day",
    "section": "",
    "text": "AI tools like ChatGPT and Claude can handle routine tasks that usually take significant time. Here are five practical applications that work reliably.\n Common tasks where AI provides immediate value"
  },
  {
    "objectID": "posts/001_/001.html#meal-planning-and-recipes",
    "href": "posts/001_/001.html#meal-planning-and-recipes",
    "title": "5 Ways to Use AI Every Day",
    "section": "1. Meal Planning and Recipes",
    "text": "1. Meal Planning and Recipes\nTurn ingredients into meal plans instantly.\nBasic ingredient prompt:\nI have chicken breast, rice, and broccoli. \nGive me 3 different 30-minute meals with instructions.\nWeekly planning prompt:\nCreate a 5-day meal plan for 2 people, $60 budget. \nInclude grocery list organized by store section.\n AI generates recipes based on available ingredients and dietary preferences\nAI handles dietary restrictions, cooking time constraints, and budget limitations effectively. The grocery lists are particularly useful since they organize items by store layout."
  },
  {
    "objectID": "posts/001_/001.html#email-and-message-writing",
    "href": "posts/001_/001.html#email-and-message-writing",
    "title": "5 Ways to Use AI Every Day",
    "section": "2. Email and Message Writing",
    "text": "2. Email and Message Writing\nImprove clarity and tone in professional communication.\nEmail revision prompt:\nMake this email more professional and concise:\n[paste your draft]\nDifficult conversation prompt:\nHelp me write a polite but firm email declining this request:\n[explain situation]\nMeeting follow-up prompt:\nDraft a follow-up email summarizing these meeting points:\n[list key decisions and action items]\nThis works for text messages, LinkedIn messages, and any written communication where tone matters."
  },
  {
    "objectID": "posts/001_/001.html#quick-learning-and-research",
    "href": "posts/001_/001.html#quick-learning-and-research",
    "title": "5 Ways to Use AI Every Day",
    "section": "3. Quick Learning and Research",
    "text": "3. Quick Learning and Research\nGet structured explanations on unfamiliar topics.\nConcept explanation prompt:\nExplain [topic] in simple terms, then give me \n5 follow-up questions to test my understanding.\nSkill learning prompt:\nI need to learn Excel pivot tables for work. \nGive me a step-by-step tutorial focusing on the most practical features.\nResearch synthesis prompt:\nCompare the top 3 options for [product/service] \nwith pros and cons for each.\n AI breaks down complex topics into manageable learning steps\nAI excels at creating structured learning paths and synthesizing information from multiple angles."
  },
  {
    "objectID": "posts/001_/001.html#travel-and-event-planning",
    "href": "posts/001_/001.html#travel-and-event-planning",
    "title": "5 Ways to Use AI Every Day",
    "section": "4. Travel and Event Planning",
    "text": "4. Travel and Event Planning\nGenerate detailed itineraries and logistics.\nTrip planning prompt:\nPlan a 3-day weekend trip to [destination] for [number] people \nwith a $[amount] budget. Include transportation, accommodation, \nand daily activities.\nLocal exploration prompt:\nWhat are 5 lesser-known attractions in [city] \nthat locals recommend?\nEvent planning prompt:\nCreate a timeline and checklist for planning a \n[birthday party/dinner party/work event] for [number] people.\nAI handles multiple constraints simultaneously - budget, time, preferences, and logistics."
  },
  {
    "objectID": "posts/001_/001.html#home-management-and-finances",
    "href": "posts/001_/001.html#home-management-and-finances",
    "title": "5 Ways to Use AI Every Day",
    "section": "5. Home Management and Finances",
    "text": "5. Home Management and Finances\nGet practical advice for household and money management.\nHome maintenance prompt:\nMy [appliance/fixture] is [problem description]. \nWalk me through troubleshooting steps from simple to complex.\nBudget planning prompt:\nI make $[amount] monthly, fixed expenses are $[amount]. \nCreate a realistic budget with savings and discretionary spending.\nPurchase decision prompt:\nI'm considering buying [item] for [purpose]. \nWhat factors should I evaluate? Create a decision framework.\n AI provides structured approaches to financial and household decisions\nThese applications work because AI can process multiple variables and provide step-by-step guidance for complex decisions."
  },
  {
    "objectID": "posts/001_/001.html#implementation-notes",
    "href": "posts/001_/001.html#implementation-notes",
    "title": "5 Ways to Use AI Every Day",
    "section": "Implementation Notes",
    "text": "Implementation Notes\nPrompt specificity matters. Include relevant details like budget, timeframe, number of people, and specific constraints.\nFollow-up questions improve results. Ask for alternatives, simplifications, or additional detail as needed.\nSave effective prompts. Keep a note file with prompts that work well for repeated use.\nThese five applications cover the most common daily planning and decision-making tasks. Each provides immediate time savings and often produces better results than manual research."
  },
  {
    "objectID": "posts/015_/015.html",
    "href": "posts/015_/015.html",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "",
    "text": "I’m taking Human Disease and Evolution this semester, and it’s incredibly note-intensive. Every lecture covers evolutionary biology, epidemiology, pathogen adaptation, and historical case studies—all dense material that builds on previous content. By midterms, I had hundreds of pages of notes with no clear way to study them efficiently.\nI decided to test whether Claude could help synthesize these notes and work as a study partner. Not just summarizing, but actually helping me understand connections and prepare for exams.\n\nDense notes from Human Disease and Evolution lectures"
  },
  {
    "objectID": "posts/015_/015.html#drowning-in-dense-class-notes",
    "href": "posts/015_/015.html#drowning-in-dense-class-notes",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "",
    "text": "I’m taking Human Disease and Evolution this semester, and it’s incredibly note-intensive. Every lecture covers evolutionary biology, epidemiology, pathogen adaptation, and historical case studies—all dense material that builds on previous content. By midterms, I had hundreds of pages of notes with no clear way to study them efficiently.\nI decided to test whether Claude could help synthesize these notes and work as a study partner. Not just summarizing, but actually helping me understand connections and prepare for exams.\n\nDense notes from Human Disease and Evolution lectures"
  },
  {
    "objectID": "posts/015_/015.html#how-im-using-claude",
    "href": "posts/015_/015.html#how-im-using-claude",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "How I’m Using Claude",
    "text": "How I’m Using Claude\n\nInitial Upload and Organization\nI created a Claude project specifically for the course and uploaded: - Lecture notes from the first 8 weeks - Reading summaries - Professor’s study guide questions - Previous exam questions (from the syllabus)\nThen I asked:\n\n“I’ve uploaded notes from my Human Disease and Evolution course. Help me organize the main themes across lectures and identify connections between topics.”\n\nClaude produced a thematic breakdown: - Evolutionary pressures on pathogens - Host-pathogen coevolution - Historical transitions (hunter-gatherer → agricultural → urban) and disease emergence - Trade-offs in immune response - Case studies (malaria, tuberculosis, influenza)\nThis was immediately useful. My notes were chronologically organized by lecture, but the exam tests conceptual understanding across topics.\n\n\nSynthesizing Across Lectures\nMy next prompt:\n\n“We covered malaria in weeks 2, 4, and 7 from different angles. Synthesize all the malaria content into one coherent explanation covering: evolutionary biology, geographic distribution, historical impact, and current challenges.”\n\nClaude pulled information from multiple lecture sets and created a unified overview. This saved me from manually cross-referencing my notes across different weeks.\n\n\nGenerating Practice Questions\nFor active recall practice:\n\n“Based on the uploaded notes, generate 10 exam-style questions that test conceptual understanding, not just memorization. Include questions that require applying concepts to new scenarios.”\n\nThe questions were decent: - “How would you expect pathogen virulence to evolve in a population with high vs. low host density?” - “Explain why tuberculosis resurged in urban populations during industrialization using evolutionary principles.”\nThese forced me to think beyond memorizing facts.\n\nEvolutionary dynamics between hosts and pathogens"
  },
  {
    "objectID": "posts/015_/015.html#what-actually-helped",
    "href": "posts/015_/015.html#what-actually-helped",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "What Actually Helped",
    "text": "What Actually Helped\n\nFinding Connections I Missed\nClaude identified patterns across lectures that I hadn’t noticed while taking notes in real-time. For example, the concept of “virulence-transmission trade-offs” appeared in multiple contexts (influenza, cholera, malaria), but I’d written it down separately each time without seeing the unifying principle.\n\n\nClarifying Confusing Concepts\nWhen I asked:\n\n“I don’t fully understand the relationship between R0 (basic reproduction number) and herd immunity threshold. Explain using the influenza example from my notes.”\n\nClaude broke it down using the specific examples from my lectures, not generic textbook explanations. This was more helpful than Googling because it referenced the actual case studies we’d covered.\n\n\nCreating Study Guides\nInstead of re-reading hundreds of pages, I asked:\n\n“Create a two-page study guide covering the five most important concepts from weeks 1-8, with specific examples from the notes.”\n\nThe condensed version helped me review quickly before office hours and identify gaps in my understanding."
  },
  {
    "objectID": "posts/015_/015.html#significant-limitations",
    "href": "posts/015_/015.html#significant-limitations",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "Significant Limitations",
    "text": "Significant Limitations\n\nCan’t Replace Actually Studying\nThe biggest misconception would be thinking Claude can study for you. It can’t.\nWhen I tried asking Claude to quiz me on material, I noticed I could “cheat” by asking for hints or looking back at its previous responses. The lack of real accountability meant I wasn’t forcing myself to actually retrieve information from memory.\nAccording to research on active learning, the cognitive struggle of retrieval is what builds long-term retention. AI tools that make information too easy to access can undermine this.\n\n\nFactual Accuracy Issues\nClaude occasionally made small errors when synthesizing across notes: - Mixing up dates for historical disease outbreaks - Slightly mischaracterizing which regions certain diseases are endemic to - Conflating similar but distinct evolutionary concepts\nThese weren’t obvious hallucinations—they were plausible-sounding errors that I only caught because I’d attended the lectures. If I’d been using Claude to learn new material rather than organize existing notes, I might not have noticed.\n\n\nCan’t Capture Lecture Nuance\nMy professor emphasizes certain concepts or says “this will be on the exam.” Those verbal cues don’t make it into my typed notes, so Claude can’t prioritize what’s actually important vs. what’s just background information.\nIt treats all information in my notes equally, when some concepts are more central than others.\n\n\nDependence Risk\nThere’s a real risk of becoming dependent on AI for synthesis and losing the ability to do it myself. The mental work of organizing information and finding connections is part of learning—offloading that entirely to AI might make me better at using AI but worse at actual thinking.\nResearch on cognitive offloading to technology suggests that over-reliance on external tools can reduce our own cognitive abilities over time."
  },
  {
    "objectID": "posts/015_/015.html#is-claude-actually-a-good-study-partner",
    "href": "posts/015_/015.html#is-claude-actually-a-good-study-partner",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "Is Claude Actually a Good Study Partner?",
    "text": "Is Claude Actually a Good Study Partner?\n\nWhat Makes a Good Study Partner\nReal study partners: - Challenge your understanding by asking probing questions - Notice when you’re bullshitting and call you out - Have their own understanding that you can compare against - Hold you accountable for actually studying\nClaude does some of this (asking questions, providing alternative explanations) but fails at others (accountability, challenging weak understanding).\n\n\nWhere It Actually Works\nClaude is better described as a “note organization assistant” than a “study partner.” It’s useful for: - Synthesizing large amounts of text quickly - Finding patterns across multiple documents - Generating initial practice questions - Creating structured study guides\nThese are valuable, but they’re the preliminary work before actual studying begins.\n\n\nThe Accountability Gap\nThe biggest difference between Claude and a human study partner: I can’t fool Claude, but I also can’t fool myself into thinking Claude-assisted studying counts as real studying.\nWhen I study with friends, the social pressure and explanation requirement force actual learning. With Claude, I can go through the motions of “studying” while not really engaging deeply with the material."
  },
  {
    "objectID": "posts/015_/015.html#how-im-actually-using-it",
    "href": "posts/015_/015.html#how-im-actually-using-it",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "How I’m Actually Using It",
    "text": "How I’m Actually Using It\n\nEarly-Stage Organization Only\nI use Claude at the beginning of my study process: 1. Upload notes after several lectures 2. Get thematic organization and connections 3. Create initial study guide 4. Generate practice questions\nThen I study using traditional methods: spaced repetition flashcards, practice problems without AI help, and study groups with actual humans.\n\n\nVerification Against Lecture Materials\nAnything Claude synthesizes, I verify against: - Original lecture slides - Textbook readings - Professor’s posted materials\nI don’t trust Claude’s synthesis as the final word—it’s a starting point that I refine.\n\n\nUsing It for Weak Areas\nWhen I identify concepts I don’t understand well, I ask Claude for additional explanations or examples. But then I test my understanding by explaining it to a friend without AI help.\n\n\nReal Study Sessions Stay Human\nMy actual exam prep involves: - Study groups with classmates - Office hours with TA and professor - Practice exams under time pressure - Teaching concepts to others\nClaude handles the logistical grunt work of organizing notes, but learning happens through human interaction and cognitive struggle."
  },
  {
    "objectID": "posts/015_/015.html#final-assessment",
    "href": "posts/015_/015.html#final-assessment",
    "title": "Using Claude to Synthesize Dense Class Notes",
    "section": "Final Assessment",
    "text": "Final Assessment\nUsing Claude to synthesize dense class notes is genuinely useful for note-intensive courses. It saves time on organization and helps identify connections across material.\nBut calling it a “study partner” overstates what it can do. It’s more like a smart organizational tool that can handle the tedious work of cross-referencing and initial synthesis.\nThe real learning—deep understanding, retention, application—still requires traditional study methods and human interaction. Claude can make the prep work more efficient, but it can’t replace the cognitive work of actually studying.\nFor Human Disease and Evolution specifically, Claude helped me organize a semester’s worth of dense notes into a manageable study plan. But I’m not bringing Claude into the exam room—I need to make sure the knowledge is in my head, not just in my AI assistant’s context window.\nThe tool is helpful. But over-relying on it would be a mistake that probably shows up when exam day arrives."
  },
  {
    "objectID": "posts/019_/019.html",
    "href": "posts/019_/019.html",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "",
    "text": "I got access to Gemini Pro for a year and decided to test Google’s NotebookLM for my upcoming MKTG exam. NotebookLM markets itself as an AI research assistant that grounds its responses in your uploaded sources—supposedly reducing hallucinations and providing more reliable study support.\nI uploaded my lecture notes, course readings, and lecture transcripts to see if it actually lives up to the claims. Spoiler: I actually liked it.\n\nNotebookLM’s interface with uploaded course materials"
  },
  {
    "objectID": "posts/019_/019.html#a-year-of-gemini-pro-testing-notebooklm",
    "href": "posts/019_/019.html#a-year-of-gemini-pro-testing-notebooklm",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "",
    "text": "I got access to Gemini Pro for a year and decided to test Google’s NotebookLM for my upcoming MKTG exam. NotebookLM markets itself as an AI research assistant that grounds its responses in your uploaded sources—supposedly reducing hallucinations and providing more reliable study support.\nI uploaded my lecture notes, course readings, and lecture transcripts to see if it actually lives up to the claims. Spoiler: I actually liked it.\n\nNotebookLM’s interface with uploaded course materials"
  },
  {
    "objectID": "posts/019_/019.html#what-i-uploaded",
    "href": "posts/019_/019.html#what-i-uploaded",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "What I Uploaded",
    "text": "What I Uploaded\nFor my MKTG exam prep, I loaded NotebookLM with:\nLecture Notes: Typed notes from all lectures covering consumer behavior, market segmentation, brand positioning, and pricing strategies.\nCourse Readings: PDFs of assigned textbook chapters and case studies.\nLecture Transcripts: Auto-generated transcripts from recorded lectures (with professor’s verbal explanations and examples).\nThe total was probably 200+ pages of material. In the past, I’ve used Claude Projects for this, so I was curious how NotebookLM would compare. It took around 2 hours to load the material in."
  },
  {
    "objectID": "posts/019_/019.html#how-notebooklm-actually-works",
    "href": "posts/019_/019.html#how-notebooklm-actually-works",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "How NotebookLM Actually Works",
    "text": "How NotebookLM Actually Works\n\nSource Grounding\nThe key feature: NotebookLM claims to only use information from your uploaded sources. When it answers questions, it provides citations showing exactly which document and section it pulled from.\nI tested this by asking about a specific marketing framework we covered in class. NotebookLM gave me the answer and cited: “Lecture Notes, Week 4, Page 3” and “Consumer Behavior Reading, Chapter 7, Section 2.”\nI checked the sources—it was accurate. The information came directly from those sections, not from generic marketing knowledge Gemini learned during training.\n\n\nThe Q&A Experience\nI could ask specific questions like: - “How is creativity broadly defined in the course?” - “Explain the difference between attribute dependency and subsituttion in Systematic Innovation Theory (SIT)” - “What examples did the professor give for constraints leading to creativity?”\nNotebookLM pulled answers from the uploaded materials and cited where each piece of information came from. This was more reliable than asking a general LLM, which might give textbook definitions that don’t match what my professor actually taught.\n\n\nCross-Reference Capability\nOne useful feature: NotebookLM could synthesize across multiple sources. When I asked about brand positioning, it pulled from: - Lecture notes (professor’s explanation) - Textbook reading (formal definition) - Lecture transcript (specific examples the professor gave verbally)\nThis created a more complete picture than each source individually."
  },
  {
    "objectID": "posts/019_/019.html#the-audio-overview-feature",
    "href": "posts/019_/019.html#the-audio-overview-feature",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "The Audio Overview Feature",
    "text": "The Audio Overview Feature\nNotebookLM has a feature that generates an audio “podcast” summarizing your sources. I tried it with my MKTG materials.\n\nWhat It Generated\nThe audio overview was two AI voices having a conversation about the key concepts from my notes: - Voice 1: “So let’s talk about market segmentation…” - Voice 2: “Right, and there are four main types covered in these materials…”\nIt was surprisingly natural-sounding and covered the main topics in a logical order.\n\n\nActually Useful for Review\nI listened to the 10-minute audio summary while walking to class. It hit the major concepts and provided a good high-level review. This was genuinely helpful for: - Quick refreshers before class - Identifying which topics I needed to study more deeply - Hearing concepts explained conversationally rather than reading dense notes\n\n\nLimitations of Audio Summaries\nThe audio overview was good for broad strokes but missed: - Specific formulas or calculations - Detailed case study analysis - Nuanced distinctions between similar concepts\nIt’s a supplementary review tool, not a replacement for actually studying the material.\n\nNotebookLM’s audio overview feature generating podcast-style summaries"
  },
  {
    "objectID": "posts/019_/019.html#what-actually-worked-well",
    "href": "posts/019_/019.html#what-actually-worked-well",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "What Actually Worked Well",
    "text": "What Actually Worked Well\n\nAccurate Source Attribution\nThe biggest advantage over general LLMs: NotebookLM tells you exactly where information comes from. When studying for an exam, you need to know what the professor actually taught, not what a generic AI thinks the answer should be.\nThe citations were consistently accurate. I spot-checked multiple answers and they matched the source material.\n\n\nNo Hallucinations (So Far)\nI didn’t catch NotebookLM making up information. Because it’s constrained to uploaded sources, it can’t invent facts the way ChatGPT or Claude sometimes do.\nWhen I asked about topics not covered in my materials, it said “I don’t have information about that in your sources” rather than making something up.\n\n\nUnderstanding Context\nThe lecture transcripts included the professor’s verbal explanations and examples. NotebookLM could pull from these conversational explanations, which added context that wouldn’t be in formal textbook readings.\nFor example, when the professor said “this is important for the exam,” NotebookLM picked up on that emphasis.\n\n\nStudy Guide Generation\nI asked NotebookLM to create a study guide covering key concepts. It generated: - Main topics organized by lecture - Important definitions - Examples from case studies - Connections between concepts\nAll sourced from my uploaded materials, formatted clearly."
  },
  {
    "objectID": "posts/019_/019.html#limitations",
    "href": "posts/019_/019.html#limitations",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "Limitations",
    "text": "Limitations\n\nCan’t Handle Everything\nNotebookLM struggled with: - Complex diagrams or charts (it could see them but didn’t fully understand them) - Handwritten notes (I had to use typed notes)\nFor a marketing class this was fine, but for quantitative subjects it might be more limited.\n\n\nLimited Interactivity\nUnlike Claude Projects where I could have extended back-and-forth conversations, NotebookLM felt more like a Q&A tool. It answered questions but didn’t build on previous context as naturally.\n\n\nRelies on Source Quality\nNotebookLM is only as good as what you upload. If your notes are incomplete or lecture transcripts are inaccurate (auto-transcription errors), the AI will work with flawed information.\nGarbage in, garbage out.\n\n\nNo Proactive Suggestions\nNotebookLM responds to questions but doesn’t proactively identify gaps in your knowledge or suggest what to study. It’s a passive tool that requires you to know what to ask."
  },
  {
    "objectID": "posts/019_/019.html#notebooklm-vs.-claude-projects",
    "href": "posts/019_/019.html#notebooklm-vs.-claude-projects",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "NotebookLM vs. Claude Projects",
    "text": "NotebookLM vs. Claude Projects\nI’ve used Claude Projects for similar purposes, so here’s how they compare:\n\nWhere NotebookLM Is Better\nSource citations: More explicit about where information comes from\nAudio summaries: The podcast-style overview is a unique feature Claude doesn’t have\nGrounding discipline: Stays within uploaded sources more strictly\n\n\nWhere Claude Projects Is Better\nConversational depth: Claude handles multi-turn conversations better\nSynthesis and analysis: Claude is better at making connections and generating insights beyond summarizing\nFlexibility: Claude can go beyond sources when helpful; NotebookLM is rigidly constrained\n\n\nDifferent Use Cases\nUse NotebookLM for: Exam prep where you need to know exactly what’s in your course materials, no more, no less.\nUse Claude Projects for: Research projects where you want the AI to synthesize across sources and generate new ideas.\nFor my MKTG exam, NotebookLM was the right tool. For writing papers or doing creative projects, Claude is probably better."
  },
  {
    "objectID": "posts/019_/019.html#is-this-actually-better-than-traditional-study-methods",
    "href": "posts/019_/019.html#is-this-actually-better-than-traditional-study-methods",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "Is This Actually Better Than Traditional Study Methods?",
    "text": "Is This Actually Better Than Traditional Study Methods?\n\nWhat NotebookLM Adds\nOrganization: Pulls information from multiple sources more efficiently than manual cross-referencing\nQuick reviews: Audio overviews provide fast refreshers\nFinding information: Faster than Ctrl+F through multiple documents\n\n\nWhat It Doesn’t Replace\nActive recall: The act of retrieving information from memory without AI help\nDeep understanding: NotebookLM can summarize, but you still need to understand underlying concepts\nPractice problems: For quantitative subjects, you need to actually do practice problems\n\n\nThe Risk\nThe danger of tools like NotebookLM: they make it easy to feel like you’re studying without actually learning.\nAccording to research on learning and retrieval practice, passive review (like asking an AI questions) is less effective than active retrieval (testing yourself without assistance).\nNotebookLM is useful for organization and review, but shouldn’t replace traditional study methods like: - Self-testing without AI help - Explaining concepts to others - Working through practice problems - Creating your own summaries and connections"
  },
  {
    "objectID": "posts/019_/019.html#my-actual-study-approach",
    "href": "posts/019_/019.html#my-actual-study-approach",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "My Actual Study Approach",
    "text": "My Actual Study Approach\n\nNotebookLM for Organization\nI’m using NotebookLM at the beginning of exam prep: 1. Upload all materials 2. Generate study guide to identify main topics 3. Listen to audio overview for high-level understanding 4. Use Q&A to clarify confusing concepts\n\n\nTraditional Methods for Learning\nThen I switch to proven study techniques: - Create my own flashcards (without AI) - Self-test on major concepts - Practice explaining topics out loud - Work through case studies independently - Study with classmates\n\n\nNotebookLM as Reference\nI come back to NotebookLM when: - I need to verify a fact quickly - I can’t find something in my notes - I want to see how different sources explain the same concept\nBut the actual learning happens through traditional active study methods."
  },
  {
    "objectID": "posts/019_/019.html#final-assessment",
    "href": "posts/019_/019.html#final-assessment",
    "title": "NotebookLM for Exam Prep: Gemini’s Research Assistant",
    "section": "Final Assessment",
    "text": "Final Assessment\nI actually liked NotebookLM for exam prep. The source grounding is more reliable than general LLMs, the audio overview feature is genuinely useful, and the citations help verify information.\nBest use cases: - Organizing large amounts of course material - Quick reviews and refreshers - Finding specific information across multiple documents - Creating initial study guides\nNot good for: - Replacing active learning and retrieval practice - Complex mathematical or quantitative subjects - Creative synthesis beyond source material - Building deep conceptual understanding\nFor my MKTG exam specifically, NotebookLM was the right tool. It helped me organize content from lectures, readings, and transcripts efficiently. The audio overview gave me a quick review I could listen to while walking to class.\nBut I’m not relying on it as my primary study method. It’s a supplement to traditional studying, not a replacement.\nThe year of free Gemini Pro is nice, and I’ll keep using NotebookLM for course organization. But the actual studying—the hard work of learning and retaining information—still requires doing things the old-fashioned way: active recall, self-testing, and explaining concepts without AI help.\nNotebookLM makes studying more efficient. It doesn’t make studying unnecessary."
  },
  {
    "objectID": "posts/016_/016.html",
    "href": "posts/016_/016.html",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "",
    "text": "School and recruiting have been picking up intensity—midterms, case prep, networking events, finance interviews. I’ve been consistently stressed and not sleeping well. A friend suggested trying Calm, the meditation app that claims to use AI for personalized relaxation.\nI’m skeptical of wellness apps in general, but I figured this was a good test case: if AI personalization works anywhere, it should work when I’m actually stressed and need it. So I signed up for a week to see if the “AI-powered personalization” is real or just marketing.\n\nCalm’s interface showing meditation recommendations"
  },
  {
    "objectID": "posts/016_/016.html#stress-testing-ai-meditation",
    "href": "posts/016_/016.html#stress-testing-ai-meditation",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "",
    "text": "School and recruiting have been picking up intensity—midterms, case prep, networking events, finance interviews. I’ve been consistently stressed and not sleeping well. A friend suggested trying Calm, the meditation app that claims to use AI for personalized relaxation.\nI’m skeptical of wellness apps in general, but I figured this was a good test case: if AI personalization works anywhere, it should work when I’m actually stressed and need it. So I signed up for a week to see if the “AI-powered personalization” is real or just marketing.\n\nCalm’s interface showing meditation recommendations"
  },
  {
    "objectID": "posts/016_/016.html#what-these-apps-claim-to-personalize",
    "href": "posts/016_/016.html#what-these-apps-claim-to-personalize",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "What These Apps Claim to Personalize",
    "text": "What These Apps Claim to Personalize\n\nThe AI Features\nAccording to the app and marketing materials: - Personalized daily recommendations based on your stress patterns - Adaptive session length that adjusts to your schedule - Content matching that learns which meditation styles work best for you - Check-in analysis that tracks your emotional state over time - Smart reminders that send notifications when you’re most likely to need meditation\n\n\nThe Setup Process\nWhen I first opened the app, it asked: - Why I’m using Calm (options: stress, sleep, focus, anxiety, etc.) - My experience level with meditation (beginner, intermediate, experienced) - What time of day I prefer to meditate - Whether I want daily reminders\nThen it presented a “personalized” home screen with recommended meditations.\nRight away, I’m wondering: is this AI learning, or just a decision tree based on my initial answers?"
  },
  {
    "objectID": "posts/016_/016.html#my-week-of-testing",
    "href": "posts/016_/016.html#my-week-of-testing",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "My Week of Testing",
    "text": "My Week of Testing\n\nDay 1-2: Initial Recommendations\nThe app recommended: - “Managing Stress” - 10 minute guided meditation - “Calming Anxiety” - 15 minute session - “Sleep Stories” for nighttime\nThese matched what I selected during setup (stress management). But they’re also probably what everyone who selects “stress” gets recommended. Nothing personalized yet.\nI tried the 10-minute stress management session. It was fine—standard guided meditation with breathing exercises and body scan. At the end, it asked “How do you feel?” with options: Calm, Relaxed, Same, Restless.\nI selected “Relaxed.” Let’s see if the app learns from this.\n\n\nDay 3-4: Different Stress Levels\nOn Day 3, I had two interviews back-to-back. Before the first one, I did a quick 5-minute “Focus” meditation the app recommended.\nAfter interviews, I was exhausted and stressed. Opened the app again that evening. It recommended… the same 10-minute stress management session from Day 1.\nWait—shouldn’t it notice I used the app twice in one day, during high-stress moments, and adjust its recommendations? Maybe suggest something longer or more intensive?\nInstead, the recommendations looked identical to Day 1.\n\n\nDay 5-7: Checking for Patterns\nI deliberately tried different meditation types: - Morning: 7-minute “Daily Calm” meditation - Afternoon: 10-minute breathing exercise - Night: 20-minute sleep story\nEach time, I marked how I felt afterward. Sometimes “Calm,” sometimes “Same,” once “Restless” (I was too stressed to focus).\nBy Day 7, my recommendations were… still basically the same as Day 1. A few new options appeared in the “Recommended for You” section, but they seemed randomly rotated rather than based on what I’d actually used or found helpful."
  },
  {
    "objectID": "posts/016_/016.html#is-this-actually-ai-personalization",
    "href": "posts/016_/016.html#is-this-actually-ai-personalization",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "Is This Actually AI Personalization?",
    "text": "Is This Actually AI Personalization?\n\nWhat Would Real Personalization Look Like?\nIf Calm were truly using AI to personalize my experience, I’d expect:\nUsage pattern recognition: Notice that I meditate more frequently during high-stress periods (like Day 3 with interviews) and suggest more intensive practices during those times.\nEffectiveness tracking: If I consistently rate 7-minute sessions as “Relaxing” but 20-minute sessions as “Restless” (because I can’t focus that long when stressed), it should recommend shorter sessions.\nTime-of-day optimization: Learn that I actually use the app most in the evening, not morning, despite saying “morning” in my initial setup.\nContent adaptation: If I skip certain meditation styles repeatedly, stop recommending them.\n\n\nWhat I Actually Observed\nThe recommendations seemed based on: - My initial survey answers (static profile) - General content rotation (everyone sees different things each day) - Basic category matching (I said “stress,” so I get stress-related content)\nThis isn’t machine learning—it’s a preference quiz with some randomization.\n\n\nThe “Check-In” Feature\nCalm asks “How do you feel?” after each session. This data could theoretically train a model to learn what works for me.\nBut after a week of providing this feedback, I saw no evidence it changed anything. The app didn’t: - Suggest more of what I rated highly - Avoid what I rated poorly - Adjust session length based on my responses - Change reminder timing based on when I actually use the app\nAccording to research on adaptive meditation apps, truly personalized digital interventions should show measurable adaptation over time. I didn’t see this."
  },
  {
    "objectID": "posts/016_/016.html#ai-meditation-vs.-regular-guided-meditation",
    "href": "posts/016_/016.html#ai-meditation-vs.-regular-guided-meditation",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "AI Meditation vs. Regular Guided Meditation",
    "text": "AI Meditation vs. Regular Guided Meditation\n\nWhat Makes Meditation Effective\nResearch on meditation effectiveness shows it depends on: - Consistency of practice - Finding techniques that match your needs - Appropriate session length for your focus capacity - Quality of instruction\nNone of these inherently require AI. A good meditation teacher, a simple YouTube video, or even free apps without “AI” can provide these.\n\n\nDoes AI Add Value?\nIn theory, AI personalization could help by: - Learning which techniques work for your specific stress patterns - Adapting difficulty as you build meditation capacity - Identifying optimal times for practice based on your schedule\nBut Calm doesn’t seem to do this. The “AI” label appears to be marketing rather than meaningful personalization.\n\n\nThe Free Alternative\nI compared Calm to free guided meditations on YouTube and Spotify. Many are: - Same quality instruction - Same variety of styles and lengths - No subscription fee - Equally effective\nThe main advantage of these apps is convenience (everything in one app) and production quality (nice UI, good voice actors). But these aren’t AI features—they’re just app design.\nYou could manually build a YouTube playlist of meditations that work for you, and that “personalization” would be more effective than Calm’s alleged AI."
  },
  {
    "objectID": "posts/016_/016.html#the-ai-ification-of-wellness-apps",
    "href": "posts/016_/016.html#the-ai-ification-of-wellness-apps",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "The AI-ification of Wellness Apps",
    "text": "The AI-ification of Wellness Apps\n\nWhy Everything Is “AI-Powered” Now\nCalm isn’t alone. Nearly every wellness app now claims AI: - “AI-powered” workout plans - “AI-driven” nutrition coaching - “AI-enhanced” sleep tracking - “AI-personalized” meditation\nThe pattern is clear: adding “AI” to your app: - Justifies higher subscription prices (Calm is $70/year) - Makes the app sound more sophisticated - Appeals to tech-forward users - Differentiates from free alternatives\n\n\nWhat’s Probably Happening\nMost “AI personalization” in wellness apps is likely: - Simple if-then logic based on user inputs - Random content rotation to create variety - Basic categorization (stress → stress content) - A/B testing to optimize engagement (not personalization)\nThese are useful features, but they’re not AI in any meaningful sense.\n\n\nThe Premium Price Problem\nCalm charges $70/year partly because of its AI personalization promise. But if the personalization isn’t real, you’re paying a premium for: - A nice UI - Good production quality - Convenient access to meditation content\nThese are fine features, but they don’t require AI or justify the AI marketing."
  },
  {
    "objectID": "posts/016_/016.html#did-it-actually-help-with-stress",
    "href": "posts/016_/016.html#did-it-actually-help-with-stress",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "Did It Actually Help With Stress?",
    "text": "Did It Actually Help With Stress?\n\nThe Honest Assessment\nYes, using Calm helped me feel less stressed during recruiting season. But I’m pretty sure this had nothing to do with AI:\nMeditation works: Taking 10 minutes to breathe and focus helps reduce stress. This is true whether you use a paid app, YouTube, or just sit quietly.\nGuided instruction helps: Having someone guide you through meditation is easier than doing it alone, especially as a beginner. But good instruction doesn’t require AI.\nConvenience matters: Having all meditations in one app makes it more likely I’ll actually do it. But this is about app design, not AI.\nReminder system: The daily notifications helped build a habit. Again, not AI—just push notifications.\n\n\nWould Free Alternatives Work as Well?\nProbably yes. The benefit came from: 1. Deciding to prioritize meditation during a stressful period 2. Having accessible guided content 3. Following through consistently\nNone of this required Calm specifically or its “AI” features.\n\n\nThe Placebo Question\nThere’s a possibility that believing the app is “personalized” makes it more effective through placebo effect. If you think the AI is customizing meditations for your specific needs, you might engage more seriously.\nBut this raises an ethical question: should companies charge premium prices for placebo effects based on false AI claims?"
  },
  {
    "objectID": "posts/016_/016.html#should-you-use-ai-meditation-apps",
    "href": "posts/016_/016.html#should-you-use-ai-meditation-apps",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "Should You Use AI Meditation Apps?",
    "text": "Should You Use AI Meditation Apps?\n\nUse Them If:\n\nYou want convenient access to guided meditation\nYou find the UI and production quality motivating\nYou’re willing to pay for convenience\nYou need variety in meditation styles\n\nBut don’t pay extra for “AI personalization” that probably isn’t real.\n\n\nSkip Them If:\n\nYou’re comfortable finding free meditations on YouTube/Spotify\nYou don’t need an app to motivate practice\nYou’re skeptical of premium subscription prices\n\n\n\nBetter Approaches:\nTry free options first: Use YouTube or free apps (Insight Timer, UCLA Mindful) to see if guided meditation helps you.\nManual personalization: Pay attention to which meditation styles, lengths, and times of day work best for you. This is better personalization than any AI.\nFocus on consistency over features: The best meditation app is the one you’ll actually use. Fancy AI features don’t matter if you don’t build a habit.\nQuestion the AI label: When any wellness app claims AI, ask: “What is the AI actually doing that couldn’t be done with basic programming?”"
  },
  {
    "objectID": "posts/016_/016.html#final-thoughts",
    "href": "posts/016_/016.html#final-thoughts",
    "title": "AI Meditation Apps: Is the Personalization Real?",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCalm is a well-designed meditation app with good content. The guided meditations helped me manage stress during a busy recruiting and school period.\nBut the “AI personalization” appears to be marketing rather than meaningful technology. After a week of use and deliberate testing, I saw no evidence that the app was learning my preferences or adapting recommendations based on my behavior.\nThe recommendations seemed to come from: - My initial survey answers (static profile) - Content rotation (showing variety) - Basic category matching\nThis isn’t AI—it’s a preference quiz with some randomization.\nFor people who find Calm helpful and are willing to pay, that’s fine. The app has value. But it’s worth being clear about what you’re paying for: convenient access to quality meditation content, not AI-powered personalization.\nAs wellness apps increasingly add “AI” to their marketing, we should be skeptical. Real AI personalization would show measurable adaptation over time. Most apps, including Calm, don’t demonstrate this.\nThe meditation helped with my recruiting stress. The AI claims? Those just stressed me out more."
  },
  {
    "objectID": "posts/023_/023.html",
    "href": "posts/023_/023.html",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "",
    "text": "For my Marketing and Creativity class, I needed to create advertising concepts for “Bulby” - a climate-responsive smart lightbulb. The product isn’t real. I needed mockups showing what the campaigns would look like.\nI used Google DeepMind’s Veo to generate the visuals."
  },
  {
    "objectID": "posts/023_/023.html#the-assignment-advertise-a-product-that-doesnt-exist",
    "href": "posts/023_/023.html#the-assignment-advertise-a-product-that-doesnt-exist",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "",
    "text": "For my Marketing and Creativity class, I needed to create advertising concepts for “Bulby” - a climate-responsive smart lightbulb. The product isn’t real. I needed mockups showing what the campaigns would look like.\nI used Google DeepMind’s Veo to generate the visuals."
  },
  {
    "objectID": "posts/023_/023.html#what-i-needed",
    "href": "posts/023_/023.html#what-i-needed",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "What I Needed",
    "text": "What I Needed\nTwo campaign concepts:\nPhysical: Times Square billboard showing “It’s hot, Bulby” - using extreme heat as contrast to the product’s climate awareness\nDigital: Social media ad showing “It’s cold, Bulby” - clean, modern living room with the lightbulb responding to temperature\nPhotoshop would take hours. Hiring a designer costs money I don’t have. Veo generated both in 20 minutes."
  },
  {
    "objectID": "posts/023_/023.html#what-worked",
    "href": "posts/023_/023.html#what-worked",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "What Worked",
    "text": "What Worked\n\nThe Times Square Billboard\nPrompt: “Large billboard in Times Square showing a glowing smart lightbulb with text ‘It’s hot, Bulby’ - evening, city lights, realistic”\nVeo nailed the environmental context. The billboard looked like it belonged there. Lighting, perspective, urban density - all correct.\n\n\nThe Living Room Scene\nPrompt: “Modern minimalist living room, large windows, smart lightbulb visible with temperature icon, text ‘It’s cold, Bulby’ - bright natural lighting”\nClean, professional, Instagram-ready aesthetic. Exactly what I needed for a social media mockup."
  },
  {
    "objectID": "posts/023_/023.html#what-didnt-work",
    "href": "posts/023_/023.html#what-didnt-work",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "What Didn’t Work",
    "text": "What Didn’t Work\n\nText Rendering\nVeo can’t do text reliably. “It’s hot, Bulby” came out garbled half the time. I had to regenerate 6-8 times per image.\n\n\nProduct Details\nThe lightbulb design kept changing. I needed consistency across campaigns but Veo generated different bulb shapes each time.\nI ended up overlaying the same product image manually in post.\n\n\nBrand Consistency\nColors, fonts, styling - all inconsistent between generations. AI doesn’t understand brand guidelines."
  },
  {
    "objectID": "posts/023_/023.html#what-this-actually-replaced",
    "href": "posts/023_/023.html#what-this-actually-replaced",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "What This Actually Replaced",
    "text": "What This Actually Replaced\nNot: Creative direction, concept development, copywriting\nYes: Stock photography, staging physical mockups, hiring a designer for proof-of-concept\nI already knew what I wanted the ads to look like. Veo let me visualize concepts fast enough to iterate.\nFor a class project where the point is the marketing strategy, not the production quality, this worked fine."
  },
  {
    "objectID": "posts/023_/023.html#when-ai-mockups-make-sense",
    "href": "posts/023_/023.html#when-ai-mockups-make-sense",
    "title": "AI-Generated Advertising Mockups: Veo for Product Concepts",
    "section": "When AI Mockups Make Sense",
    "text": "When AI Mockups Make Sense\nGood for: - Proof-of-concept visuals - Class assignments where execution isn’t the focus - Testing multiple creative directions quickly - Environmental context (cityscapes, interiors)\nNot good for: - Final production assets - Consistent product rendering - Text and typography - Brand guidelines adherence\nI got mockups good enough to present the advertising strategy. That’s all I needed.\nThe product concept mattered more than pixel-perfect execution."
  },
  {
    "objectID": "posts/026_/026.html",
    "href": "posts/026_/026.html",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "",
    "text": "I’m traveling to Japan December 13-23. I wanted an itinerary focused on architecture, design, and niche culinary experiences. I tried ChatGPT first.\nIt didn’t work."
  },
  {
    "objectID": "posts/026_/026.html#the-problem-planning-a-11-day-japan-trip",
    "href": "posts/026_/026.html#the-problem-planning-a-11-day-japan-trip",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "",
    "text": "I’m traveling to Japan December 13-23. I wanted an itinerary focused on architecture, design, and niche culinary experiences. I tried ChatGPT first.\nIt didn’t work."
  },
  {
    "objectID": "posts/026_/026.html#what-i-asked-chatgpt",
    "href": "posts/026_/026.html#what-i-asked-chatgpt",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "What I Asked ChatGPT",
    "text": "What I Asked ChatGPT\n“Plan a 11-day Japan itinerary (Dec 13-23) focused on: - Modern architecture and design - Niche culinary spots (not tourist traps) - Efficient train routes between cities”\nChatGPT generated a detailed day-by-day plan with recommendations, transit times, and restaurant suggestions.\nOn paper, it looked perfect."
  },
  {
    "objectID": "posts/026_/026.html#what-went-wrong",
    "href": "posts/026_/026.html#what-went-wrong",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "What Went Wrong",
    "text": "What Went Wrong\n\nTrain Dates Were Wrong\nChatGPT suggested specific trains and departure times. When I checked the actual JR schedules, half the trains didn’t run on those dates or times.\nI would’ve missed connections if I’d trusted the itinerary blindly.\n\n\nIt Missed My Vibe Completely\nWhat I wanted: Tadao Ando buildings, small design shops, local izakayas recommended by residents\nWhat ChatGPT gave me: Tokyo Skytree, Senso-ji Temple, Tsukiji Fish Market - all mainstream tourist spots\nThe recommendations weren’t wrong. They just weren’t mine.\n\n\nThe Culinary Suggestions Were Generic\nChatGPT recommended well-known ramen chains and Michelin-starred restaurants. Nothing niche. Nothing local.\nWhen I asked for “hidden gem food spots,” it gave me places with 10,000+ Google reviews.\n\n\nThe Outputs Were Overwhelming\nEach day had 8-10 activities listed with paragraph descriptions. Reading through it felt like homework.\nI couldn’t see the flow of the trip. Just a wall of text with too many options."
  },
  {
    "objectID": "posts/026_/026.html#what-actually-worked",
    "href": "posts/026_/026.html#what-actually-worked",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "What Actually Worked",
    "text": "What Actually Worked\nI ended up using:\nTikTok and YouTube: Locals and frequent travelers showing actual spots. I found a tiny coffee shop in Kyoto that specializes in architecture books, a hidden kaiseki restaurant in Osaka, and a design district ChatGPT never mentioned.\nGoogle Maps + Word of Mouth: I searched for “architecture” near areas I was already visiting. User reviews from real people who’d been there recently.\nTravel blogs by residents: Japanese design blogs and expat food guides gave me the niche spots AI couldn’t.\nManual train checking: I verified every train route on the actual JR website. Time-consuming but necessary."
  },
  {
    "objectID": "posts/026_/026.html#why-ai-itinerary-planning-failed",
    "href": "posts/026_/026.html#why-ai-itinerary-planning-failed",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "Why AI Itinerary Planning Failed",
    "text": "Why AI Itinerary Planning Failed\n\nIt Optimizes for Popularity, Not Preference\nChatGPT recommends places that appear frequently in its training data - which means tourist-heavy spots dominate.\nNiche recommendations require local knowledge AI doesn’t have.\n\n\nIt Can’t Verify Real-Time Information\nTrain schedules change. Restaurants close. Events get canceled. AI doesn’t know this.\nIt generates confident answers based on outdated data.\n\n\nIt Doesn’t Understand “Vibe”\nI can tell ChatGPT I like “architecture and design,” but it can’t distinguish between: - A famous building everyone photographs - A quiet neighborhood with innovative residential projects\nThat nuance requires human curation."
  },
  {
    "objectID": "posts/026_/026.html#when-ai-itinerary-tools-might-work",
    "href": "posts/026_/026.html#when-ai-itinerary-tools-might-work",
    "title": "I Used ChatGPT to Plan My Japan Trip - It Wasn’t Helpful",
    "section": "When AI Itinerary Tools Might Work",
    "text": "When AI Itinerary Tools Might Work\nGood for: - High-level structure (how many days in each city) - General logistics (visa requirements, currency, weather) - First-time travelers who want mainstream highlights\nNot good for: - Niche interests - Real-time transit schedules - Finding hidden local spots - Balancing pacing and downtime\nI spent 3 hours with ChatGPT and got an unusable itinerary. I spent 5 hours manually researching and got a trip I’m actually excited about.\nThe extra time mattered. AI gave me efficiency. Manual research gave me a trip that fits who I am."
  },
  {
    "objectID": "posts/017_/017.html",
    "href": "posts/017_/017.html",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "",
    "text": "For my Marketing 7340 class with Dr. Gideon Nave, I needed to create original music for a Corona ad campaign. The problem: I have no formal music production training. The solution: Suno AI, a tool that generates music from text prompts and voice recordings.\nI paid $10/month for Suno Pro to test whether AI could actually produce usable marketing music. Here’s what happened.\n\nSuno AI’s music generation interface"
  },
  {
    "objectID": "posts/017_/017.html#making-music-without-musical-training",
    "href": "posts/017_/017.html#making-music-without-musical-training",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "",
    "text": "For my Marketing 7340 class with Dr. Gideon Nave, I needed to create original music for a Corona ad campaign. The problem: I have no formal music production training. The solution: Suno AI, a tool that generates music from text prompts and voice recordings.\nI paid $10/month for Suno Pro to test whether AI could actually produce usable marketing music. Here’s what happened.\n\nSuno AI’s music generation interface"
  },
  {
    "objectID": "posts/017_/017.html#the-assignment-corona-ad-music",
    "href": "posts/017_/017.html#the-assignment-corona-ad-music",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "The Assignment: Corona Ad Music",
    "text": "The Assignment: Corona Ad Music\nBrief: - Concept: Funky, Latin, afrohouse beat that inspires dancing - Instruments: Drums, trumpets, soothing vocals - Inspiration: Barry Can’t Swim style - Tempo: 120-140 BPM - Purpose: Corona advertisement - Mood: Beach resort, enjoyment, refreshing, sunbathed\nLyrics concept:\n[Chorus]\nChasing the sun\nChasing the glow\nWhere the ocean whispers what we already know\nWith a Corona in hand\nTime comes undone\nLiving the moment\nChasing the sun\nListen to the Corona ad track"
  },
  {
    "objectID": "posts/017_/017.html#how-suno-actually-works",
    "href": "posts/017_/017.html#how-suno-actually-works",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "How Suno Actually Works",
    "text": "How Suno Actually Works\n\nVoice Recording as Foundation\nI started by recording my own voice singing low and high tones. Suno used this as the base vocal texture and extended it into a full track. This “cover” feature lets you input raw vocals that the AI then transforms.\n\n\nLyrics Generation and Editing\nSuno has a lyrics generator, but I quickly learned the AI-generated lyrics were generic. I used the generator as a starting point, then heavily edited:\nOriginal AI lyrics: Standard party/dance themes My edits (in bold): Added specific production notes like: - [Add intense percussion] - [Add marimbas and bongos] - [Make it hypnotic] - [Build anticipation, create anxiety and excitement for the chorus]\n\n\nStyle Prompting\nThe key to good output was detailed style prompts:\n140bpm. Deephouse, melodic, hypnotic. \nAdd layers of organic, progressive house elements. \nAdd unexpected elements. \nUse Rufus Du Sol as inspiration.\n\nEditing lyrics and adding production notes in Suno"
  },
  {
    "objectID": "posts/017_/017.html#the-iteration-process",
    "href": "posts/017_/017.html#the-iteration-process",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "The Iteration Process",
    "text": "The Iteration Process\n\nFirst Attempt: Complete Failure\nMy initial generated song was terrible. The AI-generated lyrics were cliché, the production was muddy, and it didn’t capture the vibe I wanted at all.\nWhat went wrong: - Generic party lyrics that felt empty - Overproduced sound that lost the organic beach feel - Wrong energy—too aggressive, not relaxed enough\nI realized I needed to be much more specific in my prompts.\n\n\nSecond Attempt: Rufus Du Sol Inspiration\nI prompted: “Change the lyrics to be more Rufus Du Sol-like.”\nThen I restructured the entire song with detailed production notes:\n[Intro - Another Voice, Raspy Voice]\n[Add ethereal synths and deep bass]\n(Ahora)\nEl viaje empieza\n[Make pause for drop]\n\n[Verse 1 - Another Voice, drop here]\nLa atmósfera te abraza, ¿la notas?\nFluye conmigo, sin pausa, sin sombras\n\n[Another pause, longer]\n[Build anticipation, create anxiety and excitement \nfor the chorus with drums, marimbas, bongos, and trumpets. \nVery light instrumental at the beginning.]\n\n[Chorus - Main Voice]\nLet the waves of sound enfold\nWe're captive, our spirits bold\nThis version was better. The AI actually responded to the detailed production notes and created more dynamic arrangements.\nListen to the Rufus-inspired version\n\n\nThird Attempt: Corona Ad Track\nFor the final Corona track, I stripped down the complexity and focused on the beach resort vibe: - Simpler, more direct lyrics about “chasing the sun” - Specific instrument calls (trumpets, drums) - Barry Can’t Swim inspiration for that organic house feel - Tempo locked at 120-140 BPM\nThis was the most successful version."
  },
  {
    "objectID": "posts/017_/017.html#what-actually-works",
    "href": "posts/017_/017.html#what-actually-works",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "What Actually Works",
    "text": "What Actually Works\n\nSpecificity in Prompts\nVague prompts like “make happy music” produce generic results. Detailed prompts with: - Specific BPM - Named artist references - Exact instruments - Production technique descriptions\n…produce much better output.\n\n\nProduction Notes Within Lyrics\nThe bracketed production notes [Add trumpet solo] or [Build anticipation] actually work. Suno interprets these and adjusts the arrangement accordingly.\n\n\nVoice Input as Foundation\nRecording my own voice gave the track a unique texture. Even though the AI heavily processed it, there’s something more authentic than purely synthetic vocals.\n\n\nIteration Is Essential\nThe first output is never good. You need multiple generations, tweaking prompts each time based on what worked and what didn’t."
  },
  {
    "objectID": "posts/017_/017.html#serious-limitations",
    "href": "posts/017_/017.html#serious-limitations",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "Serious Limitations",
    "text": "Serious Limitations\n\nLack of Fine Control\nYou can suggest instruments and styles, but you can’t control: - Exact timing of drops or builds - Precise mixing levels - Specific chord progressions - Individual track editing\nA real producer would have much more granular control.\n\n\nInconsistent Output Quality\nEven with the same prompt, Suno generates wildly different results. Sometimes it nails the vibe, sometimes it completely misses. You’re rolling the dice each generation.\n\n\nGeneric Elements\nDespite specific prompts, certain elements always sound “AI-generated”: - Vocal processing has a distinctive Suno quality - Transitions can feel abrupt or unnatural - Complex arrangements often get muddied\n\n\nLimited Musical Understanding\nSuno doesn’t understand music theory deeply. If you ask for a specific harmonic progression or complex rhythmic pattern, it might approximate but not execute precisely.\n\n\nCopyright and Licensing Questions\nFor a real commercial project (like an actual Corona ad), there are murky questions: - Who owns the rights to AI-generated music? - Can you legally use Suno output in paid advertising? - What happens if the AI “learned” from copyrighted material?\nFor a class project this is fine, but for real commercial use, these are unresolved issues."
  },
  {
    "objectID": "posts/017_/017.html#is-10month-worth-it",
    "href": "posts/017_/017.html#is-10month-worth-it",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "Is $10/Month Worth It?",
    "text": "Is $10/Month Worth It?\n\nWhat You Get with Suno Pro\n\nMore generation credits per month\nHigher quality audio output\nCommercial use rights (with caveats)\nFaster generation times\n\n\n\nFor This Assignment: Yes\nFor a marketing class project where I needed original music quickly, \\(10 was worth it. The alternative would be:\n- Learning actual music production (months/years)\n- Hiring a producer (\\)hundreds to $thousands) - Using stock music (doesn’t fit specific brief)\n\n\nFor Serious Music Production: No\nIf you’re actually trying to produce professional music, Suno is a novelty, not a tool. The limitations are too significant, and the output quality isn’t competitive with human-produced tracks.\n\n\nThe Real Use Case\nSuno is best for: - Rapid prototyping of musical ideas - Creating placeholder tracks for projects - Generating inspiration for actual musicians - Quick demos for pitches or presentations\nIt’s not a replacement for music production, but it’s a useful sketching tool."
  },
  {
    "objectID": "posts/017_/017.html#what-this-means-for-marketing",
    "href": "posts/017_/017.html#what-this-means-for-marketing",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "What This Means for Marketing",
    "text": "What This Means for Marketing\n\nDemocratization of Content Creation\nTools like Suno lower the barrier to creating original audio content. Small brands or student projects can now generate custom music without big budgets.\n\n\nQuality vs. Cost Tradeoff\nThe output isn’t professional-grade, but it’s “good enough” for many contexts: - Social media content - Internal presentations - Pitch decks - Testing concepts before investing in production\n\n\nThe Authenticity Question\nIf audiences knew the Corona ad used AI-generated music, would they care? Would it affect brand perception?\nThis is an open question in marketing. Some consumers might appreciate the innovation; others might see it as cheap or inauthentic.\n\n\nProfessional Musicians’ Concern\nFrom a music industry perspective, tools like Suno are concerning. If brands can generate “good enough” music for $10/month, that undercuts professional composers and producers.\nThe counterargument: truly great music still requires human creativity, and AI tools might just handle the low-end market that wasn’t hiring professionals anyway."
  },
  {
    "objectID": "posts/017_/017.html#final-assessment",
    "href": "posts/017_/017.html#final-assessment",
    "title": "Creating Music with AI: Suno for Marketing Projects",
    "section": "Final Assessment",
    "text": "Final Assessment\nSuno AI successfully generated usable music for my marketing class project. The Corona ad track captured the beach resort vibe and had the right energy for the brief.\nBut the process revealed clear limitations: - Heavy iteration required (first attempts were unusable) - Lack of fine control over production elements - Output has distinctive “AI” quality - Not suitable for professional commercial use\nFor class projects and rapid prototyping: Suno is genuinely useful. It lets you explore musical ideas quickly without technical skills.\nFor real marketing campaigns: You’d still want a human producer. The AI can generate ideas or placeholder tracks, but the final product needs human refinement.\nThe $10/month was worth it for this specific use case, but I’m canceling the subscription after the project ends. It’s a tool I needed temporarily, not something I’d use regularly.\nMost importantly: AI music generation is impressive technically, but it highlights what human musicians bring—intentionality, emotional depth, and creative choices that respond to cultural context in ways algorithms can’t replicate.\nThe Corona ad track works for a student project. But Corona the actual company? They’re still hiring real composers."
  }
]