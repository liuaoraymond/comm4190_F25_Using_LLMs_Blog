[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What Can You Do With AI",
    "section": "",
    "text": "Let’s Find Out\n\nExploring AI in daily life\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow AI Really Works: Beyond the Magic\n\n\n\nAI\n\ndeep-dive\n\ntechnology\n\n\n\nA deep dive into the mechanics and reality behind artificial intelligence systems\n\n\n\n\n\nSep 3, 2025\n\n\nRaymond Liu Ao\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html",
    "href": "posts/000_How_Does_AI_Really_Work/index.html",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "",
    "text": "Artificial Intelligence feels like magic. You ask ChatGPT a question, and it responds with human-like intelligence. You show DALL-E a text prompt, and it creates art. But here’s the uncomfortable truth: there’s no actual intelligence happening here.\nWhat we call “AI” is really an incredibly sophisticated pattern matching system—one that’s so good at finding and reproducing patterns that it can fool us into thinking it understands. Today, we’re going to pull back the curtain and examine exactly how these systems work.\n AI neural networks mimic brain structure but work very differently under the hood\n\nKey Question: If AI doesn’t truly “think,” why does it seem so smart?"
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#the-great-ai-illusion",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#the-great-ai-illusion",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "",
    "text": "Artificial Intelligence feels like magic. You ask ChatGPT a question, and it responds with human-like intelligence. You show DALL-E a text prompt, and it creates art. But here’s the uncomfortable truth: there’s no actual intelligence happening here.\nWhat we call “AI” is really an incredibly sophisticated pattern matching system—one that’s so good at finding and reproducing patterns that it can fool us into thinking it understands. Today, we’re going to pull back the curtain and examine exactly how these systems work.\n AI neural networks mimic brain structure but work very differently under the hood\n\nKey Question: If AI doesn’t truly “think,” why does it seem so smart?"
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#the-mathematical-foundation-its-all-about-prediction",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#the-mathematical-foundation-its-all-about-prediction",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "The Mathematical Foundation: It’s All About Prediction",
    "text": "The Mathematical Foundation: It’s All About Prediction\nAt its core, every AI system is trying to solve one fundamental problem: given some input, predict the most likely output. Whether it’s predicting the next word in a sentence, the next pixel in an image, or the next move in a game, AI is fundamentally a prediction engine.\n\nThe Architecture of Modern AI\nModern AI systems, particularly large language models like GPT-4 or Claude, are built on an architecture called transformers. Here’s how they work:\n# Simplified transformer logic\ndef transformer_prediction(input_text):\n    tokens = tokenize(input_text)  # Break text into pieces\n    embeddings = convert_to_vectors(tokens)  # Convert to numbers\n    \n    for layer in neural_layers:\n        embeddings = attention_mechanism(embeddings)  # Find relationships\n        embeddings = feed_forward(embeddings)  # Process patterns\n    \n    return predict_next_token(embeddings)  # Guess what comes next\n The transformer architecture that powers modern AI - layers of attention and processing\nThe scale of modern AI is staggering. GPT-3 has 175 billion parameters and was trained on 45TB of text data at a cost of around $4.6 million. GPT-4 is estimated to have over 1 trillion parameters with training costs exceeding $60 million.\n\n\nThe Attention Mechanism: How AI “Focuses”\nThe breakthrough that made modern AI possible was the attention mechanism. This allows models to selectively focus on different parts of their input when making predictions.\nThink of attention like a spotlight that can illuminate different parts of a sentence based on context:\nExample: “The cat sat on the mat because it was comfortable.”\nWhen predicting what “it” refers to, the attention mechanism looks at: - “cat” (high attention - 0.7) - “mat” (medium attention - 0.2) - “sat” (low attention - 0.1)\nThis attention mechanism allows AI to understand relationships between words that are far apart in a sentence, enabling more sophisticated language understanding."
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#the-training-process-teaching-patterns-at-scale",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#the-training-process-teaching-patterns-at-scale",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "The Training Process: Teaching Patterns at Scale",
    "text": "The Training Process: Teaching Patterns at Scale\nUnderstanding how AI systems learn is crucial to understanding their capabilities and limitations. The training process happens in distinct phases:\n The complete pipeline from raw data to deployed AI system\n\nPhase 1: Pre-training (Learning the World)\nImagine you had to read the entire internet and predict what comes next in every sentence. That’s essentially what happens during pre-training:\n\nData Collection: Scrape massive amounts of text from websites, books, articles\nTokenization: Break everything into small chunks (words, parts of words, punctuation)\nPrediction Training: For every sequence, hide the last word and train the model to predict it\nRepeat Trillions of Times: Adjust internal parameters based on prediction accuracy\n\n# Simplified training loop\nfor epoch in range(many_epochs):\n    for text_chunk in massive_dataset:\n        input_tokens = text_chunk[:-1]  # All but last token\n        target_token = text_chunk[-1]   # The token to predict\n        \n        prediction = model(input_tokens)\n        loss = calculate_error(prediction, target_token)\n        \n        # Adjust model weights to reduce error\n        model.update_weights(loss.gradient())\n\n\nPhase 2: Fine-tuning (Learning to be Helpful)\nRaw pre-training creates a model that can continue any text, but it doesn’t necessarily produce helpful responses. Fine-tuning shapes the model’s behavior:\n\nSupervised Fine-tuning: Train on high-quality question-answer pairs\nReinforcement Learning from Human Feedback (RLHF): Use human preferences to reward good responses\nConstitutional AI: Train the model to follow principles and avoid harmful outputs\n\nThis is why ChatGPT feels helpful and conversational, while a raw language model might just continue your sentence in unexpected ways."
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#emergent-abilities-when-simple-rules-create-complex-behavior",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#emergent-abilities-when-simple-rules-create-complex-behavior",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "Emergent Abilities: When Simple Rules Create Complex Behavior",
    "text": "Emergent Abilities: When Simple Rules Create Complex Behavior\nOne of the most fascinating aspects of large AI models is emergence—complex capabilities that weren’t explicitly programmed but arise from the interaction of simple components at scale.\n\nExamples of Emergent Abilities\nAs models get larger, they suddenly develop new capabilities:\nChain-of-Thought Reasoning: Models learn to “think step by step” without being explicitly taught this strategy.\nIn-Context Learning: Models can learn new tasks from just a few examples in the prompt, without any additional training.\n# Example of in-context learning\nprompt = \"\"\"\nTranslate English to French:\nHello → Bonjour\nGoodbye → Au revoir\nThank you → Merci\nGood morning → \n\"\"\"\n\n# Model predicts \"Bonjour\" despite never being\n# explicitly trained on this translation task\nCross-Lingual Transfer: Models trained primarily on English can perform well in other languages.\nScientists still don’t fully understand why emergence happens. Leading theories include phase transitions (like water becoming ice), increased representational capacity, and “grokking”—when models suddenly understand patterns after seeing enough examples."
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#the-fundamental-limitations-what-ai-cant-do",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#the-fundamental-limitations-what-ai-cant-do",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "The Fundamental Limitations: What AI Can’t Do",
    "text": "The Fundamental Limitations: What AI Can’t Do\nDespite their impressive capabilities, current AI systems have fundamental limitations that stem from their architecture:\n Understanding what AI can and cannot reliably do\n\n1. No True Understanding\nAI systems manipulate symbols without understanding their meaning. They’re like a person who can perfectly reproduce Chinese characters without speaking Chinese.\nExample: An AI can tell you that “water boils at 100°C” but doesn’t understand what boiling actually is—the molecular motion, the phase change, the physical reality behind the words.\n\n\n2. Hallucination and Confabulation\nBecause AI systems are trained to always produce output, they’ll generate plausible-sounding but false information when they don’t know something.\n# What happens inside when AI doesn't know\ndef generate_response(query):\n    if confidence_score &gt; threshold:\n        return known_information(query)\n    else:\n        # Problem: AI still tries to respond!\n        return generate_plausible_sounding_answer(query)\n\n\n3. Training Data Cutoff\nAI models are frozen in time at their training cutoff. They can’t learn new information or update their knowledge without retraining.\n\n\n4. Context Window Limitations\nCurrent models can only “remember” a limited amount of recent conversation (typically 4,000-128,000 tokens). They have no long-term episodic memory.\n\n\n5. Lack of Causal Understanding\nAI systems excel at finding correlations but struggle with causation. They might notice that umbrella sales correlate with rain but don’t understand that rain causes people to buy umbrellas."
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#what-this-means-for-society",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#what-this-means-for-society",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "What This Means for Society",
    "text": "What This Means for Society\nUnderstanding how AI really works has profound implications for how we should think about and use these systems:\n\nThe Good News\n\nPowerful Tools: AI systems are incredibly useful for pattern recognition, content generation, and automation\nDemocratization: Complex capabilities are becoming accessible to everyone\nAugmentation: AI can enhance human capabilities rather than replace human judgment\n\n\n\nThe Concerning News\n\nOverconfidence: AI systems present uncertain information with false confidence\nBias Amplification: Training on internet data amplifies existing societal biases\nMisinformation: Sophisticated text generation can create convincing but false content\n\n\n\nBest Practices for AI Use\n\nVerify Important Information: Always fact-check AI outputs for critical decisions\nUnderstand Limitations: Know what AI can and cannot do reliably\nMaintain Human Oversight: Keep humans in the loop for important judgments\nRecognize Bias: Be aware that AI systems reflect training data biases\nUse as a Tool: Treat AI as a sophisticated calculator, not an oracle"
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#the-future-whats-next",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#the-future-whats-next",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "The Future: What’s Next?",
    "text": "The Future: What’s Next?\nCurrent AI represents just the beginning. Several developments on the horizon could dramatically change the landscape:\n\nNear-Term Developments (1-3 years)\n\nMultimodal Integration: AI that seamlessly combines text, images, audio, and video\nLonger Context Windows: Models that can “remember” entire books or conversations\nBetter Reasoning: Improved step-by-step problem-solving capabilities\nSpecialized Models: AI systems optimized for specific domains (medicine, law, science)\n\n\n\nLong-Term Questions (10+ years)\n\nArtificial General Intelligence (AGI): AI that matches human cognitive abilities across all domains\nConsciousness: Whether AI systems can develop subjective experiences\nAlignment: Ensuring advanced AI systems remain beneficial to humanity\n\n\n\nThe Research Frontiers\nScientists are actively working on fundamental questions:\n\nScaling Laws: How do capabilities change with model size, data, and compute?\nEmergence: Why do new abilities suddenly appear at certain scales?\nAlignment: How do we ensure AI systems do what we want them to do?\nInterpretability: Can we understand what’s happening inside these black boxes?"
  },
  {
    "objectID": "posts/000_How_Does_AI_Really_Work/index.html#conclusion-intelligence-vs.-sophistication",
    "href": "posts/000_How_Does_AI_Really_Work/index.html#conclusion-intelligence-vs.-sophistication",
    "title": "How AI Really Works: Beyond the Magic",
    "section": "Conclusion: Intelligence vs. Sophistication",
    "text": "Conclusion: Intelligence vs. Sophistication\nAfter peeling back the layers, we can see that current AI systems are incredibly sophisticated pattern-matching engines rather than truly intelligent entities. They don’t understand the world in the way humans do—they manipulate symbols based on statistical relationships learned from vast amounts of data.\nBut here’s the remarkable thing: this statistical approach is powerful enough to seem intelligent. By processing patterns at unprecedented scale, these systems can engage in conversations, solve problems, and create content that feels genuinely intelligent.\n\nThe Paradox of AI\nThe central paradox of modern AI is that it achieves intelligence-like behavior without intelligence-like understanding. This has profound implications:\n\nFor Users: We must learn to work with these systems’ strengths while compensating for their weaknesses\nFor Society: We need new frameworks for thinking about machine capabilities and limitations\nFor the Future: We must grapple with questions about consciousness, agency, and what it means to be intelligent\n\nUnderstanding how AI really works doesn’t diminish its impressiveness—if anything, it makes the achievement more remarkable. The fact that statistical pattern matching at scale can produce such sophisticated behavior suggests that intelligence itself might be more about information processing patterns than we previously thought.\nAs these systems become more powerful and ubiquitous, our understanding of their true nature becomes increasingly important. The more we know about how AI works, the better we can harness its benefits while avoiding its pitfalls.\nThe AI revolution is just beginning, and we’re all learning to navigate this new landscape together. By understanding the reality behind the magic, we can make better decisions about how to integrate these powerful tools into our lives and society.\n\nWhat do you think? Does understanding the mechanics behind AI change how you view these systems? Let me know your thoughts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "What Can You Do With AI?"
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "About",
    "section": "",
    "text": "What Can You Do With AI?"
  },
  {
    "objectID": "about.html#raymond-liu-ao",
    "href": "about.html#raymond-liu-ao",
    "title": "About",
    "section": "Raymond Liu Ao",
    "text": "Raymond Liu Ao\nOriginally from Lima, Peru, I am a Philosophy, Politics, and Economics (PPE) student at the University of Pennsylvania. Interested in exploring the uses and implications of AI in daily life, this blog discusses how LLM can help us (or not) in commonly encountered scenarios.\n–"
  }
]