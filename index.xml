<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>What Can You Do With AI?</title>
<link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/</link>
<atom:link href="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Let&#39;s Find Out</description>
<generator>quarto-1.8.24</generator>
<lastBuildDate>Sat, 27 Sep 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>AI Photo Organization: Finding Pictures I Forgot I Had</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /008.html</link>
  <description><![CDATA[ 





<section id="searching-through-10000-photos" class="level2">
<h2 class="anchored" data-anchor-id="searching-through-10000-photos">Searching Through 10,000 Photos</h2>
<p>I realized I had over 10,000 photos in Google Photos and no way to find specific ones. Today I tried using the AI search features to locate pictures from last year’s vacation, and it actually worked better than expected.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-search.jpg" class="img-fluid" alt="AI Photo Search"> <em>Google Photos AI recognizing objects, people, and locations</em></p>
</section>
<section id="what-the-ai-can-find" class="level2">
<h2 class="anchored" data-anchor-id="what-the-ai-can-find">What the AI Can Find</h2>
<section id="object-recognition" class="level3">
<h3 class="anchored" data-anchor-id="object-recognition">Object Recognition</h3>
<p>I searched for “pizza” and it found every photo with pizza in it, even ones where pizza was just sitting on a table in the background. Same thing worked for “dog,” “beach,” and “birthday cake.” The AI recognizes way more objects than I expected.</p>
</section>
<section id="face-grouping" class="level3">
<h3 class="anchored" data-anchor-id="face-grouping">Face Grouping</h3>
<p>Google Photos automatically groups photos by faces, so I can find all pictures of specific people without having to manually tag them. It even recognizes people as they age or in different lighting.</p>
</section>
<section id="location-and-time" class="level3">
<h3 class="anchored" data-anchor-id="location-and-time">Location and Time</h3>
<p>If you have location data turned on, you can search by place names. I found all my photos from “San Francisco” or “coffee shop” pretty easily. Time-based searches work too - “photos from summer 2024” pulled up the right time period.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-albums.jpg" class="img-fluid" alt="Auto-Generated Albums"> <em>Automatically created albums based on events and trips</em></p>
</section>
</section>
<section id="automatic-albums" class="level2">
<h2 class="anchored" data-anchor-id="automatic-albums">Automatic Albums</h2>
<section id="trip-detection" class="level3">
<h3 class="anchored" data-anchor-id="trip-detection">Trip Detection</h3>
<p>The AI creates albums for trips automatically based on location and date patterns. It figured out my weekend in Portland and grouped all those photos together without me doing anything.</p>
</section>
<section id="event-recognition" class="level3">
<h3 class="anchored" data-anchor-id="event-recognition">Event Recognition</h3>
<p>It also makes albums for things like “Birthday party” or “Graduation” based on the types of photos and timing. Sometimes it gets it wrong - labeled a regular dinner as a “celebration” - but it’s right more often than not.</p>
</section>
<section id="people-albums" class="level3">
<h3 class="anchored" data-anchor-id="people-albums">People Albums</h3>
<p>Creates collections of photos featuring specific people, which is useful for family pictures or when you want to share photos of someone with them.</p>
</section>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<section id="privacy-concerns" class="level3">
<h3 class="anchored" data-anchor-id="privacy-concerns">Privacy Concerns</h3>
<p>All this convenience requires uploading your photos to Google’s servers where they analyze everything. If that bothers you, you can’t really use these features.</p>
</section>
<section id="sometimes-too-smart" class="level3">
<h3 class="anchored" data-anchor-id="sometimes-too-smart">Sometimes Too Smart</h3>
<p>The AI occasionally creates albums for things that weren’t actually events, or groups random photos together based on superficial similarities.</p>
</section>
<section id="search-isnt-perfect" class="level3">
<h3 class="anchored" data-anchor-id="search-isnt-perfect">Search Isn’t Perfect</h3>
<p>Complex searches don’t always work. “Photos of John at the beach” might miss some or include wrong results. Simple, single-concept searches work much better.</p>
<p>It’s genuinely useful for finding old photos you’d never locate otherwise. The search functionality makes having thousands of photos actually manageable instead of just overwhelming.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>photos</category>
  <category>organization</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /008.html</guid>
  <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-search.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Email Management That Actually Works</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/007.html</link>
  <description><![CDATA[ 





<section id="letting-ai-handle-my-inbox" class="level2">
<h2 class="anchored" data-anchor-id="letting-ai-handle-my-inbox">Letting AI Handle My Inbox</h2>
<p>I set up SaneBox to manage my email and it’s been running for about a week now. Instead of manually sorting through everything, the AI decides what’s important and what can wait.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-inbox-sorting.jpg" class="img-fluid" alt="Smart Inbox Sorting"> <em>AI automatically categorizing emails by priority level</em></p>
</section>
<section id="how-it-sorts-things-out" class="level2">
<h2 class="anchored" data-anchor-id="how-it-sorts-things-out">How It Sorts Things Out</h2>
<section id="priority-filtering" class="level3">
<h3 class="anchored" data-anchor-id="priority-filtering">Priority Filtering</h3>
<p>SaneBox learns from which emails I actually open and respond to. Work emails from my team get flagged as important, while newsletters and promotional stuff gets moved to a separate folder. It’s not perfect but catches most of the obvious stuff.</p>
</section>
<section id="smart-scheduling" class="level3">
<h3 class="anchored" data-anchor-id="smart-scheduling">Smart Scheduling</h3>
<p>Gmail’s AI also suggests response times and can schedule emails to send later. I’ve been using it to send emails during business hours even when I’m working late, so I don’t look like I’m always online.</p>
</section>
<section id="quick-replies" class="level3">
<h3 class="anchored" data-anchor-id="quick-replies">Quick Replies</h3>
<p>The suggested responses are actually useful for simple emails. When someone sends a meeting request, it’ll suggest “Looks good” or “Let me check my calendar” which saves typing the same responses over and over.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-email-responses.jpg" class="img-fluid" alt="Email Response Suggestions"> <em>AI-generated reply suggestions for common email types</em></p>
</section>
</section>
<section id="what-ive-noticed" class="level2">
<h2 class="anchored" data-anchor-id="what-ive-noticed">What I’ve Noticed</h2>
<section id="less-time-sorting" class="level3">
<h3 class="anchored" data-anchor-id="less-time-sorting">Less Time Sorting</h3>
<p>The main benefit is spending less time deciding what to read first. Important emails show up in the main inbox, everything else gets organized automatically.</p>
</section>
<section id="fewer-missed-messages" class="level3">
<h3 class="anchored" data-anchor-id="fewer-missed-messages">Fewer Missed Messages</h3>
<p>Before, urgent emails would get buried under promotional stuff. Now they’re separated, so I’m less likely to miss something important.</p>
</section>
<section id="still-need-to-check" class="level3">
<h3 class="anchored" data-anchor-id="still-need-to-check">Still Need to Check</h3>
<p>The AI sometimes gets it wrong - puts important emails in the low-priority folder or flags spam as urgent. You still need to glance through everything, but it’s more organized.</p>
<p>It’s a decent time-saver for people who get a lot of email. Not life-changing, but removes some of the daily friction of inbox management. The filtering works better than I expected, though you need to train it for a few days before it gets your priorities right.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>productivity</category>
  <category>email</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/007.html</guid>
  <pubDate>Thu, 25 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-inbox-sorting.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Building a Brand with AI: Cuzco Crunch</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/006.html</link>
  <description><![CDATA[ 





<section id="creating-a-brand-with-ai" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-brand-with-ai">Creating a Brand with AI</h2>
<p>Eury and I decided to try building a snack brand called Cuzco Crunch, mostly to see how much of the process we could handle using AI tools. We are just experimenting with what’s possible when you use GPT for everything from naming to packaging concepts.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch.jpg" class="img-fluid" alt="Cuzco Crunch Logo"> <em>Initial logo concepts generated through AI prompting</em></p>
</section>
<section id="what-were-using-ai-for" class="level2">
<h2 class="anchored" data-anchor-id="what-were-using-ai-for">What We’re Using AI For</h2>
<section id="brand-development" class="level3">
<h3 class="anchored" data-anchor-id="brand-development">Brand Development</h3>
<p>The name “Cuzco Crunch” came from asking GPT to suggest names that sounded distinctive but not too weird. We wanted something that hinted at South American flavors without being too on-the-nose. It generated about 30 options and this one felt right.</p>
</section>
<section id="packaging-design-direction" class="level3">
<h3 class="anchored" data-anchor-id="packaging-design-direction">Packaging Design Direction</h3>
<p>We’re using AI to create mood boards and design concepts. Instead of hiring a designer upfront, we’re generating different packaging styles to see what resonates. The AI helps us think through color schemes, typography, and overall brand personality.</p>
</section>
<section id="marketing-copy" class="level3">
<h3 class="anchored" data-anchor-id="marketing-copy">Marketing Copy</h3>
<p>Product descriptions, social media posts, and even this blog post started with AI-generated drafts that we then edited. It’s faster than staring at a blank page, and sometimes the AI suggests angles we wouldn’t have thought of.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch-packaging.jpg" class="img-fluid" alt="Packaging Concepts"> <em>Various packaging design concepts and color schemes</em></p>
</section>
</section>
<section id="whats-working-and-what-isnt" class="level2">
<h2 class="anchored" data-anchor-id="whats-working-and-what-isnt">What’s Working and What Isn’t</h2>
<section id="the-good-stuff" class="level3">
<h3 class="anchored" data-anchor-id="the-good-stuff">The Good Stuff</h3>
<p>Speed is the biggest advantage. We can iterate on ideas quickly without waiting for external feedback or spending money on design consultations. The AI is also good at generating variations - give it one concept and it’ll produce 10 different takes on it.</p>
</section>
<section id="the-limitations" class="level3">
<h3 class="anchored" data-anchor-id="the-limitations">The Limitations</h3>
<p>Everything needs human editing. The AI-generated copy often sounds too generic or tries too hard to be clever. Design concepts look decent but lack the subtle details that make professional packaging stand out on shelves.</p>
<p>Also, the AI doesn’t understand practical constraints. It’ll suggest elaborate packaging designs that would be expensive to produce or flavors that might not actually taste good together.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch-mockups.jpg" class="img-fluid" alt="Package Mockups"> <em>3D mockups and shelf visualization concepts</em></p>
</section>
</section>
<section id="the-reality-check" class="level2">
<h2 class="anchored" data-anchor-id="the-reality-check">The Reality Check</h2>
<section id="still-need-real-skills" class="level3">
<h3 class="anchored" data-anchor-id="still-need-real-skills">Still Need Real Skills</h3>
<p>AI handles the brainstorming and initial concepts, but you still need to understand branding, know your target market, and make business decisions. It’s a tool, not a replacement for actual knowledge about building a brand.</p>
</section>
<section id="cost-vs.-quality-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="cost-vs.-quality-trade-offs">Cost vs.&nbsp;Quality Trade-offs</h3>
<p>We’re probably saving money in the early stages, but there’s a point where you need professional designers and marketers. The question is finding that sweet spot where AI gets you far enough to make informed decisions about what’s worth investing in.</p>
</section>
<section id="learning-experience" class="level3">
<h3 class="anchored" data-anchor-id="learning-experience">Learning Experience</h3>
<p>The most valuable part has been understanding how much work goes into brand development. Using AI to handle the repetitive parts lets us focus on strategy and decision-making instead of getting stuck on execution details.</p>
<p>We’re treating this as an experiment rather than a serious business venture. If Cuzco Crunch turns into something real, great. If not, we’ve learned a lot about using AI for creative projects and brand development.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>branding</category>
  <category>entrepreneurship</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/006.html</guid>
  <pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Fitness Coaching at Home</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/005.html</link>
  <description><![CDATA[ 





<section id="working-out-with-ai-guidance" class="level2">
<h2 class="anchored" data-anchor-id="working-out-with-ai-guidance">Working Out with AI Guidance</h2>
<p>I tried the Freeletics app today instead of going to the gym. It uses your phone’s camera to watch your form and give feedback in real time, which felt like having a trainer watching you.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/ai-form-analysis.jpg" class="img-fluid" alt="AI Form Analysis"> <em>Smartphone analyzing exercise form with real-time feedback</em></p>
</section>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How It Works</h2>
<section id="real-time-form-correction" class="level3">
<h3 class="anchored" data-anchor-id="real-time-form-correction">Real-Time Form Correction</h3>
<p>You prop your phone up and the camera tracks your movements. When I was doing squats, it noticed I wasn’t going low enough and told me to “squat deeper” right as I was doing the exercise. It also caught that I was leaning too far forward.</p>
</section>
<section id="counts-reps-automatically" class="level3">
<h3 class="anchored" data-anchor-id="counts-reps-automatically">Counts Reps Automatically</h3>
<p>The app counts your repetitions so you don’t have to keep track. It only counts reps with proper form, so if your push-up doesn’t go low enough, it won’t count it.</p>
</section>
<section id="adjusts-based-on-performance" class="level3">
<h3 class="anchored" data-anchor-id="adjusts-based-on-performance">Adjusts Based on Performance</h3>
<p>When I started struggling with burpees halfway through, the app suggested switching to a modified version. It seemed to pick up on the fact that my form was getting sloppy and offered an easier variation.</p>
</section>
</section>
<section id="what-works-well" class="level2">
<h2 class="anchored" data-anchor-id="what-works-well">What Works Well</h2>
<section id="form-feedback" class="level3">
<h3 class="anchored" data-anchor-id="form-feedback">Form Feedback</h3>
<p>The corrections are actually helpful. It’s like having someone watch you who knows what proper form looks like. Caught several things I didn’t realize I was doing wrong.</p>
</section>
<section id="no-equipment-needed" class="level3">
<h3 class="anchored" data-anchor-id="no-equipment-needed">No Equipment Needed</h3>
<p>All bodyweight exercises, so you can do it anywhere. The app designs workouts based on what space and time you have available.</p>
</section>
<section id="adapts-to-your-level" class="level3">
<h3 class="anchored" data-anchor-id="adapts-to-your-level">Adapts to Your Level</h3>
<p>Starts with easier exercises and gradually increases difficulty based on how you perform. If you’re struggling, it scales back. If you’re crushing it, it adds more challenging moves.</p>
</section>
<section id="tracks-progress-over-time" class="level3">
<h3 class="anchored" data-anchor-id="tracks-progress-over-time">Tracks Progress Over Time</h3>
<p>Keeps track of how many reps you can do and how your form improves. You can see whether you’re getting stronger or if certain exercises are still difficult.</p>
</section>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<section id="camera-angle-matters" class="level3">
<h3 class="anchored" data-anchor-id="camera-angle-matters">Camera Angle Matters</h3>
<p>You need to position your phone correctly for it to see your whole body. Took a few tries to get the angle right.</p>
</section>
<section id="lighting-requirements" class="level3">
<h3 class="anchored" data-anchor-id="lighting-requirements">Lighting Requirements</h3>
<p>Works better in good lighting. Had trouble tracking movements when the room was too dim.</p>
</section>
<section id="limited-exercise-types" class="level3">
<h3 class="anchored" data-anchor-id="limited-exercise-types">Limited Exercise Types</h3>
<p>Focuses mainly on bodyweight movements. If you want to lift weights or use equipment, you’ll need a different approach.</p>
</section>
<section id="not-always-perfect" class="level3">
<h3 class="anchored" data-anchor-id="not-always-perfect">Not Always Perfect</h3>
<p>Sometimes misses form issues or gives feedback that doesn’t quite match what you’re doing. Still better than working out with no guidance, but not as precise as a human trainer.</p>
<p>It’s a solid option for home workouts when you want some structure and feedback. The form correction feature is genuinely useful, especially for exercises you’re not familiar with.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>fitness</category>
  <category>health</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/005.html</guid>
  <pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/ai-form-analysis.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI-Assisted Grocery Shopping and Meal Prep</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/004.html</link>
  <description><![CDATA[ 





<section id="smarter-grocery-shopping" class="level2">
<h2 class="anchored" data-anchor-id="smarter-grocery-shopping">Smarter Grocery Shopping</h2>
<p>I tried out the AnyList grocery app today and it’s different from just writing things down on paper. Instead of my usual scattered notes and forgotten items, the app organizes everything and suggests what I might need.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/smart-grocery-list.jpg" class="img-fluid" alt="Smart Grocery List"> <em>AI-generated grocery list organized by store layout</em></p>
</section>
<section id="what-it-actually-does" class="level2">
<h2 class="anchored" data-anchor-id="what-it-actually-does">What It Actually Does</h2>
<section id="tracks-what-you-need" class="level3">
<h3 class="anchored" data-anchor-id="tracks-what-you-need">Tracks What You Need</h3>
<p>The app learns from your purchase history and can predict when you’re running low on regular items. It suggested I needed milk and bread this week before I even thought about it. Not perfect, but surprisingly accurate for staples I buy regularly.</p>
</section>
<section id="organizes-by-store-layout" class="level3">
<h3 class="anchored" data-anchor-id="organizes-by-store-layout">Organizes by Store Layout</h3>
<p>Instead of jumping around the store, the list is organized by sections - produce, dairy, meat, etc. Some apps even know the specific layout of stores you frequent, so your list follows the actual aisles.</p>
</section>
<section id="meal-planning-integration" class="level3">
<h3 class="anchored" data-anchor-id="meal-planning-integration">Meal Planning Integration</h3>
<p>You can add meals for the week and it automatically generates ingredient lists. When I planned tacos for Tuesday, it added ground beef, tortillas, and lettuce to my list. It also checked what I already had at home based on recent purchases.</p>
</section>
</section>
<section id="practical-benefits" class="level2">
<h2 class="anchored" data-anchor-id="practical-benefits">Practical Benefits</h2>
<section id="less-time-in-store" class="level3">
<h3 class="anchored" data-anchor-id="less-time-in-store">Less Time in Store</h3>
<p>Following an organized list means less wandering around looking for items. I’ve noticed my shopping trips are about 15-20 minutes shorter.</p>
</section>
<section id="fewer-forgotten-items" class="level3">
<h3 class="anchored" data-anchor-id="fewer-forgotten-items">Fewer Forgotten Items</h3>
<p>The app remembers things I consistently buy but often forget to write down, like batteries or cleaning supplies.</p>
</section>
<section id="better-meal-planning" class="level3">
<h3 class="anchored" data-anchor-id="better-meal-planning">Better Meal Planning</h3>
<p>When you can see ingredient costs upfront, it’s easier to plan meals within budget. The app sometimes suggests cheaper alternatives for expensive items.</p>
</section>
<section id="automatic-coupons" class="level3">
<h3 class="anchored" data-anchor-id="automatic-coupons">Automatic Coupons</h3>
<p>Many apps integrate with store loyalty programs and apply relevant coupons automatically. I’ve saved money without having to hunt for deals.</p>
</section>
</section>
<section id="what-doesnt-work-perfectly" class="level2">
<h2 class="anchored" data-anchor-id="what-doesnt-work-perfectly">What Doesn’t Work Perfectly</h2>
<section id="learning-period" class="level3">
<h3 class="anchored" data-anchor-id="learning-period">Learning Period</h3>
<p>It takes a few weeks for the app to understand your shopping patterns. Early suggestions were often wrong.</p>
</section>
<section id="store-specific-features" class="level3">
<h3 class="anchored" data-anchor-id="store-specific-features">Store-Specific Features</h3>
<p>Advanced features like aisle mapping only work with certain grocery chains. Smaller or independent stores usually don’t have this integration.</p>
</section>
<section id="fresh-produce-timing" class="level3">
<h3 class="anchored" data-anchor-id="fresh-produce-timing">Fresh Produce Timing</h3>
<p>The AI isn’t great at predicting when you need fresh items since it depends on how quickly you use them.</p>
<p>Overall, it’s a useful tool that makes grocery shopping more organized. The meal planning aspect is particularly helpful for busy weeks when you need to think ahead. Not essential, but definitely convenient once you get used to it.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>daily-life</category>
  <category>productivity</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/004.html</guid>
  <pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/smart-fridge-inventory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Research with Perplexity AI</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/003.html</link>
  <description><![CDATA[ 





<section id="using-ai-for-research" class="level2">
<h2 class="anchored" data-anchor-id="using-ai-for-research">Using AI for Research</h2>
<p>I’ve been trying out Perplexity AI for research tasks lately. It’s different from regular Google searches because it synthesizes information from multiple sources and gives you one coherent answer with citations.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-research.jpg" class="img-fluid" alt="Perplexity AI Interface"> <em>Perplexity AI interface showing search results with sources</em></p>
</section>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How It Works</h2>
<section id="getting-information-from-multiple-sources" class="level3">
<h3 class="anchored" data-anchor-id="getting-information-from-multiple-sources">Getting Information from Multiple Sources</h3>
<p>Instead of opening multiple tabs and reading through different articles, Perplexity pulls information from various sources and combines it into a single response. When I was researching market trends for a work project, I got a summary that included key points from several industry reports, all with proper citations.</p>
</section>
<section id="follow-up-questions" class="level3">
<h3 class="anchored" data-anchor-id="follow-up-questions">Follow-up Questions</h3>
<p>You can ask follow-up questions that build on your previous search. After asking about “sustainable packaging trends 2025,” I could continue with: - “What are the cost implications?” - “Which companies are leading this transition?” - “How does this compare to 2024 predictions?”</p>
<p>The AI remembers the context, so you don’t need to re-explain what you’re looking for.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-citations.jpg" class="img-fluid" alt="Perplexity Search Results"> <em>Live citations and source integration in action</em></p>
</section>
</section>
<section id="when-its-useful" class="level2">
<h2 class="anchored" data-anchor-id="when-its-useful">When It’s Useful</h2>
<section id="academic-work" class="level3">
<h3 class="anchored" data-anchor-id="academic-work">Academic Work</h3>
<p>Good for getting an overview of research topics and finding relevant studies. Helps identify what’s already been studied and where there might be gaps.</p>
</section>
<section id="business-research" class="level3">
<h3 class="anchored" data-anchor-id="business-research">Business Research</h3>
<p>Useful for market analysis and industry trends. You can ask specific questions and get answers that draw from recent reports and news sources.</p>
</section>
<section id="learning-new-topics" class="level3">
<h3 class="anchored" data-anchor-id="learning-new-topics">Learning New Topics</h3>
<p>When you’re unfamiliar with a subject, it can explain concepts and provide background without having to piece together information from multiple websites.</p>
</section>
<section id="fact-checking" class="level3">
<h3 class="anchored" data-anchor-id="fact-checking">Fact-Checking</h3>
<p>Since it shows sources for each piece of information, it’s easier to verify claims and see where data comes from.</p>
</section>
</section>
<section id="what-ive-found" class="level2">
<h2 class="anchored" data-anchor-id="what-ive-found">What I’ve Found</h2>
<section id="saves-time" class="level3">
<h3 class="anchored" data-anchor-id="saves-time">Saves Time</h3>
<p>The main benefit is speed. You get the key information faster since it’s already compiled from multiple sources. You still need to read the original sources for details, but the initial overview is much quicker.</p>
</section>
<section id="clear-sources" class="level3">
<h3 class="anchored" data-anchor-id="clear-sources">Clear Sources</h3>
<p>Every piece of information comes with citations, so you can see exactly where it came from and verify it if needed.</p>
</section>
<section id="handles-context-well" class="level3">
<h3 class="anchored" data-anchor-id="handles-context-well">Handles Context Well</h3>
<p>The conversation aspect works better than I expected. You can refine questions or explore related topics without starting over.</p>
</section>
<section id="shows-different-viewpoints" class="level3">
<h3 class="anchored" data-anchor-id="shows-different-viewpoints">Shows Different Viewpoints</h3>
<p>When sources disagree, it usually mentions the different perspectives rather than just presenting one view.</p>
<p>It’s a useful tool for the initial stages of research when you need to understand a topic quickly or gather information from multiple sources. Not a replacement for thorough research, but it does help speed up the information gathering process.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>research</category>
  <category>productivity</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/003.html</guid>
  <pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-research.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Do’s and Don’ts: Safe and Effective Usage</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/002.html</link>
  <description><![CDATA[ 





<section id="essential-ai-guidelines" class="level2">
<h2 class="anchored" data-anchor-id="essential-ai-guidelines">Essential AI Guidelines</h2>
<p>AI tools are powerful but require careful usage. These guidelines help you maximize benefits while avoiding common pitfalls.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-safety-guidelines.jpg" class="img-fluid" alt="AI Safety Guidelines"> <em>Key principles for responsible AI usage</em></p>
</section>
<section id="what-to-do" class="level2">
<h2 class="anchored" data-anchor-id="what-to-do">What TO Do</h2>
<section id="verify-important-information" class="level3">
<h3 class="anchored" data-anchor-id="verify-important-information">✅ Verify Important Information</h3>
<p>Always fact-check AI outputs for: - Medical or health advice - Financial decisions - Legal matters - Technical specifications - Current events or recent data</p>
<p>Cross-reference with authoritative sources before acting on AI recommendations.</p>
</section>
<section id="be-specific-in-your-prompts" class="level3">
<h3 class="anchored" data-anchor-id="be-specific-in-your-prompts">✅ Be Specific in Your Prompts</h3>
<p><strong>Instead of:</strong> “Help me with my presentation” <strong>Use:</strong> “Create an outline for a 10-minute sales presentation to executives about Q3 revenue growth”</p>
<p>Specific prompts produce more useful results.</p>
</section>
<section id="use-ai-for-brainstorming-and-drafts" class="level3">
<h3 class="anchored" data-anchor-id="use-ai-for-brainstorming-and-drafts">✅ Use AI for Brainstorming and Drafts</h3>
<p>AI excels at: - Generating initial ideas - Creating first drafts - Organizing thoughts - Providing alternative perspectives</p>
<p>Use AI output as a starting point, not a final product.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-workflow-diagram.jpg" class="img-fluid" alt="AI Workflow Best Practices"> <em>Proper workflow: AI assists, human validates and refines</em></p>
</section>
<section id="maintain-human-judgment" class="level3">
<h3 class="anchored" data-anchor-id="maintain-human-judgment">✅ Maintain Human Judgment</h3>
<p>Keep human oversight for: - Final decision-making - Quality assessment - Ethical considerations - Context that AI might miss</p>
</section>
<section id="ask-follow-up-questions" class="level3">
<h3 class="anchored" data-anchor-id="ask-follow-up-questions">✅ Ask Follow-Up Questions</h3>
<p>Improve results by asking: - “Can you explain this differently?” - “What are potential problems with this approach?” - “Give me three alternatives” - “Make this more specific”</p>
</section>
</section>
<section id="what-not-to-do" class="level2">
<h2 class="anchored" data-anchor-id="what-not-to-do">What NOT to Do</h2>
<section id="dont-share-sensitive-information" class="level3">
<h3 class="anchored" data-anchor-id="dont-share-sensitive-information">❌ Don’t Share Sensitive Information</h3>
<p>Never input: - Passwords or login credentials - Social Security numbers - Credit card details - Proprietary business information - Personal addresses or phone numbers - Private family details</p>
<p>Assume all AI conversations could be stored or accessed by others.</p>
</section>
<section id="dont-rely-on-ai-for-critical-decisions" class="level3">
<h3 class="anchored" data-anchor-id="dont-rely-on-ai-for-critical-decisions">❌ Don’t Rely on AI for Critical Decisions</h3>
<p>Avoid using AI alone for: - Medical diagnoses or treatment - Legal advice or document preparation - Financial investment decisions - Safety-critical calculations - Emergency situations</p>
<p>Consult qualified professionals for these matters.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-security-risks.jpg" class="img-fluid" alt="AI Limitations Warning"> <em>Areas where AI should not be the primary decision maker</em></p>
</section>
<section id="dont-assume-ai-is-always-accurate" class="level3">
<h3 class="anchored" data-anchor-id="dont-assume-ai-is-always-accurate">❌ Don’t Assume AI is Always Accurate</h3>
<p>AI can produce: - Outdated information - Factual errors - Biased responses - Plausible-sounding but incorrect details</p>
<p>Especially problematic for recent events or specialized technical information.</p>
</section>
<section id="dont-use-ai-for-harmful-purposes" class="level3">
<h3 class="anchored" data-anchor-id="dont-use-ai-for-harmful-purposes">❌ Don’t Use AI for Harmful Purposes</h3>
<p>Avoid requesting: - Misleading or false content - Harassment or threatening messages - Plagiarism or academic dishonesty - Illegal activity guidance - Discriminatory content</p>
</section>
<section id="dont-ignore-context-limitations" class="level3">
<h3 class="anchored" data-anchor-id="dont-ignore-context-limitations">❌ Don’t Ignore Context Limitations</h3>
<p>AI doesn’t understand: - Your full personal situation - Unspoken cultural context - Real-time environmental factors - Emotional nuances</p>
<p>Provide necessary context explicitly in your prompts.</p>
</section>
</section>
<section id="implementation-strategy" class="level2">
<h2 class="anchored" data-anchor-id="implementation-strategy">Implementation Strategy</h2>
<section id="start-small" class="level3">
<h3 class="anchored" data-anchor-id="start-small">Start Small</h3>
<p>Begin with low-stakes tasks like email drafting or meal planning before using AI for important projects.</p>
</section>
<section id="build-verification-habits" class="level3">
<h3 class="anchored" data-anchor-id="build-verification-habits">Build Verification Habits</h3>
<p>Develop a routine of checking AI outputs against reliable sources.</p>
</section>
<section id="keep-learning" class="level3">
<h3 class="anchored" data-anchor-id="keep-learning">Keep Learning</h3>
<p>AI capabilities and limitations evolve. Stay informed about updates and new research.</p>
</section>
<section id="document-what-works" class="level3">
<h3 class="anchored" data-anchor-id="document-what-works">Document What Works</h3>
<p>Save effective prompts and note which applications produce reliable results for your needs.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-usage-tips.jpg" class="img-fluid" alt="AI Usage Tips"> <em>Use these tips and tricks!</em></p>
<p>Following these guidelines ensures you gain AI’s benefits while avoiding common mistakes that can lead to poor decisions or security issues.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>safety</category>
  <category>guidelines</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/002.html</guid>
  <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-safety-guidelines.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>5 Ways to Use AI Every Day</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/001.html</link>
  <description><![CDATA[ 





<section id="using-ai-for-daily-tasks" class="level2">
<h2 class="anchored" data-anchor-id="using-ai-for-daily-tasks">Using AI for Daily Tasks</h2>
<p>AI tools like ChatGPT and Claude can handle routine tasks that usually take significant time. Here are five practical applications that work reliably.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/ai-daily-tasks.jpg" class="img-fluid" alt="AI Daily Tasks"> <em>Common tasks where AI provides immediate value</em></p>
</section>
<section id="meal-planning-and-recipes" class="level2">
<h2 class="anchored" data-anchor-id="meal-planning-and-recipes">1. Meal Planning and Recipes</h2>
<p>Turn ingredients into meal plans instantly.</p>
<p><strong>Basic ingredient prompt:</strong></p>
<pre><code>I have chicken breast, rice, and broccoli. 
Give me 3 different 30-minute meals with instructions.</code></pre>
<p><strong>Weekly planning prompt:</strong></p>
<pre><code>Create a 5-day meal plan for 2 people, $60 budget. 
Include grocery list organized by store section.</code></pre>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/ai-meal-planning.jpg" class="img-fluid" alt="AI Meal Planning"> <em>AI generates recipes based on available ingredients and dietary preferences</em></p>
<p>AI handles dietary restrictions, cooking time constraints, and budget limitations effectively. The grocery lists are particularly useful since they organize items by store layout.</p>
</section>
<section id="email-and-message-writing" class="level2">
<h2 class="anchored" data-anchor-id="email-and-message-writing">2. Email and Message Writing</h2>
<p>Improve clarity and tone in professional communication.</p>
<p><strong>Email revision prompt:</strong></p>
<pre><code>Make this email more professional and concise:
[paste your draft]</code></pre>
<p><strong>Difficult conversation prompt:</strong></p>
<pre><code>Help me write a polite but firm email declining this request:
[explain situation]</code></pre>
<p><strong>Meeting follow-up prompt:</strong></p>
<pre><code>Draft a follow-up email summarizing these meeting points:
[list key decisions and action items]</code></pre>
<p>This works for text messages, LinkedIn messages, and any written communication where tone matters.</p>
</section>
<section id="quick-learning-and-research" class="level2">
<h2 class="anchored" data-anchor-id="quick-learning-and-research">3. Quick Learning and Research</h2>
<p>Get structured explanations on unfamiliar topics.</p>
<p><strong>Concept explanation prompt:</strong></p>
<pre><code>Explain [topic] in simple terms, then give me 
5 follow-up questions to test my understanding.</code></pre>
<p><strong>Skill learning prompt:</strong></p>
<pre><code>I need to learn Excel pivot tables for work. 
Give me a step-by-step tutorial focusing on the most practical features.</code></pre>
<p><strong>Research synthesis prompt:</strong></p>
<pre><code>Compare the top 3 options for [product/service] 
with pros and cons for each.</code></pre>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/ai-learning-interface.jpg" class="img-fluid" alt="AI Learning Assistant"> <em>AI breaks down complex topics into manageable learning steps</em></p>
<p>AI excels at creating structured learning paths and synthesizing information from multiple angles.</p>
</section>
<section id="travel-and-event-planning" class="level2">
<h2 class="anchored" data-anchor-id="travel-and-event-planning">4. Travel and Event Planning</h2>
<p>Generate detailed itineraries and logistics.</p>
<p><strong>Trip planning prompt:</strong></p>
<pre><code>Plan a 3-day weekend trip to [destination] for [number] people 
with a $[amount] budget. Include transportation, accommodation, 
and daily activities.</code></pre>
<p><strong>Local exploration prompt:</strong></p>
<pre><code>What are 5 lesser-known attractions in [city] 
that locals recommend?</code></pre>
<p><strong>Event planning prompt:</strong></p>
<pre><code>Create a timeline and checklist for planning a 
[birthday party/dinner party/work event] for [number] people.</code></pre>
<p>AI handles multiple constraints simultaneously - budget, time, preferences, and logistics.</p>
</section>
<section id="home-management-and-finances" class="level2">
<h2 class="anchored" data-anchor-id="home-management-and-finances">5. Home Management and Finances</h2>
<p>Get practical advice for household and money management.</p>
<p><strong>Home maintenance prompt:</strong></p>
<pre><code>My [appliance/fixture] is [problem description]. 
Walk me through troubleshooting steps from simple to complex.</code></pre>
<p><strong>Budget planning prompt:</strong></p>
<pre><code>I make $[amount] monthly, fixed expenses are $[amount]. 
Create a realistic budget with savings and discretionary spending.</code></pre>
<p><strong>Purchase decision prompt:</strong></p>
<pre><code>I'm considering buying [item] for [purpose]. 
What factors should I evaluate? Create a decision framework.</code></pre>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/ai-budget-planning.jpg" class="img-fluid" alt="AI Home Finance"> <em>AI provides structured approaches to financial and household decisions</em></p>
<p>These applications work because AI can process multiple variables and provide step-by-step guidance for complex decisions.</p>
</section>
<section id="implementation-notes" class="level2">
<h2 class="anchored" data-anchor-id="implementation-notes">Implementation Notes</h2>
<p><strong>Prompt specificity matters.</strong> Include relevant details like budget, timeframe, number of people, and specific constraints.</p>
<p><strong>Follow-up questions improve results.</strong> Ask for alternatives, simplifications, or additional detail as needed.</p>
<p><strong>Save effective prompts.</strong> Keep a note file with prompts that work well for repeated use.</p>
<p>These five applications cover the most common daily planning and decision-making tasks. Each provides immediate time savings and often produces better results than manual research.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>productivity</category>
  <category>tutorial</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/001.html</guid>
  <pubDate>Fri, 05 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/001_AI_Daily_Guide/ai-daily-tasks.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>How AI Systems Work: A Technical Overview</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/000.html</link>
  <description><![CDATA[ 





<section id="understanding-modern-ai-systems" class="level2">
<h2 class="anchored" data-anchor-id="understanding-modern-ai-systems">Understanding Modern AI Systems</h2>
<p>Artificial intelligence systems like ChatGPT and Claude can engage in conversations, solve problems, and generate content. However, their underlying mechanisms are fundamentally different from human cognition.</p>
<p>These systems operate as sophisticated pattern recognition and prediction engines. While they can produce human-like responses, they function by identifying statistical patterns in data rather than developing conceptual understanding.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/neural-network-brain.jpg" class="img-fluid" alt="Neural Network vs Brain"> <em>AI neural networks are inspired by brain structure but operate through different mechanisms</em></p>
<blockquote class="blockquote">
<p><strong>Key Question:</strong> How do statistical pattern-matching systems produce seemingly intelligent behavior?</p>
</blockquote>
</section>
<section id="core-architecture-prediction-systems" class="level2">
<h2 class="anchored" data-anchor-id="core-architecture-prediction-systems">Core Architecture: Prediction Systems</h2>
<p>Modern AI systems solve a fundamental prediction problem: given an input, determine the most statistically likely output. This applies whether predicting the next word in text, pixels in an image, or moves in a game.</p>
<section id="transformer-architecture" class="level3">
<h3 class="anchored" data-anchor-id="transformer-architecture">Transformer Architecture</h3>
<p>Current large language models like GPT-4 and Claude use transformer architecture:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simplified transformer process</span></span>
<span id="cb1-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> transformer_prediction(input_text):</span>
<span id="cb1-3">    tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenize(input_text)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert text to processable units</span></span>
<span id="cb1-4">    embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> convert_to_vectors(tokens)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Map to numerical representations</span></span>
<span id="cb1-5">    </span>
<span id="cb1-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> layer <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> neural_layers:</span>
<span id="cb1-7">        embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attention_mechanism(embeddings)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Identify relationships</span></span>
<span id="cb1-8">        embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> feed_forward(embeddings)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process patterns</span></span>
<span id="cb1-9">    </span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> predict_next_token(embeddings)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate most likely continuation</span></span></code></pre></div></div>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/transformer-architecture.jpg" class="img-fluid" alt="Transformer Architecture"> <em>Transformer architecture with attention and processing layers</em></p>
<p>Modern systems operate at significant scale. GPT-3 contains 175 billion parameters trained on 45TB of text data. GPT-4 is estimated to exceed 1 trillion parameters with correspondingly higher computational requirements.</p>
</section>
<section id="attention-mechanisms" class="level3">
<h3 class="anchored" data-anchor-id="attention-mechanisms">Attention Mechanisms</h3>
<p>The attention mechanism enables models to focus selectively on different input elements when making predictions.</p>
<p><strong>Example:</strong> “The cat sat on the mat because it was comfortable.”</p>
<p>When determining what “it” refers to, the attention mechanism assigns weights: - “cat” (high attention - 0.7) - “mat” (medium attention - 0.2) - “sat” (low attention - 0.1)</p>
<p>This mechanism allows processing of relationships between distant elements in sequences.</p>
</section>
</section>
<section id="training-process" class="level2">
<h2 class="anchored" data-anchor-id="training-process">Training Process</h2>
<p>AI system development occurs through structured training phases that determine capabilities and limitations.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/ai-training-process.jpg" class="img-fluid" alt="AI Training Process"> <em>Complete pipeline from data collection to deployed system</em></p>
<section id="phase-1-pre-training" class="level3">
<h3 class="anchored" data-anchor-id="phase-1-pre-training">Phase 1: Pre-training</h3>
<p>Systems learn from large text datasets through next-token prediction:</p>
<ol type="1">
<li><strong>Data Collection</strong>: Process text from websites, books, and articles</li>
<li><strong>Tokenization</strong>: Convert text to discrete units for processing</li>
<li><strong>Prediction Training</strong>: Train models to predict missing tokens in sequences</li>
<li><strong>Parameter Adjustment</strong>: Iteratively modify billions of parameters based on prediction accuracy</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simplified training loop</span></span>
<span id="cb2-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> epoch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(many_epochs):</span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> text_chunk <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> massive_dataset:</span>
<span id="cb2-4">        input_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_chunk[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Input sequence</span></span>
<span id="cb2-5">        target_token <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_chunk[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target prediction</span></span>
<span id="cb2-6">        </span>
<span id="cb2-7">        prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(input_tokens)</span>
<span id="cb2-8">        loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> calculate_error(prediction, target_token)</span>
<span id="cb2-9">        </span>
<span id="cb2-10">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update model parameters</span></span>
<span id="cb2-11">        model.update_weights(loss.gradient())</span></code></pre></div></div>
</section>
<section id="phase-2-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="phase-2-fine-tuning">Phase 2: Fine-tuning</h3>
<p>Pre-trained models are refined for specific applications:</p>
<ul>
<li><strong>Supervised Fine-tuning</strong>: Training on curated question-answer pairs</li>
<li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong>: Using human preferences to shape responses</li>
<li><strong>Safety Training</strong>: Implementing guidelines to avoid harmful outputs</li>
</ul>
<p>This process transforms basic text predictors into conversational assistants.</p>
</section>
</section>
<section id="emergent-capabilities" class="level2">
<h2 class="anchored" data-anchor-id="emergent-capabilities">Emergent Capabilities</h2>
<p>Large-scale training produces capabilities that weren’t explicitly programmed. These emergent abilities arise from complex interactions between simple components.</p>
<section id="examples-of-emergence" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-emergence">Examples of Emergence</h3>
<p>As model size increases, new capabilities develop:</p>
<p><strong>Chain-of-Thought Reasoning</strong>: Models develop step-by-step problem-solving approaches without explicit training on this strategy.</p>
<p><strong>In-Context Learning</strong>: Systems can perform new tasks based on examples in prompts without additional training.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example of in-context learning</span></span>
<span id="cb3-2">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Translate English to French:</span></span>
<span id="cb3-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Hello → Bonjour</span></span>
<span id="cb3-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Goodbye → Au revoir</span></span>
<span id="cb3-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Thank you → Merci</span></span>
<span id="cb3-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Good morning → </span></span>
<span id="cb3-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model produces "Bonjour" despite no explicit</span></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># training on this translation task</span></span></code></pre></div></div>
<p><strong>Cross-Lingual Transfer</strong>: Models trained primarily on English can operate effectively in other languages.</p>
<p>The mechanisms underlying emergence remain an active research area, with theories including phase transitions, increased representational capacity, and pattern recognition thresholds.</p>
</section>
</section>
<section id="system-limitations" class="level2">
<h2 class="anchored" data-anchor-id="system-limitations">System Limitations</h2>
<p>Current AI systems have several fundamental constraints that stem from their statistical architecture:</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/ai-limitations-chart.jpg" class="img-fluid" alt="AI Limitations Chart"> <em>Overview of AI system capabilities and constraints</em></p>
<section id="pattern-matching-vs.-understanding" class="level3">
<h3 class="anchored" data-anchor-id="pattern-matching-vs.-understanding">Pattern Matching vs.&nbsp;Understanding</h3>
<p>AI systems process statistical relationships in symbols rather than developing conceptual understanding. They can accurately reproduce information without grasping underlying mechanisms.</p>
<p><strong>Example</strong>: A system can state that “water boils at 100°C” without understanding molecular behavior, phase transitions, or the physical processes involved.</p>
</section>
<section id="output-generation-under-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="output-generation-under-uncertainty">Output Generation Under Uncertainty</h3>
<p>Systems are designed to produce responses even when lacking relevant information, leading to plausible but potentially inaccurate outputs.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simplified response generation</span></span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_response(query):</span>
<span id="cb4-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> confidence_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> threshold:</span>
<span id="cb4-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> retrieve_known_information(query)</span>
<span id="cb4-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb4-6">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># System still generates output</span></span>
<span id="cb4-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> generate_plausible_response(query)</span></code></pre></div></div>
</section>
<section id="training-data-constraints" class="level3">
<h3 class="anchored" data-anchor-id="training-data-constraints">Training Data Constraints</h3>
<p>Models are limited by their training data cutoff and cannot incorporate new information without retraining.</p>
</section>
<section id="memory-limitations" class="level3">
<h3 class="anchored" data-anchor-id="memory-limitations">Memory Limitations</h3>
<p>Current systems can process limited context windows (typically 4,000-128,000 tokens) with no persistent memory between conversations.</p>
</section>
<section id="correlation-vs.-causation" class="level3">
<h3 class="anchored" data-anchor-id="correlation-vs.-causation">Correlation vs.&nbsp;Causation</h3>
<p>Systems excel at identifying statistical correlations but have limited understanding of causal relationships. They may recognize that umbrella sales correlate with rain without understanding the causal mechanism.</p>
</section>
</section>
<section id="practical-implications" class="level2">
<h2 class="anchored" data-anchor-id="practical-implications">Practical Implications</h2>
<p>Understanding AI architecture has important implications for effective use:</p>
<section id="system-strengths" class="level3">
<h3 class="anchored" data-anchor-id="system-strengths">System Strengths</h3>
<ul>
<li>Pattern recognition and text generation capabilities</li>
<li>Rapid processing of large information sets</li>
<li>Accessible interface for complex tasks</li>
<li>Consistent performance within training domains</li>
</ul>
</section>
<section id="appropriate-applications" class="level3">
<h3 class="anchored" data-anchor-id="appropriate-applications">Appropriate Applications</h3>
<ul>
<li>Content drafting and editing</li>
<li>Information synthesis from known sources</li>
<li>Code generation and debugging assistance</li>
<li>Language translation</li>
<li>Creative brainstorming</li>
</ul>
</section>
<section id="best-practices" class="level3">
<h3 class="anchored" data-anchor-id="best-practices">Best Practices</h3>
<ol type="1">
<li><strong>Verify Important Information</strong>: Fact-check outputs for critical applications</li>
<li><strong>Understand Limitations</strong>: Recognize domain constraints and knowledge cutoffs</li>
<li><strong>Maintain Human Oversight</strong>: Keep humans involved in important decisions</li>
<li><strong>Recognize Bias</strong>: Be aware that systems reflect training data biases</li>
<li><strong>Use as Tools</strong>: Apply systems as analytical instruments rather than authoritative sources</li>
</ol>
</section>
</section>
<section id="future-development" class="level2">
<h2 class="anchored" data-anchor-id="future-development">Future Development</h2>
<p>Current AI systems represent early implementations of statistical learning approaches. Several research directions may expand capabilities:</p>
<section id="near-term-developments-1-3-years" class="level3">
<h3 class="anchored" data-anchor-id="near-term-developments-1-3-years">Near-Term Developments (1-3 years)</h3>
<ul>
<li>Multimodal systems integrating text, images, audio, and video</li>
<li>Extended context windows for longer conversations and documents</li>
<li>Improved reasoning and problem-solving capabilities</li>
<li>Specialized models optimized for specific domains</li>
</ul>
</section>
<section id="long-term-research-areas-10-years" class="level3">
<h3 class="anchored" data-anchor-id="long-term-research-areas-10-years">Long-Term Research Areas (10+ years)</h3>
<ul>
<li>Artificial General Intelligence research</li>
<li>Questions about machine consciousness and subjective experience</li>
<li>AI alignment and safety considerations</li>
</ul>
</section>
<section id="active-research-questions" class="level3">
<h3 class="anchored" data-anchor-id="active-research-questions">Active Research Questions</h3>
<p>Researchers are investigating fundamental questions:</p>
<ul>
<li><strong>Scaling Laws</strong>: Relationships between model size, data, and capabilities</li>
<li><strong>Emergence Mechanisms</strong>: Why new abilities appear at certain scales</li>
<li><strong>Alignment</strong>: Ensuring AI systems operate according to intended objectives</li>
<li><strong>Interpretability</strong>: Understanding internal model representations and processes</li>
</ul>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Modern AI systems represent sophisticated statistical engines that process patterns in data to generate human-like outputs. While they demonstrate impressive capabilities, they operate through pattern matching rather than conceptual understanding.</p>
<section id="key-technical-points" class="level3">
<h3 class="anchored" data-anchor-id="key-technical-points">Key Technical Points</h3>
<p>Current AI systems achieve intelligent-seeming behavior through statistical pattern processing rather than understanding. This approach has several implications:</p>
<ul>
<li><strong>For Users</strong>: Understanding system strengths and limitations enables more effective application</li>
<li><strong>For Organizations</strong>: Appropriate use requires human oversight and verification processes</li>
<li><strong>For Society</strong>: New frameworks are needed for evaluating machine capabilities and limitations</li>
</ul>
<p>Statistical pattern matching at scale produces sophisticated behavior, suggesting that aspects of intelligence may be more computational than previously understood.</p>
<p>As these systems become more prevalent, understanding their statistical nature becomes increasingly important for effective implementation. The technology continues evolving rapidly, with ongoing research addressing questions about scaling, emergence, and alignment with human objectives.</p>
<p>The field represents significant progress in automated pattern recognition and generation, with continued development likely to expand capabilities while maintaining the fundamental statistical architecture.</p>
<hr>
<p><strong>Understanding the technical foundations of AI systems helps inform appropriate use and realistic expectations about current capabilities.</strong></p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>deep-dive</category>
  <category>technology</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/000.html</guid>
  <pubDate>Wed, 03 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/000_How_Does_AI_Really_Work/neural-network-brain.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
