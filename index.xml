<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>What Can You Do With AI?</title>
<link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/</link>
<atom:link href="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Let&#39;s Find Out</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Sun, 02 Nov 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Superagency Review #3: Testing, Benchmarking, and the Gamification of Regulation</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/021_/021.html</link>
  <description><![CDATA[ 





<section id="chapter-5-testing-testing-1-2-infinite" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-testing-testing-1-2-infinite">Chapter 5: <em>Testing, Testing, 1, 2 (Infinite)</em></h2>
<p>This section of <em>Superagency</em> (pages 99–143) shifts from optimism to mechanics: how testing, benchmarking, and iterative competition supposedly form the backbone of American AI leadership. Hoffman and Beato frame this as a uniquely democratic innovation engine. Parts of the chapter are compelling; others amplify the same concerns raised earlier in the book.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/021_/superagency-testing-cover.jpg" alt="AI Testing Race" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
</section>
<section id="the-cold-war-parallel" class="level2">
<h2 class="anchored" data-anchor-id="the-cold-war-parallel">The Cold War Parallel</h2>
<p>Hoffman highlights the rising use of phrases like <strong>“AI arms race”</strong> and <strong>“AI Space Race.”</strong> These metaphors frame AI as a geopolitical contest and cast innovation as national defense.</p>
<p>Cold War language implies: - national survival stakes - winner-take-all dynamics - justification for speed over caution - suspicion toward dissent</p>
<p>My concern is that emergency framing narrows public debate. It turns critique into perceived disloyalty. The question becomes whether urgency helps innovation or simply suppresses precaution.</p>
</section>
<section id="democracy-vs.-china-competitive-advantage-or-ideological-comfort" class="level2">
<h2 class="anchored" data-anchor-id="democracy-vs.-china-competitive-advantage-or-ideological-comfort">Democracy vs.&nbsp;China – Competitive Advantage or Ideological Comfort?</h2>
<p>The authors argue that American innovation thrives because democracy encourages open experimentation, while China favors control and pre-approval. This framing leads to the implicit claim that <strong>American hegemony is the only acceptable outcome</strong>, a point that deserves more scrutiny.</p>
<p>The real tension is not democracy vs.&nbsp;authoritarianism; it’s <strong>permissionless innovation vs.&nbsp;burden-of-proof safety models.</strong> For frontier AI, neither extreme may work. The chapter sidesteps how high-risk technologies challenge this binary.</p>
</section>
<section id="benchmarks-as-pseudo-regulation" class="level2">
<h2 class="anchored" data-anchor-id="benchmarks-as-pseudo-regulation">Benchmarks as Pseudo-Regulation</h2>
<p>Hoffman argues that benchmarks function as a cultural form of regulation—“regulation, gamified.” When companies compete to score well on shared tests, innovation accelerates.</p>
<p>The assumption is that: - companies will voluntarily exceed standards - benchmarks naturally tighten over time - competition substitutes for enforcement</p>
<p>In practice, gamified regulation creates problems: - companies optimize for the test, not real-world safety - metrics become PR tools - firms cherry-pick flattering benchmarks - bad actors simply ignore the system</p>
<p>Benchmarks matter, but they cannot govern high-risk technology alone.</p>
</section>
<section id="why-expect-ai-to-be-perfect" class="level2">
<h2 class="anchored" data-anchor-id="why-expect-ai-to-be-perfect">Why Expect AI to Be Perfect?</h2>
<p>Hoffman asks why society expects AI to achieve near-zero error when humans make mistakes constantly. The answer is scale.</p>
<ul>
<li>A human error affects one person.</li>
<li>An AI system deployed to millions repeats an error instantly.</li>
<li>Failures are opaque and hard to trace.</li>
<li>Risks become systemic, not isolated.</li>
</ul>
<p>Expectations are higher because the consequences are broader.</p>
</section>
<section id="innovation-as-safety-a-tension" class="level2">
<h2 class="anchored" data-anchor-id="innovation-as-safety-a-tension">Innovation as Safety – A Tension</h2>
<p>The authors claim innovation itself is safety: rapidly iterating helps uncover failures early. This logic underpins “permissionless innovation.” But if real users become unwitting test subjects, the line between experimentation and exploitation blurs.</p>
<p>The analogy to the Ford assembly line captures both sides. It democratized mobility while creating decades of infrastructural and environmental dependencies. Innovation often hides long-tail costs that appear only after widespread deployment.</p>
</section>
<section id="the-vorsorgeprinzip" class="level2">
<h2 class="anchored" data-anchor-id="the-vorsorgeprinzip">The Vorsorgeprinzip</h2>
<p>Germany’s <strong>forecaring principle</strong> requires developers to prove safety before deployment. Hoffman frames this as overly conservative, but it’s not clear that frontier AI fits the American model of “deploy first, fix later.”</p>
<p>When developers can’t fully predict system behavior, shifting the burden of proof may be reasonable.</p>
</section>
<section id="big-knowledge-and-collective-intelligence" class="level2">
<h2 class="anchored" data-anchor-id="big-knowledge-and-collective-intelligence">Big Knowledge and Collective Intelligence</h2>
<p>The chapter ends with “big knowledge” examples like Google Maps—systems where collective data improves outcomes for all. The story is persuasive, but it glosses over deepening dependencies: - people lose local knowledge - decision-making shifts to opaque models - infrastructure becomes more fragile</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/021_/placeholder-big-knowledge.jpg" alt="Collective Intelligence" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p>Optimistic narratives rarely acknowledge these hidden costs.</p>
</section>
<section id="my-notes-and-questions" class="level2">
<h2 class="anchored" data-anchor-id="my-notes-and-questions">My Notes and Questions</h2>
<ul>
<li>If testing replaces regulation, who enforces the testers?</li>
<li>Who absorbs harm during iterative deployment?</li>
<li>Is innovation inherently democratic, or is this an American myth?</li>
<li>Why should speed be a virtue when consequences scale exponentially?</li>
</ul>
<p>The book grows more persuasive, but its implicit assumptions grow louder too.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Chapter 5 argues that testing can replace regulation, accelerating safe innovation. The idea has merit—overly strict regulation can freeze progress.</p>
<p>But the chapter underestimates what happens when testing becomes a governance substitute. Benchmarks become branding exercises. Users become test subjects. Accountability evaporates.</p>
<p>The line between innovation and recklessness is thin, and <em>Superagency</em> often blurs it more than it clarifies it.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>book-review</category>
  <category>skeptical</category>
  <category>research</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/021_/021.html</guid>
  <pubDate>Sun, 02 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/021_/superagency-book-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Your Brain on ChatGPT: The Cost of Cognitive Convenience</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/020_/020.html</link>
  <description><![CDATA[ 





<section id="a-study-that-made-me-uncomfortable" class="level2">
<h2 class="anchored" data-anchor-id="a-study-that-made-me-uncomfortable">A Study That Made Me Uncomfortable</h2>
<p>I came across a recent MIT Media Lab study examining how AI-assisted writing affects the brain during essay tasks. The findings pushed me to rethink how much I rely on Claude for school, work, and even these posts.</p>
<p>The study followed 54 participants over four months. Some wrote essays with no tools, some used search engines, and others used ChatGPT. EEG measurements revealed something striking: <strong>LLM-assisted writers consistently showed the weakest neural connectivity and lowest cognitive engagement.</strong></p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/020_/brain-connectivity-scan.jpg" alt="Brain Activity Differences" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
</section>
<section id="what-the-study-found" class="level2">
<h2 class="anchored" data-anchor-id="what-the-study-found">What the Study Found</h2>
<section id="cognitive-engagement-differences" class="level3">
<h3 class="anchored" data-anchor-id="cognitive-engagement-differences">Cognitive Engagement Differences</h3>
<p>Participants’ neural activity broke down into three clear tiers: - <strong>Brain-only:</strong> strongest, most distributed activation - <strong>Search Engine:</strong> moderate activation - <strong>LLM-assisted:</strong> lowest activation and weakest connectivity</p>
<p>The more the tool handled the synthesis, the less the brain participated.</p>
</section>
<section id="cognitive-debt-builds-over-time" class="level3">
<h3 class="anchored" data-anchor-id="cognitive-debt-builds-over-time">Cognitive Debt Builds Over Time</h3>
<p>After four months, patterns did not converge. If anything, they diverged.</p>
<p>When researchers forced participants to switch modes: - <strong>LLM-to-Brain</strong> users struggled to activate core cognitive networks once the AI was removed - <strong>Brain-to-LLM</strong> users still retained higher activation patterns</p>
<p>The authors call this <strong>cognitive debt</strong> — a cumulative loss of mental effort that makes it harder to think independently after extended reliance on AI.</p>
</section>
</section>
<section id="the-ownership-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-ownership-problem">The Ownership Problem</h2>
<p>Participants were asked how much each essay felt like “their own.” Results tracked the neural data: - Brain-only: highest sense of ownership - Search Engine: moderate - LLM-assisted: lowest</p>
<p>More tellingly, LLM-assisted writers struggled to <strong>quote their own work</strong> later. Because they did not synthesize the ideas themselves, the memory trace was weaker. The AI generated wording; participants just approved it.</p>
</section>
<section id="everyone-started-sounding-the-same" class="level2">
<h2 class="anchored" data-anchor-id="everyone-started-sounding-the-same">Everyone Started Sounding the Same</h2>
<p>Using NLP techniques, the researchers found that LLM-assisted essays clustered tightly around similar: - topics - n-gram structures - named entities - argument patterns</p>
<p>The essays demonstrated <strong>linguistic homogeneity</strong> — a flattening of personal style that did not appear in the other groups.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/020_/essay-similarity-analysis.jpg" alt="Essay Similarity Patterns" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
</section>
<section id="why-this-hits-close-for-me" class="level2">
<h2 class="anchored" data-anchor-id="why-this-hits-close-for-me">Why This Hits Close for Me</h2>
<p>I use Claude constantly: to summarize lectures, structure research, draft arguments, and shape my writing. This study suggests I may have been offloading the exact cognitive work that produces long-term learning and memory.</p>
<p>When I revise an AI-generated draft, I’m not constructing ideas — I’m <strong>judging</strong> them. That’s a different neural mode. It feels productive but sidesteps the hardest, most valuable part of thinking.</p>
</section>
<section id="what-this-means-for-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-this-means-for-learning">What This Means for Learning</h2>
<section id="cognitive-debt-accumulates" class="level3">
<h3 class="anchored" data-anchor-id="cognitive-debt-accumulates">Cognitive Debt Accumulates</h3>
<p>Long-term LLM reliance was associated with: - weaker neural activation - shallower memory formation - reduced engagement - diminished ownership</p>
<p>The brain adapts to what it practices. If cognitive synthesis is outsourced, the skill erodes.</p>
</section>
<section id="not-all-tools-are-equal" class="level3">
<h3 class="anchored" data-anchor-id="not-all-tools-are-equal">Not All Tools Are Equal</h3>
<p>Search engines require active synthesis: evaluating sources, forming arguments, deciding what matters. LLMs <strong>do</strong> the synthesis for you. That difference matters.</p>
</section>
</section>
<section id="the-larger-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-larger-picture">The Larger Picture</h2>
<section id="who-benefits-from-offloading-thinking" class="level3">
<h3 class="anchored" data-anchor-id="who-benefits-from-offloading-thinking">Who Benefits From Offloading Thinking?</h3>
<p>On paper, productivity increases. But in education, productivity is not the point. The <strong>cognitive work</strong> is the point.</p>
</section>
<section id="the-convenience-trap" class="level3">
<h3 class="anchored" data-anchor-id="the-convenience-trap">The Convenience Trap</h3>
<p>You don’t feel cognitive decline happening. You only feel the difficulty once you try to write or think without the AI.</p>
<p>That’s exactly what happened to the LLM-to-Brain group. Their minds had become dependent on external structure.</p>
</section>
</section>
<section id="what-im-changing" class="level2">
<h2 class="anchored" data-anchor-id="what-im-changing">What I’m Changing</h2>
<section id="where-ill-reduce-ai" class="level3">
<h3 class="anchored" data-anchor-id="where-ill-reduce-ai">Where I’ll Reduce AI</h3>
<ul>
<li>reading and synthesis</li>
<li>argument construction</li>
<li>high-stakes learning tasks</li>
<li>creative work</li>
</ul>
</section>
<section id="where-ai-is-fine" class="level3">
<h3 class="anchored" data-anchor-id="where-ai-is-fine">Where AI Is Fine</h3>
<ul>
<li>logistics</li>
<li>summaries of things I already understand</li>
<li>admin tasks</li>
<li>formatting</li>
</ul>
<p>The goal isn’t purity — it’s avoiding cognitive atrophy.</p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>This MIT study raises real concerns about the hidden cost of AI convenience. We gain speed and efficiency. But we risk losing: - cognitive engagement - memory formation - ownership - originality</p>
<p><strong>The question isn’t whether AI works. It’s what happens to our minds when we let it think for us.</strong></p>


</section>

 ]]></description>
  <category>AI</category>
  <category>book-review</category>
  <category>skeptical</category>
  <category>learning</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/020_/020.html</guid>
  <pubDate>Sat, 01 Nov 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/020_/superagency-book-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>NotebookLM for Exam Prep: Gemini’s Research Assistant</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/019_/019.html</link>
  <description><![CDATA[ 





<section id="a-year-of-gemini-pro-testing-notebooklm" class="level2">
<h2 class="anchored" data-anchor-id="a-year-of-gemini-pro-testing-notebooklm">A Year of Gemini Pro: Testing NotebookLM</h2>
<p>I got access to Gemini Pro for a year and decided to test Google’s NotebookLM for my upcoming MKTG exam. NotebookLM markets itself as an AI research assistant that grounds its responses in your uploaded sources—supposedly reducing hallucinations and providing more reliable study support.</p>
<p>I uploaded my lecture notes, course readings, and lecture transcripts to see if it actually lives up to the claims. Spoiler: I actually liked it.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/019_/notebooklm-interface.jpg" alt="NotebookLM Interface" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>NotebookLM’s interface with uploaded course materials</em></p>
</section>
<section id="what-i-uploaded" class="level2">
<h2 class="anchored" data-anchor-id="what-i-uploaded">What I Uploaded</h2>
<p>For my MKTG exam prep, I loaded NotebookLM with:</p>
<p><strong>Lecture Notes:</strong> Typed notes from all lectures covering consumer behavior, market segmentation, brand positioning, and pricing strategies.</p>
<p><strong>Course Readings:</strong> PDFs of assigned textbook chapters and case studies.</p>
<p><strong>Lecture Transcripts:</strong> Auto-generated transcripts from recorded lectures (with professor’s verbal explanations and examples).</p>
<p>The total was probably 200+ pages of material. In the past, I’ve used Claude Projects for this, so I was curious how NotebookLM would compare. It took around 2 hours to load the material in.</p>
</section>
<section id="how-notebooklm-actually-works" class="level2">
<h2 class="anchored" data-anchor-id="how-notebooklm-actually-works">How NotebookLM Actually Works</h2>
<section id="source-grounding" class="level3">
<h3 class="anchored" data-anchor-id="source-grounding">Source Grounding</h3>
<p>The key feature: NotebookLM claims to only use information from your uploaded sources. When it answers questions, it provides citations showing exactly which document and section it pulled from.</p>
<p>I tested this by asking about a specific marketing framework we covered in class. NotebookLM gave me the answer and cited: “Lecture Notes, Week 4, Page 3” and “Consumer Behavior Reading, Chapter 7, Section 2.”</p>
<p>I checked the sources—it was accurate. The information came directly from those sections, not from generic marketing knowledge Gemini learned during training.</p>
</section>
<section id="the-qa-experience" class="level3">
<h3 class="anchored" data-anchor-id="the-qa-experience">The Q&amp;A Experience</h3>
<p>I could ask specific questions like: - “How is creativity broadly defined in the course?” - “Explain the difference between attribute dependency and subsituttion in Systematic Innovation Theory (SIT)” - “What examples did the professor give for constraints leading to creativity?”</p>
<p>NotebookLM pulled answers from the uploaded materials and cited where each piece of information came from. This was more reliable than asking a general LLM, which might give textbook definitions that don’t match what my professor actually taught.</p>
</section>
<section id="cross-reference-capability" class="level3">
<h3 class="anchored" data-anchor-id="cross-reference-capability">Cross-Reference Capability</h3>
<p>One useful feature: NotebookLM could synthesize across multiple sources. When I asked about brand positioning, it pulled from: - Lecture notes (professor’s explanation) - Textbook reading (formal definition) - Lecture transcript (specific examples the professor gave verbally)</p>
<p>This created a more complete picture than each source individually.</p>
</section>
</section>
<section id="the-audio-overview-feature" class="level2">
<h2 class="anchored" data-anchor-id="the-audio-overview-feature">The Audio Overview Feature</h2>
<p>NotebookLM has a feature that generates an audio “podcast” summarizing your sources. I tried it with my MKTG materials.</p>
<section id="what-it-generated" class="level3">
<h3 class="anchored" data-anchor-id="what-it-generated">What It Generated</h3>
<p>The audio overview was two AI voices having a conversation about the key concepts from my notes: - Voice 1: “So let’s talk about market segmentation…” - Voice 2: “Right, and there are four main types covered in these materials…”</p>
<p>It was surprisingly natural-sounding and covered the main topics in a logical order.</p>
</section>
<section id="actually-useful-for-review" class="level3">
<h3 class="anchored" data-anchor-id="actually-useful-for-review">Actually Useful for Review</h3>
<p>I listened to the 10-minute audio summary while walking to class. It hit the major concepts and provided a good high-level review. This was genuinely helpful for: - Quick refreshers before class - Identifying which topics I needed to study more deeply - Hearing concepts explained conversationally rather than reading dense notes</p>
</section>
<section id="limitations-of-audio-summaries" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-audio-summaries">Limitations of Audio Summaries</h3>
<p>The audio overview was good for broad strokes but missed: - Specific formulas or calculations - Detailed case study analysis - Nuanced distinctions between similar concepts</p>
<p>It’s a supplementary review tool, not a replacement for actually studying the material.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/019_/notebooklm-audio-overview.jpg" alt="Audio Overview" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>NotebookLM’s audio overview feature generating podcast-style summaries</em></p>
</section>
</section>
<section id="what-actually-worked-well" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-worked-well">What Actually Worked Well</h2>
<section id="accurate-source-attribution" class="level3">
<h3 class="anchored" data-anchor-id="accurate-source-attribution">Accurate Source Attribution</h3>
<p>The biggest advantage over general LLMs: NotebookLM tells you exactly where information comes from. When studying for an exam, you need to know what the professor actually taught, not what a generic AI thinks the answer should be.</p>
<p>The citations were consistently accurate. I spot-checked multiple answers and they matched the source material.</p>
</section>
<section id="no-hallucinations-so-far" class="level3">
<h3 class="anchored" data-anchor-id="no-hallucinations-so-far">No Hallucinations (So Far)</h3>
<p>I didn’t catch NotebookLM making up information. Because it’s constrained to uploaded sources, it can’t invent facts the way ChatGPT or Claude sometimes do.</p>
<p>When I asked about topics not covered in my materials, it said “I don’t have information about that in your sources” rather than making something up.</p>
</section>
<section id="understanding-context" class="level3">
<h3 class="anchored" data-anchor-id="understanding-context">Understanding Context</h3>
<p>The lecture transcripts included the professor’s verbal explanations and examples. NotebookLM could pull from these conversational explanations, which added context that wouldn’t be in formal textbook readings.</p>
<p>For example, when the professor said “this is important for the exam,” NotebookLM picked up on that emphasis.</p>
</section>
<section id="study-guide-generation" class="level3">
<h3 class="anchored" data-anchor-id="study-guide-generation">Study Guide Generation</h3>
<p>I asked NotebookLM to create a study guide covering key concepts. It generated: - Main topics organized by lecture - Important definitions - Examples from case studies - Connections between concepts</p>
<p>All sourced from my uploaded materials, formatted clearly.</p>
</section>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<section id="cant-handle-everything" class="level3">
<h3 class="anchored" data-anchor-id="cant-handle-everything">Can’t Handle Everything</h3>
<p>NotebookLM struggled with: - Complex diagrams or charts (it could see them but didn’t fully understand them) - Handwritten notes (I had to use typed notes)</p>
<p>For a marketing class this was fine, but for quantitative subjects it might be more limited.</p>
</section>
<section id="limited-interactivity" class="level3">
<h3 class="anchored" data-anchor-id="limited-interactivity">Limited Interactivity</h3>
<p>Unlike Claude Projects where I could have extended back-and-forth conversations, NotebookLM felt more like a Q&amp;A tool. It answered questions but didn’t build on previous context as naturally.</p>
</section>
<section id="relies-on-source-quality" class="level3">
<h3 class="anchored" data-anchor-id="relies-on-source-quality">Relies on Source Quality</h3>
<p>NotebookLM is only as good as what you upload. If your notes are incomplete or lecture transcripts are inaccurate (auto-transcription errors), the AI will work with flawed information.</p>
<p>Garbage in, garbage out.</p>
</section>
<section id="no-proactive-suggestions" class="level3">
<h3 class="anchored" data-anchor-id="no-proactive-suggestions">No Proactive Suggestions</h3>
<p>NotebookLM responds to questions but doesn’t proactively identify gaps in your knowledge or suggest what to study. It’s a passive tool that requires you to know what to ask.</p>
</section>
</section>
<section id="notebooklm-vs.-claude-projects" class="level2">
<h2 class="anchored" data-anchor-id="notebooklm-vs.-claude-projects">NotebookLM vs.&nbsp;Claude Projects</h2>
<p>I’ve used Claude Projects for similar purposes, so here’s how they compare:</p>
<section id="where-notebooklm-is-better" class="level3">
<h3 class="anchored" data-anchor-id="where-notebooklm-is-better">Where NotebookLM Is Better</h3>
<p><strong>Source citations:</strong> More explicit about where information comes from</p>
<p><strong>Audio summaries:</strong> The podcast-style overview is a unique feature Claude doesn’t have</p>
<p><strong>Grounding discipline:</strong> Stays within uploaded sources more strictly</p>
</section>
<section id="where-claude-projects-is-better" class="level3">
<h3 class="anchored" data-anchor-id="where-claude-projects-is-better">Where Claude Projects Is Better</h3>
<p><strong>Conversational depth:</strong> Claude handles multi-turn conversations better</p>
<p><strong>Synthesis and analysis:</strong> Claude is better at making connections and generating insights beyond summarizing</p>
<p><strong>Flexibility:</strong> Claude can go beyond sources when helpful; NotebookLM is rigidly constrained</p>
</section>
<section id="different-use-cases" class="level3">
<h3 class="anchored" data-anchor-id="different-use-cases">Different Use Cases</h3>
<p><strong>Use NotebookLM for:</strong> Exam prep where you need to know exactly what’s in your course materials, no more, no less.</p>
<p><strong>Use Claude Projects for:</strong> Research projects where you want the AI to synthesize across sources and generate new ideas.</p>
<p>For my MKTG exam, NotebookLM was the right tool. For writing papers or doing creative projects, Claude is probably better.</p>
</section>
</section>
<section id="is-this-actually-better-than-traditional-study-methods" class="level2">
<h2 class="anchored" data-anchor-id="is-this-actually-better-than-traditional-study-methods">Is This Actually Better Than Traditional Study Methods?</h2>
<section id="what-notebooklm-adds" class="level3">
<h3 class="anchored" data-anchor-id="what-notebooklm-adds">What NotebookLM Adds</h3>
<p><strong>Organization:</strong> Pulls information from multiple sources more efficiently than manual cross-referencing</p>
<p><strong>Quick reviews:</strong> Audio overviews provide fast refreshers</p>
<p><strong>Finding information:</strong> Faster than Ctrl+F through multiple documents</p>
</section>
<section id="what-it-doesnt-replace" class="level3">
<h3 class="anchored" data-anchor-id="what-it-doesnt-replace">What It Doesn’t Replace</h3>
<p><strong>Active recall:</strong> The act of retrieving information from memory without AI help</p>
<p><strong>Deep understanding:</strong> NotebookLM can summarize, but you still need to understand underlying concepts</p>
<p><strong>Practice problems:</strong> For quantitative subjects, you need to actually do practice problems</p>
</section>
<section id="the-risk" class="level3">
<h3 class="anchored" data-anchor-id="the-risk">The Risk</h3>
<p>The danger of tools like NotebookLM: they make it easy to feel like you’re studying without actually learning.</p>
<p>According to <a href="https://www.retrievalpractice.org/why-it-works">research on learning and retrieval practice</a>, passive review (like asking an AI questions) is less effective than active retrieval (testing yourself without assistance).</p>
<p>NotebookLM is useful for organization and review, but shouldn’t replace traditional study methods like: - Self-testing without AI help - Explaining concepts to others - Working through practice problems - Creating your own summaries and connections</p>
</section>
</section>
<section id="my-actual-study-approach" class="level2">
<h2 class="anchored" data-anchor-id="my-actual-study-approach">My Actual Study Approach</h2>
<section id="notebooklm-for-organization" class="level3">
<h3 class="anchored" data-anchor-id="notebooklm-for-organization">NotebookLM for Organization</h3>
<p>I’m using NotebookLM at the beginning of exam prep: 1. Upload all materials 2. Generate study guide to identify main topics 3. Listen to audio overview for high-level understanding 4. Use Q&amp;A to clarify confusing concepts</p>
</section>
<section id="traditional-methods-for-learning" class="level3">
<h3 class="anchored" data-anchor-id="traditional-methods-for-learning">Traditional Methods for Learning</h3>
<p>Then I switch to proven study techniques: - Create my own flashcards (without AI) - Self-test on major concepts - Practice explaining topics out loud - Work through case studies independently - Study with classmates</p>
</section>
<section id="notebooklm-as-reference" class="level3">
<h3 class="anchored" data-anchor-id="notebooklm-as-reference">NotebookLM as Reference</h3>
<p>I come back to NotebookLM when: - I need to verify a fact quickly - I can’t find something in my notes - I want to see how different sources explain the same concept</p>
<p>But the actual learning happens through traditional active study methods.</p>
</section>
</section>
<section id="final-assessment" class="level2">
<h2 class="anchored" data-anchor-id="final-assessment">Final Assessment</h2>
<p>I actually liked NotebookLM for exam prep. The source grounding is more reliable than general LLMs, the audio overview feature is genuinely useful, and the citations help verify information.</p>
<p><strong>Best use cases:</strong> - Organizing large amounts of course material - Quick reviews and refreshers - Finding specific information across multiple documents - Creating initial study guides</p>
<p><strong>Not good for:</strong> - Replacing active learning and retrieval practice - Complex mathematical or quantitative subjects - Creative synthesis beyond source material - Building deep conceptual understanding</p>
<p>For my MKTG exam specifically, NotebookLM was the right tool. It helped me organize content from lectures, readings, and transcripts efficiently. The audio overview gave me a quick review I could listen to while walking to class.</p>
<p>But I’m not relying on it as my primary study method. It’s a supplement to traditional studying, not a replacement.</p>
<p>The year of free Gemini Pro is nice, and I’ll keep using NotebookLM for course organization. But the actual studying—the hard work of learning and retaining information—still requires doing things the old-fashioned way: active recall, self-testing, and explaining concepts without AI help.</p>
<p>NotebookLM makes studying more efficient. It doesn’t make studying unnecessary.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>LLM</category>
  <category>professional</category>
  <category>daily-life</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/019_/019.html</guid>
  <pubDate>Tue, 21 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/019_/notebooklm-interface.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Superagency Review #2: Solutionism vs. Problemism</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/018_/018.html</link>
  <description><![CDATA[ 





<section id="chapter-3-what-could-possibly-go-right" class="level2">
<h2 class="anchored" data-anchor-id="chapter-3-what-could-possibly-go-right">Chapter 3: What Could Possibly Go Right</h2>
<p>This is part 2 of my review of Reid Hoffman and Greg Beato’s <em>Superagency</em>. Pages 48-94 cover Chapter 3, titled “What Could Possibly Go Right”—a deliberate play on words. Instead of the usual “what could go wrong,” Hoffman and Beato flip the framing to emphasize opportunity over risk.</p>
<p>This chapter introduces two competing worldviews: <strong>solutionism</strong> (the tech optimist’s belief that complex problems have technological fixes) and <strong>problemism</strong> (which Hoffman frames as the gloomer’s default mode of focusing on risks and downsides).</p>
<p>Let me break down why this framing is more complicated than the book presents it.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/018_/superagency-book-cover.jpg" alt="Superagency Book" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Superagency by Reid Hoffman and Greg Beato</em></p>
</section>
<section id="solutionism-technology-as-the-answer" class="level2">
<h2 class="anchored" data-anchor-id="solutionism-technology-as-the-answer">Solutionism: Technology as the Answer</h2>
<p>Hoffman defines <strong>solutionism</strong> as the belief that the world’s most vexing challenges have technological fixes. AI, in this view, is one of the most proven levers for creating change at scale.</p>
<section id="to-what-extent-is-this-true" class="level3">
<h3 class="anchored" data-anchor-id="to-what-extent-is-this-true">To What Extent Is This True?</h3>
<p>The book argues that technology has consistently solved major human problems: vaccines eradicated diseases, the internet democratized information, smartphones connected billions of people.</p>
<p>This is partially true. Technology has solved specific, well-defined problems. But “the world’s most vexing challenges” are rarely technical problems—they’re social, political, and economic problems that happen to have technical components.</p>
<p>Consider climate change. We have the technology to transition to renewable energy. The “vexing challenge” isn’t the technology—it’s coordinating global political will, managing economic transitions, and overcoming entrenched interests. No AI breakthrough solves those problems.</p>
</section>
<section id="the-question-of-scale" class="level3">
<h3 class="anchored" data-anchor-id="the-question-of-scale">The Question of Scale</h3>
<p>Hoffman emphasizes that technology creates change “at scale.” This is true—technology can reach millions or billions of people quickly.</p>
<p>But here’s the critical question the book doesn’t adequately address: <strong>Are the positives of technology distributed evenly at scale?</strong></p>
<p>The internet connected billions of people, but: - Who profited most? Tech companies and early adopters in wealthy countries - Who bears the costs? Workers displaced by automation, communities disrupted by platform economies, users whose data is monetized - Who gets left behind? People without access, those who can’t afford devices, communities where infrastructure wasn’t built</p>
<p>Solutionism tends to measure success by aggregate impact while ignoring distributional questions. “We connected 3 billion people” sounds impressive, but if those 3 billion are predominantly in wealthy countries while the other 4 billion remain disconnected, that’s not universal progress.</p>
</section>
<section id="is-technology-really-the-most-proven-lever" class="level3">
<h3 class="anchored" data-anchor-id="is-technology-really-the-most-proven-lever">Is Technology Really the Most Proven Lever?</h3>
<p>The book asserts that technology is among “the most proven levers for creating change.” But proven in what sense?</p>
<p>Social movements, policy changes, and institutional reforms have also created massive change at scale: - Civil rights legislation transformed society - Public health systems eradicated diseases (often more than vaccines alone) - Labor organizing improved working conditions - Democratic reforms expanded political participation</p>
<p>These weren’t primarily technological solutions. They were social and political solutions that sometimes used technology as a tool.</p>
<p>The solutionist framing centers technology as the primary driver of progress, which minimizes the role of human organization, policy, and collective action.</p>
</section>
</section>
<section id="problemism-the-gloomers-worldview" class="level2">
<h2 class="anchored" data-anchor-id="problemism-the-gloomers-worldview">Problemism: The Gloomer’s Worldview</h2>
<p>Hoffman introduces <strong>problemism</strong> as the default mode of skeptics (gloomers like me). Problemists focus on what could go wrong, potential harms, and unintended consequences.</p>
<p>The chapter frames problemism as: - An obstacle to progress - Overly cautious and risk-averse - Focused on negatives at the expense of recognizing benefits</p>
<section id="is-this-scapegoating" class="level3">
<h3 class="anchored" data-anchor-id="is-this-scapegoating">Is This Scapegoating?</h3>
<p>There’s something convenient about positioning skeptics as the problem. If gloomers are just pessimists who can’t see opportunities, then their concerns can be dismissed as psychological rather than substantive.</p>
<p>But “problemism” isn’t just pessimism—it’s pattern recognition based on history. Every major technological revolution has produced: - Massive distributional inequalities - Unintended harmful consequences - Power concentration among early adopters - Disruption of existing social structures</p>
<p>Pointing out these patterns isn’t holding progress back. It’s asking: “Given what we know about past technological disruptions, how can we avoid repeating the same mistakes?”</p>
</section>
<section id="has-big-tech-only-created-progress" class="level3">
<h3 class="anchored" data-anchor-id="has-big-tech-only-created-progress">Has Big Tech Only Created Progress?</h3>
<p>The book frames problemists as entities “holding progress back.” But this assumes that what Big Tech calls “progress” is universally beneficial.</p>
<p>Consider social media—a technology that Big Tech champions as connecting humanity: - <strong>Positive:</strong> Enabled global communication, grassroots organizing, democratized content creation - <strong>Negative:</strong> Amplified misinformation, enabled surveillance capitalism, contributed to mental health crises, facilitated political manipulation</p>
<p>Did social media create progress? For some people, yes. For others, it created new problems. Calling skeptics “problemists” for pointing out the downsides doesn’t make those downsides disappear—it just silences legitimate critique.</p>
</section>
<section id="unrestrained-innovation-vs.-thoughtful-innovation" class="level3">
<h3 class="anchored" data-anchor-id="unrestrained-innovation-vs.-thoughtful-innovation">Unrestrained Innovation vs.&nbsp;Thoughtful Innovation</h3>
<p>The book frames problemism as harmful to society because it slows down innovation. But here’s the question: <strong>Isn’t stepping back and rethinking innovation, rather than pursuing unrestrained innovation, ultimately good?</strong></p>
<p>We’ve learned from history that “move fast and break things” causes real harm: - Facebook’s rapid expansion broke democratic discourse - Uber’s disruption broke labor protections - Cryptocurrency’s innovation broke financial stability for many who invested</p>
<p>“Problemism”—if we’re calling it that—is the practice of asking “should we?” before “can we?” That’s not holding progress back. That’s responsible innovation.</p>
<p>According to <a href="https://www.nature.com/articles/s42256-021-00445-7">research on responsible AI development</a>, incorporating critical perspectives early in development leads to better outcomes than addressing harms reactively after deployment. “Problemism” is just another term for proactive risk assessment.</p>
</section>
</section>
<section id="the-kokobot-example-when-problemism-was-right" class="level2">
<h2 class="anchored" data-anchor-id="the-kokobot-example-when-problemism-was-right">The Kokobot Example: When Problemism Was Right</h2>
<p>Hoffman discusses Kokobot, an AI mental health chatbot that faced significant backlash. The book presents this as an example of how problemism stifles innovation in mental health.</p>
<p>But let’s look at what actually happened with Kokobot and similar AI mental health tools.</p>
<section id="the-challenges" class="level3">
<h3 class="anchored" data-anchor-id="the-challenges">The Challenges</h3>
<p>Critics raised concerns about: - <strong>Safety:</strong> Could an AI chatbot adequately handle users in crisis? - <strong>Privacy:</strong> Was user mental health data being properly protected? - <strong>Effectiveness:</strong> Did these tools actually help, or just provide the appearance of help? - <strong>Replacement of human care:</strong> Would employers use cheap chatbots instead of providing actual mental health benefits?</p>
<p>These weren’t hypothetical concerns. Studies showed that: - Some mental health chatbots gave harmful advice during crisis situations - User data from mental health apps was sold to advertisers - Many users reported the chatbots felt impersonal and unhelpful - Companies did use chatbots as cheaper alternatives to human therapists</p>
</section>
<section id="the-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="the-opportunities">The Opportunities</h3>
<p>Hoffman argues that despite these concerns, AI mental health tools offer opportunities: - Accessible mental health support for underserved populations - 24/7 availability for people in crisis - Reduced stigma through anonymous digital interfaces - Scalable support that human therapists alone can’t provide</p>
<p>These are real benefits. But here’s where solutionism and problemism diverge:</p>
<p><strong>Solutionist view:</strong> The technology has benefits, so we should deploy it widely and fix problems as they arise.</p>
<p><strong>Problemist view:</strong> The technology has serious risks, so we should address those risks before wide deployment.</p>
</section>
<section id="who-was-right" class="level3">
<h3 class="anchored" data-anchor-id="who-was-right">Who Was Right?</h3>
<p>In the case of Kokobot and similar tools, the “problemists” were vindicated. Multiple mental health chatbots: - Failed to detect suicidal ideation - Gave inappropriate advice - Violated user privacy - Created false sense of receiving adequate care</p>
<p>The backlash wasn’t people being pessimistic—it was people recognizing that mental health is high-stakes, and deploying untested AI tools in that domain was reckless.</p>
<p>Hoffman frames this as problemism holding back progress. I’d frame it as problemism preventing harm.</p>
</section>
</section>
<section id="the-false-dichotomy" class="level2">
<h2 class="anchored" data-anchor-id="the-false-dichotomy">The False Dichotomy</h2>
<p>The biggest issue with this chapter is how it sets up solutionism vs.&nbsp;problemism as opposing worldviews, with solutionism positioned as forward-thinking and problemism as regressive.</p>
<p>This is a false dichotomy.</p>
<section id="you-can-believe-both" class="level3">
<h3 class="anchored" data-anchor-id="you-can-believe-both">You Can Believe Both</h3>
<p>It’s possible to believe: - Technology can solve important problems AND - Technology creates serious risks that need careful management</p>
<p>It’s possible to be: - Excited about AI’s potential AND - Concerned about its misuse</p>
<p>The productive position isn’t pure solutionism or pure problemism—it’s <strong>conditional optimism</strong>: being optimistic about technology’s potential while insisting on safeguards, accountability, and equitable distribution of benefits.</p>
</section>
<section id="the-rhetorical-strategy" class="level3">
<h3 class="anchored" data-anchor-id="the-rhetorical-strategy">The Rhetorical Strategy</h3>
<p>By framing critics as “problemists,” Hoffman creates a rhetorical strategy where: - Skepticism = pessimism = obstruction - Optimism = innovation = progress</p>
<p>This shuts down legitimate critique by making it seem like an attitude problem rather than a substantive concern.</p>
<p>But asking hard questions isn’t pessimism. It’s due diligence.</p>
</section>
<section id="what-this-chapter-misses" class="level3">
<h3 class="anchored" data-anchor-id="what-this-chapter-misses">What This Chapter Misses</h3>
<p>The chapter doesn’t adequately address: - <strong>Power dynamics:</strong> Who controls AI development and who benefits? - <strong>Historical patterns:</strong> Why should we expect AI to be different from past technologies in terms of distributional inequity? - <strong>Alternative approaches:</strong> Could we pursue AI development with built-in safeguards rather than the “deploy first, fix later” model? - <strong>The cost of being wrong:</strong> If solutionists are wrong and AI causes serious harm, what’s the cost? If problemists are wrong and we move slower than necessary, what’s the cost?</p>
<p>Asymmetric risk matters. The cost of deploying harmful AI is potentially much higher than the cost of taking extra time to get it right.</p>
</section>
</section>
<section id="my-take-problemism-is-pattern-recognition" class="level2">
<h2 class="anchored" data-anchor-id="my-take-problemism-is-pattern-recognition">My Take: Problemism Is Pattern Recognition</h2>
<p>After reading Chapter 3, I’m more convinced that “problemism”—if we’re calling it that—is necessary and valuable.</p>
<p>It’s not pessimism. It’s pattern recognition based on history: - The Industrial Revolution increased productivity but created brutal working conditions - Social media connected people but amplified misinformation and surveillance - The internet democratized information but enabled new forms of manipulation</p>
<p>Every time, the solutionists said “the benefits outweigh the risks, let’s move fast.” Every time, the problemists said “wait, let’s think about the downsides.” And every time, we later discovered the problemists were identifying real issues that should have been addressed earlier.</p>
<p>Hoffman positions problemism as holding society back. I’d argue problemism is the only thing preventing us from repeating the same mistakes at an accelerated pace.</p>
<section id="what-good-problemism-looks-like" class="level3">
<h3 class="anchored" data-anchor-id="what-good-problemism-looks-like">What Good Problemism Looks Like</h3>
<p>Productive skepticism isn’t just saying “AI bad.” It’s asking: - Who benefits from this technology and who bears the costs? - What safeguards prevent misuse? - How do we ensure benefits are distributed equitably? - What happens if this goes wrong, and how do we mitigate that? - What can we learn from past technological transitions?</p>
<p>These questions don’t stop innovation. They guide innovation toward better outcomes.</p>
</section>
<section id="the-real-question" class="level3">
<h3 class="anchored" data-anchor-id="the-real-question">The Real Question</h3>
<p>The chapter asks: “What could possibly go right?”</p>
<p>But the more important question is: “For whom will things go right, and at whose expense?”</p>
<p>Solutionism assumes universal benefit. Problemism asks about distribution. And history suggests the problemists are asking the right question.</p>
<p>I’ll keep reading, but so far, <em>Superagency</em> is making the case for optimism without adequately addressing why past optimism about technology has often proven naive.</p>
</section>
</section>
<section id="up-next" class="level2">
<h2 class="anchored" data-anchor-id="up-next">Up Next</h2>
<p>Review #3 will cover pages 95-141. I’m curious to see if the book addresses distributional concerns more seriously, or if it continues positioning skepticism as the primary obstacle to AI progress.</p>
<p>Stay tuned.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>book-review</category>
  <category>skeptical</category>
  <category>research</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/018_/018.html</guid>
  <pubDate>Sun, 19 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/018_/superagency-book-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Creating Music with AI: Suno for Marketing Projects</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/017_/017.html</link>
  <description><![CDATA[ 





<section id="making-music-without-musical-training" class="level2">
<h2 class="anchored" data-anchor-id="making-music-without-musical-training">Making Music Without Musical Training</h2>
<p>For my Marketing 7340 class with Dr.&nbsp;Gideon Nave, I needed to create original music for a Corona ad campaign. The problem: I have no formal music production training. The solution: Suno AI, a tool that generates music from text prompts and voice recordings.</p>
<p>I paid $10/month for Suno Pro to test whether AI could actually produce usable marketing music. Here’s what happened.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/017_/suno-interface.jpg" alt="Suno AI Interface" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Suno AI’s music generation interface</em></p>
</section>
<section id="the-assignment-corona-ad-music" class="level2">
<h2 class="anchored" data-anchor-id="the-assignment-corona-ad-music">The Assignment: Corona Ad Music</h2>
<p><strong>Brief:</strong> - <strong>Concept:</strong> Funky, Latin, afrohouse beat that inspires dancing - <strong>Instruments:</strong> Drums, trumpets, soothing vocals - <strong>Inspiration:</strong> Barry Can’t Swim style - <strong>Tempo:</strong> 120-140 BPM - <strong>Purpose:</strong> Corona advertisement - <strong>Mood:</strong> Beach resort, enjoyment, refreshing, sunbathed</p>
<p><strong>Lyrics concept:</strong></p>
<pre><code>[Chorus]
Chasing the sun
Chasing the glow
Where the ocean whispers what we already know
With a Corona in hand
Time comes undone
Living the moment
Chasing the sun</code></pre>
<p><a href="https://suno.com/s/pVpIq9q52NzBOw79">Listen to the Corona ad track</a></p>
</section>
<section id="how-suno-actually-works" class="level2">
<h2 class="anchored" data-anchor-id="how-suno-actually-works">How Suno Actually Works</h2>
<section id="voice-recording-as-foundation" class="level3">
<h3 class="anchored" data-anchor-id="voice-recording-as-foundation">Voice Recording as Foundation</h3>
<p>I started by recording my own voice singing low and high tones. Suno used this as the base vocal texture and extended it into a full track. This “cover” feature lets you input raw vocals that the AI then transforms.</p>
</section>
<section id="lyrics-generation-and-editing" class="level3">
<h3 class="anchored" data-anchor-id="lyrics-generation-and-editing">Lyrics Generation and Editing</h3>
<p>Suno has a lyrics generator, but I quickly learned the AI-generated lyrics were generic. I used the generator as a starting point, then heavily edited:</p>
<p><strong>Original AI lyrics:</strong> Standard party/dance themes <strong>My edits (in bold):</strong> Added specific production notes like: - <code>[Add intense percussion]</code> - <code>[Add marimbas and bongos]</code> - <code>[Make it hypnotic]</code> - <code>[Build anticipation, create anxiety and excitement for the chorus]</code></p>
</section>
<section id="style-prompting" class="level3">
<h3 class="anchored" data-anchor-id="style-prompting">Style Prompting</h3>
<p>The key to good output was detailed style prompts:</p>
<pre><code>140bpm. Deephouse, melodic, hypnotic. 
Add layers of organic, progressive house elements. 
Add unexpected elements. 
Use Rufus Du Sol as inspiration.</code></pre>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/017_/suno-editing-interface.jpg" alt="Suno Editing" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Editing lyrics and adding production notes in Suno</em></p>
</section>
</section>
<section id="the-iteration-process" class="level2">
<h2 class="anchored" data-anchor-id="the-iteration-process">The Iteration Process</h2>
<section id="first-attempt-complete-failure" class="level3">
<h3 class="anchored" data-anchor-id="first-attempt-complete-failure">First Attempt: Complete Failure</h3>
<p>My initial generated song was terrible. The AI-generated lyrics were cliché, the production was muddy, and it didn’t capture the vibe I wanted at all.</p>
<p><strong>What went wrong:</strong> - Generic party lyrics that felt empty - Overproduced sound that lost the organic beach feel - Wrong energy—too aggressive, not relaxed enough</p>
<p>I realized I needed to be much more specific in my prompts.</p>
</section>
<section id="second-attempt-rufus-du-sol-inspiration" class="level3">
<h3 class="anchored" data-anchor-id="second-attempt-rufus-du-sol-inspiration">Second Attempt: Rufus Du Sol Inspiration</h3>
<p>I prompted: “Change the lyrics to be more Rufus Du Sol-like.”</p>
<p>Then I restructured the entire song with detailed production notes:</p>
<pre><code>[Intro - Another Voice, Raspy Voice]
[Add ethereal synths and deep bass]
(Ahora)
El viaje empieza
[Make pause for drop]

[Verse 1 - Another Voice, drop here]
La atmósfera te abraza, ¿la notas?
Fluye conmigo, sin pausa, sin sombras

[Another pause, longer]
[Build anticipation, create anxiety and excitement 
for the chorus with drums, marimbas, bongos, and trumpets. 
Very light instrumental at the beginning.]

[Chorus - Main Voice]
Let the waves of sound enfold
We're captive, our spirits bold</code></pre>
<p>This version was better. The AI actually responded to the detailed production notes and created more dynamic arrangements.</p>
<p><a href="https://suno.com/s/cVPcEWzySbkOZdG">Listen to the Rufus-inspired version</a></p>
</section>
<section id="third-attempt-corona-ad-track" class="level3">
<h3 class="anchored" data-anchor-id="third-attempt-corona-ad-track">Third Attempt: Corona Ad Track</h3>
<p>For the final Corona track, I stripped down the complexity and focused on the beach resort vibe: - Simpler, more direct lyrics about “chasing the sun” - Specific instrument calls (trumpets, drums) - Barry Can’t Swim inspiration for that organic house feel - Tempo locked at 120-140 BPM</p>
<p>This was the most successful version.</p>
</section>
</section>
<section id="what-actually-works" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-works">What Actually Works</h2>
<section id="specificity-in-prompts" class="level3">
<h3 class="anchored" data-anchor-id="specificity-in-prompts">Specificity in Prompts</h3>
<p>Vague prompts like “make happy music” produce generic results. Detailed prompts with: - Specific BPM - Named artist references - Exact instruments - Production technique descriptions</p>
<p>…produce much better output.</p>
</section>
<section id="production-notes-within-lyrics" class="level3">
<h3 class="anchored" data-anchor-id="production-notes-within-lyrics">Production Notes Within Lyrics</h3>
<p>The bracketed production notes <code>[Add trumpet solo]</code> or <code>[Build anticipation]</code> actually work. Suno interprets these and adjusts the arrangement accordingly.</p>
</section>
<section id="voice-input-as-foundation" class="level3">
<h3 class="anchored" data-anchor-id="voice-input-as-foundation">Voice Input as Foundation</h3>
<p>Recording my own voice gave the track a unique texture. Even though the AI heavily processed it, there’s something more authentic than purely synthetic vocals.</p>
</section>
<section id="iteration-is-essential" class="level3">
<h3 class="anchored" data-anchor-id="iteration-is-essential">Iteration Is Essential</h3>
<p>The first output is never good. You need multiple generations, tweaking prompts each time based on what worked and what didn’t.</p>
</section>
</section>
<section id="serious-limitations" class="level2">
<h2 class="anchored" data-anchor-id="serious-limitations">Serious Limitations</h2>
<section id="lack-of-fine-control" class="level3">
<h3 class="anchored" data-anchor-id="lack-of-fine-control">Lack of Fine Control</h3>
<p>You can suggest instruments and styles, but you can’t control: - Exact timing of drops or builds - Precise mixing levels - Specific chord progressions - Individual track editing</p>
<p>A real producer would have much more granular control.</p>
</section>
<section id="inconsistent-output-quality" class="level3">
<h3 class="anchored" data-anchor-id="inconsistent-output-quality">Inconsistent Output Quality</h3>
<p>Even with the same prompt, Suno generates wildly different results. Sometimes it nails the vibe, sometimes it completely misses. You’re rolling the dice each generation.</p>
</section>
<section id="generic-elements" class="level3">
<h3 class="anchored" data-anchor-id="generic-elements">Generic Elements</h3>
<p>Despite specific prompts, certain elements always sound “AI-generated”: - Vocal processing has a distinctive Suno quality - Transitions can feel abrupt or unnatural - Complex arrangements often get muddied</p>
</section>
<section id="limited-musical-understanding" class="level3">
<h3 class="anchored" data-anchor-id="limited-musical-understanding">Limited Musical Understanding</h3>
<p>Suno doesn’t understand music theory deeply. If you ask for a specific harmonic progression or complex rhythmic pattern, it might approximate but not execute precisely.</p>
</section>
<section id="copyright-and-licensing-questions" class="level3">
<h3 class="anchored" data-anchor-id="copyright-and-licensing-questions">Copyright and Licensing Questions</h3>
<p>For a real commercial project (like an actual Corona ad), there are murky questions: - Who owns the rights to AI-generated music? - Can you legally use Suno output in paid advertising? - What happens if the AI “learned” from copyrighted material?</p>
<p>For a class project this is fine, but for real commercial use, these are unresolved issues.</p>
</section>
</section>
<section id="is-10month-worth-it" class="level2">
<h2 class="anchored" data-anchor-id="is-10month-worth-it">Is $10/Month Worth It?</h2>
<section id="what-you-get-with-suno-pro" class="level3">
<h3 class="anchored" data-anchor-id="what-you-get-with-suno-pro">What You Get with Suno Pro</h3>
<ul>
<li>More generation credits per month</li>
<li>Higher quality audio output</li>
<li>Commercial use rights (with caveats)</li>
<li>Faster generation times</li>
</ul>
</section>
<section id="for-this-assignment-yes" class="level3">
<h3 class="anchored" data-anchor-id="for-this-assignment-yes">For This Assignment: Yes</h3>
<p>For a marketing class project where I needed original music quickly, <img src="https://latex.codecogs.com/png.latex?10%20was%20worth%20it.%20The%20alternative%20would%20be:%0A-%20Learning%20actual%20music%20production%20(months/years)%0A-%20Hiring%20a%20producer%20(">hundreds to $thousands) - Using stock music (doesn’t fit specific brief)</p>
</section>
<section id="for-serious-music-production-no" class="level3">
<h3 class="anchored" data-anchor-id="for-serious-music-production-no">For Serious Music Production: No</h3>
<p>If you’re actually trying to produce professional music, Suno is a novelty, not a tool. The limitations are too significant, and the output quality isn’t competitive with human-produced tracks.</p>
</section>
<section id="the-real-use-case" class="level3">
<h3 class="anchored" data-anchor-id="the-real-use-case">The Real Use Case</h3>
<p>Suno is best for: - Rapid prototyping of musical ideas - Creating placeholder tracks for projects - Generating inspiration for actual musicians - Quick demos for pitches or presentations</p>
<p>It’s not a replacement for music production, but it’s a useful sketching tool.</p>
</section>
</section>
<section id="what-this-means-for-marketing" class="level2">
<h2 class="anchored" data-anchor-id="what-this-means-for-marketing">What This Means for Marketing</h2>
<section id="democratization-of-content-creation" class="level3">
<h3 class="anchored" data-anchor-id="democratization-of-content-creation">Democratization of Content Creation</h3>
<p>Tools like Suno lower the barrier to creating original audio content. Small brands or student projects can now generate custom music without big budgets.</p>
</section>
<section id="quality-vs.-cost-tradeoff" class="level3">
<h3 class="anchored" data-anchor-id="quality-vs.-cost-tradeoff">Quality vs.&nbsp;Cost Tradeoff</h3>
<p>The output isn’t professional-grade, but it’s “good enough” for many contexts: - Social media content - Internal presentations - Pitch decks - Testing concepts before investing in production</p>
</section>
<section id="the-authenticity-question" class="level3">
<h3 class="anchored" data-anchor-id="the-authenticity-question">The Authenticity Question</h3>
<p>If audiences knew the Corona ad used AI-generated music, would they care? Would it affect brand perception?</p>
<p>This is an open question in marketing. Some consumers might appreciate the innovation; others might see it as cheap or inauthentic.</p>
</section>
<section id="professional-musicians-concern" class="level3">
<h3 class="anchored" data-anchor-id="professional-musicians-concern">Professional Musicians’ Concern</h3>
<p>From a music industry perspective, tools like Suno are concerning. If brands can generate “good enough” music for $10/month, that undercuts professional composers and producers.</p>
<p>The counterargument: truly great music still requires human creativity, and AI tools might just handle the low-end market that wasn’t hiring professionals anyway.</p>
</section>
</section>
<section id="final-assessment" class="level2">
<h2 class="anchored" data-anchor-id="final-assessment">Final Assessment</h2>
<p>Suno AI successfully generated usable music for my marketing class project. The Corona ad track captured the beach resort vibe and had the right energy for the brief.</p>
<p>But the process revealed clear limitations: - Heavy iteration required (first attempts were unusable) - Lack of fine control over production elements - Output has distinctive “AI” quality - Not suitable for professional commercial use</p>
<p><strong>For class projects and rapid prototyping:</strong> Suno is genuinely useful. It lets you explore musical ideas quickly without technical skills.</p>
<p><strong>For real marketing campaigns:</strong> You’d still want a human producer. The AI can generate ideas or placeholder tracks, but the final product needs human refinement.</p>
<p>The $10/month was worth it for this specific use case, but I’m canceling the subscription after the project ends. It’s a tool I needed temporarily, not something I’d use regularly.</p>
<p>Most importantly: AI music generation is impressive technically, but it highlights what human musicians bring—intentionality, emotional depth, and creative choices that respond to cultural context in ways algorithms can’t replicate.</p>
<p>The Corona ad track works for a student project. But Corona the actual company? They’re still hiring real composers.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>creative</category>
  <category>professional</category>
  <category>marketing</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/017_/017.html</guid>
  <pubDate>Fri, 17 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/017_/suno-interface.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Meditation Apps: Is the Personalization Real?</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/016_/016.html</link>
  <description><![CDATA[ 





<section id="stress-testing-ai-meditation" class="level2">
<h2 class="anchored" data-anchor-id="stress-testing-ai-meditation">Stress Testing AI Meditation</h2>
<p>School and recruiting have been picking up intensity—midterms, case prep, networking events, finance interviews. I’ve been consistently stressed and not sleeping well. A friend suggested trying Calm, the meditation app that claims to use AI for personalized relaxation.</p>
<p>I’m skeptical of wellness apps in general, but I figured this was a good test case: if AI personalization works anywhere, it should work when I’m actually stressed and need it. So I signed up for a week to see if the “AI-powered personalization” is real or just marketing.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/016_/calm-app-interface.jpg" alt="Calm App Interface" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Calm’s interface showing meditation recommendations</em></p>
</section>
<section id="what-these-apps-claim-to-personalize" class="level2">
<h2 class="anchored" data-anchor-id="what-these-apps-claim-to-personalize">What These Apps Claim to Personalize</h2>
<section id="the-ai-features" class="level3">
<h3 class="anchored" data-anchor-id="the-ai-features">The AI Features</h3>
<p>According to the app and marketing materials: - <strong>Personalized daily recommendations</strong> based on your stress patterns - <strong>Adaptive session length</strong> that adjusts to your schedule - <strong>Content matching</strong> that learns which meditation styles work best for you - <strong>Check-in analysis</strong> that tracks your emotional state over time - <strong>Smart reminders</strong> that send notifications when you’re most likely to need meditation</p>
</section>
<section id="the-setup-process" class="level3">
<h3 class="anchored" data-anchor-id="the-setup-process">The Setup Process</h3>
<p>When I first opened the app, it asked: - Why I’m using Calm (options: stress, sleep, focus, anxiety, etc.) - My experience level with meditation (beginner, intermediate, experienced) - What time of day I prefer to meditate - Whether I want daily reminders</p>
<p>Then it presented a “personalized” home screen with recommended meditations.</p>
<p>Right away, I’m wondering: is this AI learning, or just a decision tree based on my initial answers?</p>
</section>
</section>
<section id="my-week-of-testing" class="level2">
<h2 class="anchored" data-anchor-id="my-week-of-testing">My Week of Testing</h2>
<section id="day-1-2-initial-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="day-1-2-initial-recommendations">Day 1-2: Initial Recommendations</h3>
<p>The app recommended: - “Managing Stress” - 10 minute guided meditation - “Calming Anxiety” - 15 minute session - “Sleep Stories” for nighttime</p>
<p>These matched what I selected during setup (stress management). But they’re also probably what everyone who selects “stress” gets recommended. Nothing personalized yet.</p>
<p>I tried the 10-minute stress management session. It was fine—standard guided meditation with breathing exercises and body scan. At the end, it asked “How do you feel?” with options: Calm, Relaxed, Same, Restless.</p>
<p>I selected “Relaxed.” Let’s see if the app learns from this.</p>
</section>
<section id="day-3-4-different-stress-levels" class="level3">
<h3 class="anchored" data-anchor-id="day-3-4-different-stress-levels">Day 3-4: Different Stress Levels</h3>
<p>On Day 3, I had two interviews back-to-back. Before the first one, I did a quick 5-minute “Focus” meditation the app recommended.</p>
<p>After interviews, I was exhausted and stressed. Opened the app again that evening. It recommended… the same 10-minute stress management session from Day 1.</p>
<p>Wait—shouldn’t it notice I used the app twice in one day, during high-stress moments, and adjust its recommendations? Maybe suggest something longer or more intensive?</p>
<p>Instead, the recommendations looked identical to Day 1.</p>
</section>
<section id="day-5-7-checking-for-patterns" class="level3">
<h3 class="anchored" data-anchor-id="day-5-7-checking-for-patterns">Day 5-7: Checking for Patterns</h3>
<p>I deliberately tried different meditation types: - Morning: 7-minute “Daily Calm” meditation - Afternoon: 10-minute breathing exercise - Night: 20-minute sleep story</p>
<p>Each time, I marked how I felt afterward. Sometimes “Calm,” sometimes “Same,” once “Restless” (I was too stressed to focus).</p>
<p>By Day 7, my recommendations were… still basically the same as Day 1. A few new options appeared in the “Recommended for You” section, but they seemed randomly rotated rather than based on what I’d actually used or found helpful.</p>
</section>
</section>
<section id="is-this-actually-ai-personalization" class="level2">
<h2 class="anchored" data-anchor-id="is-this-actually-ai-personalization">Is This Actually AI Personalization?</h2>
<section id="what-would-real-personalization-look-like" class="level3">
<h3 class="anchored" data-anchor-id="what-would-real-personalization-look-like">What Would Real Personalization Look Like?</h3>
<p>If Calm were truly using AI to personalize my experience, I’d expect:</p>
<p><strong>Usage pattern recognition:</strong> Notice that I meditate more frequently during high-stress periods (like Day 3 with interviews) and suggest more intensive practices during those times.</p>
<p><strong>Effectiveness tracking:</strong> If I consistently rate 7-minute sessions as “Relaxing” but 20-minute sessions as “Restless” (because I can’t focus that long when stressed), it should recommend shorter sessions.</p>
<p><strong>Time-of-day optimization:</strong> Learn that I actually use the app most in the evening, not morning, despite saying “morning” in my initial setup.</p>
<p><strong>Content adaptation:</strong> If I skip certain meditation styles repeatedly, stop recommending them.</p>
</section>
<section id="what-i-actually-observed" class="level3">
<h3 class="anchored" data-anchor-id="what-i-actually-observed">What I Actually Observed</h3>
<p>The recommendations seemed based on: - My initial survey answers (static profile) - General content rotation (everyone sees different things each day) - Basic category matching (I said “stress,” so I get stress-related content)</p>
<p>This isn’t machine learning—it’s a preference quiz with some randomization.</p>
</section>
<section id="the-check-in-feature" class="level3">
<h3 class="anchored" data-anchor-id="the-check-in-feature">The “Check-In” Feature</h3>
<p>Calm asks “How do you feel?” after each session. This data could theoretically train a model to learn what works for me.</p>
<p>But after a week of providing this feedback, I saw no evidence it changed anything. The app didn’t: - Suggest more of what I rated highly - Avoid what I rated poorly - Adjust session length based on my responses - Change reminder timing based on when I actually use the app</p>
<p>According to <a href="https://www.sciencedirect.com/science/article/pii/S2949916X24000525">research on adaptive meditation apps</a>, truly personalized digital interventions should show measurable adaptation over time. I didn’t see this.</p>
</section>
</section>
<section id="ai-meditation-vs.-regular-guided-meditation" class="level2">
<h2 class="anchored" data-anchor-id="ai-meditation-vs.-regular-guided-meditation">AI Meditation vs.&nbsp;Regular Guided Meditation</h2>
<section id="what-makes-meditation-effective" class="level3">
<h3 class="anchored" data-anchor-id="what-makes-meditation-effective">What Makes Meditation Effective</h3>
<p>Research on meditation effectiveness shows it depends on: - Consistency of practice - Finding techniques that match your needs - Appropriate session length for your focus capacity - Quality of instruction</p>
<p>None of these inherently require AI. A good meditation teacher, a simple YouTube video, or even free apps without “AI” can provide these.</p>
</section>
<section id="does-ai-add-value" class="level3">
<h3 class="anchored" data-anchor-id="does-ai-add-value">Does AI Add Value?</h3>
<p>In theory, AI personalization could help by: - Learning which techniques work for your specific stress patterns - Adapting difficulty as you build meditation capacity - Identifying optimal times for practice based on your schedule</p>
<p>But Calm doesn’t seem to do this. The “AI” label appears to be marketing rather than meaningful personalization.</p>
</section>
<section id="the-free-alternative" class="level3">
<h3 class="anchored" data-anchor-id="the-free-alternative">The Free Alternative</h3>
<p>I compared Calm to free guided meditations on YouTube and Spotify. Many are: - Same quality instruction - Same variety of styles and lengths - No subscription fee - Equally effective</p>
<p>The main advantage of these apps is convenience (everything in one app) and production quality (nice UI, good voice actors). But these aren’t AI features—they’re just app design.</p>
<p>You could manually build a YouTube playlist of meditations that work for you, and that “personalization” would be more effective than Calm’s alleged AI.</p>
</section>
</section>
<section id="the-ai-ification-of-wellness-apps" class="level2">
<h2 class="anchored" data-anchor-id="the-ai-ification-of-wellness-apps">The AI-ification of Wellness Apps</h2>
<section id="why-everything-is-ai-powered-now" class="level3">
<h3 class="anchored" data-anchor-id="why-everything-is-ai-powered-now">Why Everything Is “AI-Powered” Now</h3>
<p>Calm isn’t alone. Nearly every wellness app now claims AI: - “AI-powered” workout plans - “AI-driven” nutrition coaching - “AI-enhanced” sleep tracking - “AI-personalized” meditation</p>
<p>The pattern is clear: adding “AI” to your app: - Justifies higher subscription prices (Calm is $70/year) - Makes the app sound more sophisticated - Appeals to tech-forward users - Differentiates from free alternatives</p>
</section>
<section id="whats-probably-happening" class="level3">
<h3 class="anchored" data-anchor-id="whats-probably-happening">What’s Probably Happening</h3>
<p>Most “AI personalization” in wellness apps is likely: - Simple if-then logic based on user inputs - Random content rotation to create variety - Basic categorization (stress → stress content) - A/B testing to optimize engagement (not personalization)</p>
<p>These are useful features, but they’re not AI in any meaningful sense.</p>
</section>
<section id="the-premium-price-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-premium-price-problem">The Premium Price Problem</h3>
<p>Calm charges $70/year partly because of its AI personalization promise. But if the personalization isn’t real, you’re paying a premium for: - A nice UI - Good production quality - Convenient access to meditation content</p>
<p>These are fine features, but they don’t require AI or justify the AI marketing.</p>
</section>
</section>
<section id="did-it-actually-help-with-stress" class="level2">
<h2 class="anchored" data-anchor-id="did-it-actually-help-with-stress">Did It Actually Help With Stress?</h2>
<section id="the-honest-assessment" class="level3">
<h3 class="anchored" data-anchor-id="the-honest-assessment">The Honest Assessment</h3>
<p>Yes, using Calm helped me feel less stressed during recruiting season. But I’m pretty sure this had nothing to do with AI:</p>
<p><strong>Meditation works:</strong> Taking 10 minutes to breathe and focus helps reduce stress. This is true whether you use a paid app, YouTube, or just sit quietly.</p>
<p><strong>Guided instruction helps:</strong> Having someone guide you through meditation is easier than doing it alone, especially as a beginner. But good instruction doesn’t require AI.</p>
<p><strong>Convenience matters:</strong> Having all meditations in one app makes it more likely I’ll actually do it. But this is about app design, not AI.</p>
<p><strong>Reminder system:</strong> The daily notifications helped build a habit. Again, not AI—just push notifications.</p>
</section>
<section id="would-free-alternatives-work-as-well" class="level3">
<h3 class="anchored" data-anchor-id="would-free-alternatives-work-as-well">Would Free Alternatives Work as Well?</h3>
<p>Probably yes. The benefit came from: 1. Deciding to prioritize meditation during a stressful period 2. Having accessible guided content 3. Following through consistently</p>
<p>None of this required Calm specifically or its “AI” features.</p>
</section>
<section id="the-placebo-question" class="level3">
<h3 class="anchored" data-anchor-id="the-placebo-question">The Placebo Question</h3>
<p>There’s a possibility that believing the app is “personalized” makes it more effective through placebo effect. If you think the AI is customizing meditations for your specific needs, you might engage more seriously.</p>
<p>But this raises an ethical question: should companies charge premium prices for placebo effects based on false AI claims?</p>
</section>
</section>
<section id="should-you-use-ai-meditation-apps" class="level2">
<h2 class="anchored" data-anchor-id="should-you-use-ai-meditation-apps">Should You Use AI Meditation Apps?</h2>
<section id="use-them-if" class="level3">
<h3 class="anchored" data-anchor-id="use-them-if">Use Them If:</h3>
<ul>
<li>You want convenient access to guided meditation</li>
<li>You find the UI and production quality motivating</li>
<li>You’re willing to pay for convenience</li>
<li>You need variety in meditation styles</li>
</ul>
<p>But don’t pay extra for “AI personalization” that probably isn’t real.</p>
</section>
<section id="skip-them-if" class="level3">
<h3 class="anchored" data-anchor-id="skip-them-if">Skip Them If:</h3>
<ul>
<li>You’re comfortable finding free meditations on YouTube/Spotify</li>
<li>You don’t need an app to motivate practice</li>
<li>You’re skeptical of premium subscription prices</li>
</ul>
</section>
<section id="better-approaches" class="level3">
<h3 class="anchored" data-anchor-id="better-approaches">Better Approaches:</h3>
<p><strong>Try free options first:</strong> Use YouTube or free apps (Insight Timer, UCLA Mindful) to see if guided meditation helps you.</p>
<p><strong>Manual personalization:</strong> Pay attention to which meditation styles, lengths, and times of day work best for you. This is better personalization than any AI.</p>
<p><strong>Focus on consistency over features:</strong> The best meditation app is the one you’ll actually use. Fancy AI features don’t matter if you don’t build a habit.</p>
<p><strong>Question the AI label:</strong> When any wellness app claims AI, ask: “What is the AI actually doing that couldn’t be done with basic programming?”</p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Calm is a well-designed meditation app with good content. The guided meditations helped me manage stress during a busy recruiting and school period.</p>
<p>But the “AI personalization” appears to be marketing rather than meaningful technology. After a week of use and deliberate testing, I saw no evidence that the app was learning my preferences or adapting recommendations based on my behavior.</p>
<p>The recommendations seemed to come from: - My initial survey answers (static profile) - Content rotation (showing variety) - Basic category matching</p>
<p>This isn’t AI—it’s a preference quiz with some randomization.</p>
<p>For people who find Calm helpful and are willing to pay, that’s fine. The app has value. But it’s worth being clear about what you’re paying for: convenient access to quality meditation content, not AI-powered personalization.</p>
<p>As wellness apps increasingly add “AI” to their marketing, we should be skeptical. Real AI personalization would show measurable adaptation over time. Most apps, including Calm, don’t demonstrate this.</p>
<p>The meditation helped with my recruiting stress. The AI claims? Those just stressed me out more.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>health</category>
  <category>fitness</category>
  <category>skeptical</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/016_/016.html</guid>
  <pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/016_/meditation-app-interface.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Using Claude to Synthesize Dense Class Notes</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/015_/015.html</link>
  <description><![CDATA[ 





<section id="drowning-in-dense-class-notes" class="level2">
<h2 class="anchored" data-anchor-id="drowning-in-dense-class-notes">Drowning in Dense Class Notes</h2>
<p>I’m taking Human Disease and Evolution this semester, and it’s incredibly note-intensive. Every lecture covers evolutionary biology, epidemiology, pathogen adaptation, and historical case studies—all dense material that builds on previous content. By midterms, I had hundreds of pages of notes with no clear way to study them efficiently.</p>
<p>I decided to test whether Claude could help synthesize these notes and work as a study partner. Not just summarizing, but actually helping me understand connections and prepare for exams.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/015_/disease-evolution-notes.jpg" alt="Disease Evolution Course Notes" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Dense notes from Human Disease and Evolution lectures</em></p>
</section>
<section id="how-im-using-claude" class="level2">
<h2 class="anchored" data-anchor-id="how-im-using-claude">How I’m Using Claude</h2>
<section id="initial-upload-and-organization" class="level3">
<h3 class="anchored" data-anchor-id="initial-upload-and-organization">Initial Upload and Organization</h3>
<p>I created a Claude project specifically for the course and uploaded: - Lecture notes from the first 8 weeks - Reading summaries - Professor’s study guide questions - Previous exam questions (from the syllabus)</p>
<p>Then I asked:</p>
<blockquote class="blockquote">
<p>“I’ve uploaded notes from my Human Disease and Evolution course. Help me organize the main themes across lectures and identify connections between topics.”</p>
</blockquote>
<p>Claude produced a thematic breakdown: - Evolutionary pressures on pathogens - Host-pathogen coevolution - Historical transitions (hunter-gatherer → agricultural → urban) and disease emergence - Trade-offs in immune response - Case studies (malaria, tuberculosis, influenza)</p>
<p>This was immediately useful. My notes were chronologically organized by lecture, but the exam tests conceptual understanding across topics.</p>
</section>
<section id="synthesizing-across-lectures" class="level3">
<h3 class="anchored" data-anchor-id="synthesizing-across-lectures">Synthesizing Across Lectures</h3>
<p>My next prompt:</p>
<blockquote class="blockquote">
<p>“We covered malaria in weeks 2, 4, and 7 from different angles. Synthesize all the malaria content into one coherent explanation covering: evolutionary biology, geographic distribution, historical impact, and current challenges.”</p>
</blockquote>
<p>Claude pulled information from multiple lecture sets and created a unified overview. This saved me from manually cross-referencing my notes across different weeks.</p>
</section>
<section id="generating-practice-questions" class="level3">
<h3 class="anchored" data-anchor-id="generating-practice-questions">Generating Practice Questions</h3>
<p>For active recall practice:</p>
<blockquote class="blockquote">
<p>“Based on the uploaded notes, generate 10 exam-style questions that test conceptual understanding, not just memorization. Include questions that require applying concepts to new scenarios.”</p>
</blockquote>
<p>The questions were decent: - “How would you expect pathogen virulence to evolve in a population with high vs.&nbsp;low host density?” - “Explain why tuberculosis resurged in urban populations during industrialization using evolutionary principles.”</p>
<p>These forced me to think beyond memorizing facts.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/015_/pathogen-evolution-diagram.jpg" alt="Pathogen Evolution" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Evolutionary dynamics between hosts and pathogens</em></p>
</section>
</section>
<section id="what-actually-helped" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-helped">What Actually Helped</h2>
<section id="finding-connections-i-missed" class="level3">
<h3 class="anchored" data-anchor-id="finding-connections-i-missed">Finding Connections I Missed</h3>
<p>Claude identified patterns across lectures that I hadn’t noticed while taking notes in real-time. For example, the concept of “virulence-transmission trade-offs” appeared in multiple contexts (influenza, cholera, malaria), but I’d written it down separately each time without seeing the unifying principle.</p>
</section>
<section id="clarifying-confusing-concepts" class="level3">
<h3 class="anchored" data-anchor-id="clarifying-confusing-concepts">Clarifying Confusing Concepts</h3>
<p>When I asked:</p>
<blockquote class="blockquote">
<p>“I don’t fully understand the relationship between R0 (basic reproduction number) and herd immunity threshold. Explain using the influenza example from my notes.”</p>
</blockquote>
<p>Claude broke it down using the specific examples from my lectures, not generic textbook explanations. This was more helpful than Googling because it referenced the actual case studies we’d covered.</p>
</section>
<section id="creating-study-guides" class="level3">
<h3 class="anchored" data-anchor-id="creating-study-guides">Creating Study Guides</h3>
<p>Instead of re-reading hundreds of pages, I asked:</p>
<blockquote class="blockquote">
<p>“Create a two-page study guide covering the five most important concepts from weeks 1-8, with specific examples from the notes.”</p>
</blockquote>
<p>The condensed version helped me review quickly before office hours and identify gaps in my understanding.</p>
</section>
</section>
<section id="significant-limitations" class="level2">
<h2 class="anchored" data-anchor-id="significant-limitations">Significant Limitations</h2>
<section id="cant-replace-actually-studying" class="level3">
<h3 class="anchored" data-anchor-id="cant-replace-actually-studying">Can’t Replace Actually Studying</h3>
<p>The biggest misconception would be thinking Claude can study for you. It can’t.</p>
<p>When I tried asking Claude to quiz me on material, I noticed I could “cheat” by asking for hints or looking back at its previous responses. The lack of real accountability meant I wasn’t forcing myself to actually retrieve information from memory.</p>
<p>According to <a href="https://www.cmu.edu/news/stories/archives/2021/october/active-learning.html">research on active learning</a>, the cognitive struggle of retrieval is what builds long-term retention. AI tools that make information too easy to access can undermine this.</p>
</section>
<section id="factual-accuracy-issues" class="level3">
<h3 class="anchored" data-anchor-id="factual-accuracy-issues">Factual Accuracy Issues</h3>
<p>Claude occasionally made small errors when synthesizing across notes: - Mixing up dates for historical disease outbreaks - Slightly mischaracterizing which regions certain diseases are endemic to - Conflating similar but distinct evolutionary concepts</p>
<p>These weren’t obvious hallucinations—they were plausible-sounding errors that I only caught because I’d attended the lectures. If I’d been using Claude to learn new material rather than organize existing notes, I might not have noticed.</p>
</section>
<section id="cant-capture-lecture-nuance" class="level3">
<h3 class="anchored" data-anchor-id="cant-capture-lecture-nuance">Can’t Capture Lecture Nuance</h3>
<p>My professor emphasizes certain concepts or says “this will be on the exam.” Those verbal cues don’t make it into my typed notes, so Claude can’t prioritize what’s actually important vs.&nbsp;what’s just background information.</p>
<p>It treats all information in my notes equally, when some concepts are more central than others.</p>
</section>
<section id="dependence-risk" class="level3">
<h3 class="anchored" data-anchor-id="dependence-risk">Dependence Risk</h3>
<p>There’s a real risk of becoming dependent on AI for synthesis and losing the ability to do it myself. The mental work of organizing information and finding connections is part of learning—offloading that entirely to AI might make me better at using AI but worse at actual thinking.</p>
<p><a href="https://www.mdpi.com/2075-4698/15/1/6">Research on cognitive offloading to technology</a> suggests that over-reliance on external tools can reduce our own cognitive abilities over time.</p>
</section>
</section>
<section id="is-claude-actually-a-good-study-partner" class="level2">
<h2 class="anchored" data-anchor-id="is-claude-actually-a-good-study-partner">Is Claude Actually a Good Study Partner?</h2>
<section id="what-makes-a-good-study-partner" class="level3">
<h3 class="anchored" data-anchor-id="what-makes-a-good-study-partner">What Makes a Good Study Partner</h3>
<p>Real study partners: - Challenge your understanding by asking probing questions - Notice when you’re bullshitting and call you out - Have their own understanding that you can compare against - Hold you accountable for actually studying</p>
<p>Claude does some of this (asking questions, providing alternative explanations) but fails at others (accountability, challenging weak understanding).</p>
</section>
<section id="where-it-actually-works" class="level3">
<h3 class="anchored" data-anchor-id="where-it-actually-works">Where It Actually Works</h3>
<p>Claude is better described as a “note organization assistant” than a “study partner.” It’s useful for: - Synthesizing large amounts of text quickly - Finding patterns across multiple documents - Generating initial practice questions - Creating structured study guides</p>
<p>These are valuable, but they’re the preliminary work before actual studying begins.</p>
</section>
<section id="the-accountability-gap" class="level3">
<h3 class="anchored" data-anchor-id="the-accountability-gap">The Accountability Gap</h3>
<p>The biggest difference between Claude and a human study partner: I can’t fool Claude, but I also can’t fool myself into thinking Claude-assisted studying counts as real studying.</p>
<p>When I study with friends, the social pressure and explanation requirement force actual learning. With Claude, I can go through the motions of “studying” while not really engaging deeply with the material.</p>
</section>
</section>
<section id="how-im-actually-using-it" class="level2">
<h2 class="anchored" data-anchor-id="how-im-actually-using-it">How I’m Actually Using It</h2>
<section id="early-stage-organization-only" class="level3">
<h3 class="anchored" data-anchor-id="early-stage-organization-only">Early-Stage Organization Only</h3>
<p>I use Claude at the beginning of my study process: 1. Upload notes after several lectures 2. Get thematic organization and connections 3. Create initial study guide 4. Generate practice questions</p>
<p>Then I study using traditional methods: spaced repetition flashcards, practice problems without AI help, and study groups with actual humans.</p>
</section>
<section id="verification-against-lecture-materials" class="level3">
<h3 class="anchored" data-anchor-id="verification-against-lecture-materials">Verification Against Lecture Materials</h3>
<p>Anything Claude synthesizes, I verify against: - Original lecture slides - Textbook readings - Professor’s posted materials</p>
<p>I don’t trust Claude’s synthesis as the final word—it’s a starting point that I refine.</p>
</section>
<section id="using-it-for-weak-areas" class="level3">
<h3 class="anchored" data-anchor-id="using-it-for-weak-areas">Using It for Weak Areas</h3>
<p>When I identify concepts I don’t understand well, I ask Claude for additional explanations or examples. But then I test my understanding by explaining it to a friend without AI help.</p>
</section>
<section id="real-study-sessions-stay-human" class="level3">
<h3 class="anchored" data-anchor-id="real-study-sessions-stay-human">Real Study Sessions Stay Human</h3>
<p>My actual exam prep involves: - Study groups with classmates - Office hours with TA and professor - Practice exams under time pressure - Teaching concepts to others</p>
<p>Claude handles the logistical grunt work of organizing notes, but learning happens through human interaction and cognitive struggle.</p>
</section>
</section>
<section id="final-assessment" class="level2">
<h2 class="anchored" data-anchor-id="final-assessment">Final Assessment</h2>
<p>Using Claude to synthesize dense class notes is genuinely useful for note-intensive courses. It saves time on organization and helps identify connections across material.</p>
<p>But calling it a “study partner” overstates what it can do. It’s more like a smart organizational tool that can handle the tedious work of cross-referencing and initial synthesis.</p>
<p>The real learning—deep understanding, retention, application—still requires traditional study methods and human interaction. Claude can make the prep work more efficient, but it can’t replace the cognitive work of actually studying.</p>
<p>For Human Disease and Evolution specifically, Claude helped me organize a semester’s worth of dense notes into a manageable study plan. But I’m not bringing Claude into the exam room—I need to make sure the knowledge is in my head, not just in my AI assistant’s context window.</p>
<p>The tool is helpful. But over-relying on it would be a mistake that probably shows up when exam day arrives.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>LLM</category>
  <category>daily-life</category>
  <category>professional</category>
  <category>claude</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/015_/015.html</guid>
  <pubDate>Mon, 13 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/015_/disease-evolution-notes.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Superagency Review #1: History Is Written by the Winners</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/014_/014.html</link>
  <description><![CDATA[ 





<section id="reading-superagency-a-gloomers-perspective" class="level2">
<h2 class="anchored" data-anchor-id="reading-superagency-a-gloomers-perspective">Reading Superagency: A Gloomer’s Perspective</h2>
<p>I’m reading Reid Hoffman and Greg Beato’s <a href="https://www.superagency.ai/"><em>Superagency: What Could Possibly Go Right with Our AI Future</em></a>—a book that argues for optimism about generative AI and its potential to enhance human agency. As someone who identifies as a gloomer about AI, I’m approaching this with skepticism but genuine curiosity.</p>
<p>This is part 1 of 5 reviews covering the entire book. Pages 1-47: The introduction and framing.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/014_/superagency-book-cover.jpg" alt="Superagency Book" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Superagency by Reid Hoffman and Greg Beato</em></p>
</section>
<section id="the-historical-framing-art-luddites-and-printing-presses" class="level2">
<h2 class="anchored" data-anchor-id="the-historical-framing-art-luddites-and-printing-presses">The Historical Framing: Art, Luddites, and Printing Presses</h2>
<p>The introduction opens with an interesting historical analogy. Hoffman and Beato walk through past technological disruptions:</p>
<p><strong>Socrates and Art:</strong> Socrates opposed art because it failed to capture the conversational, evolutionary, iterative process of discussion-based learning. Written text was static; dialogue was dynamic.</p>
<p><strong>The Luddites:</strong> Workers who resisted industrial machinery that threatened their livelihoods and ways of life.</p>
<p><strong>The Printing Press:</strong> A technology that faced backlash from those who feared the democratization of knowledge.</p>
<p>The pattern is clear: history is full of examples of technological backlash. The book frames AI as the latest in this line—another “infrastructural change event” that will transform human capacity and agency.</p>
<p>I’ll admit, the framing is effective. The core question the book poses is compelling: “Can we continue to maintain control of our lives, and successfully plot our own destinies?” in the age of AI.</p>
</section>
<section id="history-is-written-by-the-winners" class="level2">
<h2 class="anchored" data-anchor-id="history-is-written-by-the-winners">History Is Written by the Winners</h2>
<p>Here’s where my skepticism kicks in.</p>
<p>Yes, all these technological disruptions—art, steam power, the printing press—were consequential and enabled human agency in important ways:</p>
<p><strong>Art</strong> captured feelings, periods, and provided first-hand historical resources.</p>
<p><strong>Steam power</strong> and the Industrial Revolution brought unimaginable productivity and capital accumulation, leading to the consolidation of modern cities.</p>
<p><strong>The printing press</strong> enabled communication and knowledge dissemination like never before.</p>
<p>We’ve all benefited from these major strides, one way or another. But the more closely we examine the nuances of these pivotal moments, the more we realize there’s much more to the story.</p>
<p>The problem is that we often focus on the positives—maybe as a sign of human delusion, or a craving to minimize problems. Important details get left behind. History is written by the winners, after all.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/014_/industrial-revolution-workers.jpg" alt="Historical Technology Impact" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>The Industrial Revolution: productivity gains alongside worker displacement</em></p>
</section>
<section id="what-the-winners-history-leaves-out" class="level2">
<h2 class="anchored" data-anchor-id="what-the-winners-history-leaves-out">What the Winners’ History Leaves Out</h2>
<section id="the-industrial-revolutions-dark-side" class="level3">
<h3 class="anchored" data-anchor-id="the-industrial-revolutions-dark-side">The Industrial Revolution’s Dark Side</h3>
<p>The steam engine and industrialization brought unprecedented productivity. But they also brought: - Brutal working conditions in factories - Child labor - Destruction of artisan crafts and traditional ways of life - Environmental degradation that we’re still dealing with - Massive wealth inequality and the creation of exploitative labor systems</p>
<p>According to <a href="https://www.britannica.com/event/Industrial-Revolution">historical analysis of the Industrial Revolution</a>, while productivity soared, real wages for workers stagnated or declined for decades. The “winners” who wrote that history were the factory owners and industrialists, not the displaced weavers or child laborers.</p>
</section>
<section id="the-printing-press-and-information-chaos" class="level3">
<h3 class="anchored" data-anchor-id="the-printing-press-and-information-chaos">The Printing Press and Information Chaos</h3>
<p>The printing press democratized knowledge—but it also: - Enabled mass propaganda - Facilitated religious wars and sectarian violence - Created information overload that people weren’t equipped to handle - Disrupted existing knowledge gatekeepers (sometimes for good, sometimes not)</p>
<p>The Reformation, enabled by printing technology, led to centuries of religious conflict. That’s not in the optimistic framing.</p>
</section>
<section id="the-luddites-were-right-about-some-things" class="level3">
<h3 class="anchored" data-anchor-id="the-luddites-were-right-about-some-things">The Luddites Were Right About Some Things</h3>
<p>We use “Luddite” as an insult for technophobes. But the original Luddites weren’t irrationally afraid of technology—they were skilled workers watching their livelihoods and communities be destroyed by machines that enriched factory owners.</p>
<p>Their concerns about who benefits from technological change were valid. The technology did increase productivity, but the gains went to capital owners, not workers. The Luddites lost that fight, so history remembers them as backwards resistors rather than people with legitimate concerns about economic justice.</p>
</section>
</section>
<section id="the-agency-question-for-whom" class="level2">
<h2 class="anchored" data-anchor-id="the-agency-question-for-whom">The Agency Question: For Whom?</h2>
<p>Hoffman and Beato frame AI as an “agency enabler”—technology that will enhance our capacity to “do what we ought to do” and “plot our own destinies.”</p>
<p>But here’s the critical question the introduction doesn’t adequately address: <strong>Whose agency gets enabled?</strong></p>
<section id="technology-doesnt-distribute-benefits-evenly" class="level3">
<h3 class="anchored" data-anchor-id="technology-doesnt-distribute-benefits-evenly">Technology Doesn’t Distribute Benefits Evenly</h3>
<p>Past technological revolutions increased <em>aggregate</em> human capacity and agency. But the distribution was wildly unequal: - Factory owners gained agency; workers often lost autonomy - Landowners who adopted new agricultural tech thrived; tenant farmers were displaced - Early adopters of communication technology gained power; those without access fell further behind</p>
<p>When Hoffman talks about AI enabling “our” agency, who is “we”? Tech founders and investors? Knowledge workers with access to cutting-edge tools? Or also the truck drivers, customer service workers, and radiologists whose jobs might be automated?</p>
</section>
<section id="have-we-forgotten-our-ways-of-life" class="level3">
<h3 class="anchored" data-anchor-id="have-we-forgotten-our-ways-of-life">Have We Forgotten Our Ways of Life?</h3>
<p>Each technological revolution didn’t just change what people could do—it changed how people lived. Industrialization pulled people from rural communities into urban factories. The printing press disrupted oral traditions and face-to-face knowledge transmission.</p>
<p>Some of these changes were positive. Some represented the loss of valuable ways of life that we can never recover.</p>
<p>The introduction’s optimistic framing acknowledges these past disruptions but seems confident that AI will be different—that we can get the benefits without the costs. History suggests otherwise.</p>
</section>
</section>
<section id="what-im-looking-for-in-the-rest-of-the-book" class="level2">
<h2 class="anchored" data-anchor-id="what-im-looking-for-in-the-rest-of-the-book">What I’m Looking For in the Rest of the Book</h2>
<p>The introduction sets up an optimistic case for AI as an agency enabler, using historical technological disruptions as precedent. The framing is well-done and intellectually honest about past backlash to new technologies.</p>
<p>But it seems to brush past the real costs of those past revolutions. The “winners” narrative focuses on aggregate gains while downplaying distributional concerns and the destruction of existing ways of life.</p>
<p>As I continue reading, I’m looking for:</p>
<p><strong>Distributional analysis:</strong> Who specifically gains agency from AI, and who loses it?</p>
<p><strong>Cost acknowledgment:</strong> What ways of life, skills, or social structures might we lose, and are those losses acceptable?</p>
<p><strong>Power dynamics:</strong> How do we ensure AI benefits are distributed more equitably than past technological revolutions?</p>
<p><strong>Concrete mechanisms:</strong> Not just “AI will enable agency,” but <em>how</em> and <em>for whom</em> specifically?</p>
<p>The book asks: “What could possibly go right with our AI future?” But the introduction’s own historical examples suggest we should also ask: “What will go wrong, and for whom?”</p>
<p>History is written by the winners. I’m reading this book to see if Hoffman and Beato can imagine an AI future where there are fewer losers than in past technological revolutions—or if they’re just writing the winners’ narrative before the story has finished.</p>
</section>
<section id="up-next" class="level2">
<h2 class="anchored" data-anchor-id="up-next">Up Next</h2>
<p>Review #2 will cover pages 48-94, where I expect the book to start making its positive case for AI more explicitly. I’ll be watching to see if it addresses the distributional concerns raised by its own historical framing.</p>
<p>Stay tuned.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>book-review</category>
  <category>skeptical</category>
  <category>research</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/014_/014.html</guid>
  <pubDate>Sat, 11 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/014_/superagency-book-cover.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Testing AI as a Tutor: Does Prompt Structure Actually Matter?</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/013_/013.html</link>
  <description><![CDATA[ 





<section id="learning-to-cook-with-ai-an-experiment" class="level2">
<h2 class="anchored" data-anchor-id="learning-to-cook-with-ai-an-experiment">Learning to Cook with AI: An Experiment</h2>
<p>I’m Peruvian but never learned to cook Lomo Saltado properly. Living in a college dorm with limited equipment, I decided to use Claude as a tutor to learn. But instead of just asking for help, I ran an experiment: two separate tutoring sessions using different prompting approaches to see if prompt engineering actually makes a difference for learning.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/013_/lomo-saltado-dish.jpg" alt="Lomo Saltado Dish" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>A finished plate of Lomo Saltado - the goal of the tutoring sessions</em></p>
</section>
<section id="the-experiment-setup" class="level2">
<h2 class="anchored" data-anchor-id="the-experiment-setup">The Experiment Setup</h2>
<section id="session-1-vanilla-claude" class="level3">
<h3 class="anchored" data-anchor-id="session-1-vanilla-claude">Session 1: Vanilla Claude</h3>
<p>I started a fresh conversation with no special prompting. Just asked:</p>
<blockquote class="blockquote">
<p>“I want to learn how to cook Lomo Saltado in my college dorm. Can you teach me?”</p>
</blockquote>
<p>Claude immediately provided a comprehensive ingredient list, equipment needs, and step-by-step instructions. Efficient and informative.</p>
</section>
<section id="session-2-structured-tutoring-prompt" class="level3">
<h3 class="anchored" data-anchor-id="session-2-structured-tutoring-prompt">Session 2: Structured Tutoring Prompt</h3>
<p>For the second session, I used the <a href="https://www.oneusefulthing.org/p/how-to-use-ai-to-teach">Mollick structured tutoring prompt</a>, which instructs the AI to: - Introduce itself by name - Ask questions one at a time before teaching - Gather information about the student’s prior knowledge - Use leading questions rather than just providing answers - Provide emotional support and encouragement</p>
<p>The prompt started with:</p>
<blockquote class="blockquote">
<p>“You are an upbeat, encouraging tutor who helps students understand concepts by explaining ideas and asking students questions. Start by introducing yourself to the student as their AI-Tutor who is happy to help them with any questions…”</p>
</blockquote>
<p>Same question about learning Lomo Saltado, but this time Claude introduced itself as “Alex” and asked about my cooking experience before giving any instructions.</p>
</section>
</section>
<section id="how-the-sessions-differed" class="level2">
<h2 class="anchored" data-anchor-id="how-the-sessions-differed">How The Sessions Differed</h2>
<section id="session-1-information-first" class="level3">
<h3 class="anchored" data-anchor-id="session-1-information-first">Session 1: Information First</h3>
<p>Claude immediately delivered: - Complete ingredient list with substitutions - All equipment needed - Step-by-step cooking instructions - Do’s and don’ts - Storage and freezing tips</p>
<p>It was like reading a very thorough cookbook. Efficient, but I started feeling overwhelmed around the “do’s and don’ts” section because it kept adding more information without checking if I was following along.</p>
<p>When I asked for a “cookbook style summary” later, it became clear I’d experienced information overload.</p>
</section>
<section id="session-2-questions-first" class="level3">
<h3 class="anchored" data-anchor-id="session-2-questions-first">Session 2: Questions First</h3>
<p>Claude asked: - What’s my cooking experience level? - What equipment do I have access to? - What do I already know about Lomo Saltado?</p>
<p>When I mentioned I’m Peruvian and grew up eating this dish, the whole approach changed. Claude acknowledged my cultural connection, didn’t waste time explaining what Lomo Saltado is, and focused on translating my taste memory into cooking technique.</p>
<p>The information came in smaller chunks, each followed by a question to check understanding. It felt more like a conversation than a lecture.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/013_/claude-tutoring-interface.jpg" alt="Claude Tutoring Interface" style="max-width: 450px; max-height: 300px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Comparing the two Claude tutoring session interfaces</em></p>
</section>
</section>
<section id="when-things-went-wrong" class="level2">
<h2 class="anchored" data-anchor-id="when-things-went-wrong">When Things Went Wrong</h2>
<p>I intentionally messed up the recipe in both sessions to see how each tutor would handle mistakes.</p>
<section id="session-1-response" class="level3">
<h3 class="anchored" data-anchor-id="session-1-response">Session 1 Response</h3>
<p>When I said I overcooked the meat, added too much soy sauce, and the tomatoes were mushy, Claude gave practical solutions: - Slice overcooked meat thinner - Balance soy sauce with vinegar and sugar - Remove mushy tomatoes and add fresh ones</p>
<p>Organized by problem, very solution-focused. It worked, but felt clinical.</p>
<p>At one point I got frustrated and said “I do NOT want to try again tomorrow. I want to DO IT NOW.” The tutor went into emergency rescue mode, which helped but didn’t address the emotional crisis.</p>
</section>
<section id="session-2-response" class="level3">
<h3 class="anchored" data-anchor-id="session-2-response">Session 2 Response</h3>
<p>When I introduced the same problems, Claude started with:</p>
<blockquote class="blockquote">
<p>“Don’t panic! This is totally normal when learning, and yes, we can salvage this!”</p>
</blockquote>
<p>Then provided the same practical solutions, but added:</p>
<blockquote class="blockquote">
<p>“Remember: Even ‘mistakes’ can taste good, and every Peruvian abuela had to start somewhere!”</p>
</blockquote>
<p>This was culturally resonant and emotionally supportive. The solutions were similar, but the tone acknowledged that learning involves struggle, not just technical problem-solving.</p>
<p>I didn’t have the same emotional breakdown in Session 2. The earlier relationship-building (validation, personalization) seemed to prevent it.</p>
</section>
</section>
<section id="the-final-cookbook-recipes" class="level2">
<h2 class="anchored" data-anchor-id="the-final-cookbook-recipes">The Final Cookbook Recipes</h2>
<p>Both sessions ended with me asking for a clean cookbook-style recipe.</p>
<section id="session-1-recipe" class="level3">
<h3 class="anchored" data-anchor-id="session-1-recipe">Session 1 Recipe</h3>
<ul>
<li>Heavy use of emoji headers (🥩, 🍅, ⏰)</li>
<li>Multiple subsections: Equipment, Ingredients, Shortcuts, Steps, Money-Saving Tips, Dorm Hacks, Storage</li>
<li>Comprehensive resource document</li>
<li>Generic college student advice</li>
</ul>
</section>
<section id="session-2-recipe" class="level3">
<h3 class="anchored" data-anchor-id="session-2-recipe">Session 2 Recipe</h3>
<ul>
<li>Cleaner visual hierarchy</li>
<li>Sections: What You’ll Need → Game Plan → Key Success Tips → Storage</li>
<li>More scannable layout</li>
<li>Tailored to: college student + new cook + Peruvian heritage + meal prep constraints</li>
</ul>
<p>Both recipes are accurate and functional. Session 1 is more comprehensive; Session 2 is more personalized to my specific situation.</p>
</section>
</section>
<section id="what-actually-made-a-difference" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-made-a-difference">What Actually Made a Difference</h2>
<section id="the-structured-prompt-won" class="level3">
<h3 class="anchored" data-anchor-id="the-structured-prompt-won">The Structured Prompt Won</h3>
<p>Session 2 was the better tutoring experience because:</p>
<p><strong>Better sequencing:</strong> Asking questions before teaching meant the information was calibrated to what I actually needed, not everything the AI knows about Lomo Saltado.</p>
<p><strong>Personalization:</strong> Learning I was Peruvian changed how Claude explained things. It connected to my existing knowledge (“You know what it should taste like”) rather than starting from zero.</p>
<p><strong>Emotional support:</strong> Normalizing mistakes and providing encouragement made me more likely to persist through problems. This matters for skill-building where failure is inevitable.</p>
<p><strong>Active learning:</strong> Session 2 ended each explanation with a question, forcing me to think rather than passively receive information.</p>
</section>
<section id="where-session-1-was-better" class="level3">
<h3 class="anchored" data-anchor-id="where-session-1-was-better">Where Session 1 Was Better</h3>
<p><strong>Speed:</strong> If you just want information fast, the vanilla approach delivers immediately without the question-gathering phase.</p>
<p><strong>Comprehensiveness:</strong> The final recipe from Session 1 had more detail on meal prep, freezing, and storage tips.</p>
<p><strong>No preamble:</strong> Some people find the “getting to know you” phase of structured tutoring annoying if they just want answers.</p>
</section>
</section>
<section id="does-this-matter-beyond-cooking" class="level2">
<h2 class="anchored" data-anchor-id="does-this-matter-beyond-cooking">Does This Matter Beyond Cooking?</h2>
<section id="the-pedagogy-research" class="level3">
<h3 class="anchored" data-anchor-id="the-pedagogy-research">The Pedagogy Research</h3>
<p>The structured prompt approach aligns with established learning science. According to <a href="https://ies.ed.gov/learn/blog/high-quality-tutoring-evidence-based-strategy-tackle-learning-loss">research on effective tutoring</a>, good tutoring involves: - Assessing prior knowledge before teaching - Providing scaffolded support - Using questions to promote active learning - Giving emotional encouragement alongside technical help</p>
<p>These aren’t AI-specific insights—they’re how human tutoring works best too.</p>
</section>
<section id="the-limitations" class="level3">
<h3 class="anchored" data-anchor-id="the-limitations">The Limitations</h3>
<p>Even with perfect prompting, AI tutoring has constraints:</p>
<p><strong>Can’t taste your food:</strong> Claude couldn’t tell me if my Lomo Saltado actually tasted right. I had to rely on my own judgment.</p>
<p><strong>Can’t see your technique:</strong> When I said the meat was overcooked, Claude couldn’t see whether I was cutting it correctly or using too high heat. The advice was generic.</p>
<p><strong>Can’t adapt in real-time:</strong> A human tutor watching me cook would catch mistakes as they happen. AI only responds to what I describe.</p>
<p><strong>Generic cultural knowledge:</strong> Session 2’s cultural references (“Peruvian abuela”) were sweet but generic. It didn’t know my actual family’s cooking style or regional variations.</p>
</section>
<section id="when-structured-prompting-matters-most" class="level3">
<h3 class="anchored" data-anchor-id="when-structured-prompting-matters-most">When Structured Prompting Matters Most</h3>
<p>The prompt engineering made the biggest difference when: - Learning something new (not just looking up facts) - Dealing with frustration or mistakes - Needing personalized guidance - Building skills through practice</p>
<p>For quick information retrieval, vanilla Claude is probably fine. For actual learning, structure helps.</p>
</section>
</section>
<section id="what-i-learned" class="level2">
<h2 class="anchored" data-anchor-id="what-i-learned">What I Learned</h2>
<section id="about-ai-tutoring" class="level3">
<h3 class="anchored" data-anchor-id="about-ai-tutoring">About AI Tutoring</h3>
<p>Prompt engineering isn’t just theoretical optimization—it genuinely changed my learning experience. The structured prompt created better dialogue, personalization, and emotional support.</p>
<p>But even good prompting has limits. AI tutoring works best for knowledge-based learning where you can verify results yourself. For physical skills like cooking, you still need to trust your own judgment about the outcome.</p>
</section>
<section id="about-learning-lomo-saltado" class="level3">
<h3 class="anchored" data-anchor-id="about-learning-lomo-saltado">About Learning Lomo Saltado</h3>
<p>I actually cooked it. Both sessions gave me functional recipes, but Session 2’s emotional support made me more willing to try despite knowing I’d probably mess up.</p>
<p>The AI was right about one thing: even mistakes taste pretty good, and you learn by doing.</p>
</section>
<section id="about-prompt-design" class="level3">
<h3 class="anchored" data-anchor-id="about-prompt-design">About Prompt Design</h3>
<p>Good tutoring prompts should include: - Instructions to gather context before teaching - One-question-at-a-time pacing - Emotional scaffolding for when things go wrong - Requirements to keep students actively thinking</p>
<p>These aren’t complex AI techniques—they’re just principles of good teaching, codified for an AI to follow.</p>
<p>If you’re using AI to learn something practical, take five minutes to set up a proper tutoring prompt. The difference is real.</p>


</section>
</section>

 ]]></description>
  <category>research</category>
  <category>professional</category>
  <category>LLM</category>
  <category>daily-life</category>
  <category>claude</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/013_/013.html</guid>
  <pubDate>Thu, 09 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/013_/lomo-saltado-dish.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Switching from Consulting to Finance Prep with AI</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/012_/012.html</link>
  <description><![CDATA[ 





<section id="pivoting-interview-prep-consulting-to-finance" class="level2">
<h2 class="anchored" data-anchor-id="pivoting-interview-prep-consulting-to-finance">Pivoting Interview Prep: Consulting to Finance</h2>
<p>I have an upcoming interview for a Santander CIB Investment Banking Analyst Program, specifically for their DCM (Debt Capital Markets) division. This is different from the consulting interviews I’ve been preparing for—finance interviews require understanding specific firms, technical knowledge about debt markets, and different types of behavioral questions.</p>
<p>Since I’ve been using AI for consulting prep, I decided to test whether Claude and Perplexity could help me pivot to finance interview preparation.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/012_/claude-finance-research.jpg" alt="Claude Research Interface" style="max-width: 600px; max-height: 350px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Claude conducting research on Santander’s DCM business and interview approach</em></p>
</section>
<section id="the-prompts-i-used" class="level2">
<h2 class="anchored" data-anchor-id="the-prompts-i-used">The Prompts I Used</h2>
<section id="initial-research-request-to-claude" class="level3">
<h3 class="anchored" data-anchor-id="initial-research-request-to-claude">Initial Research Request to Claude</h3>
<p>My first prompt:</p>
<blockquote class="blockquote">
<p>“First and foremost, I am more so interested in understanding DCM, and potential BEHAVIORAL questions that might arise.</p>
<p>Why DCM? Why DCM LatAm? Why Santander DCM?</p>
<p>Use the web to thoroughly search and understand more about the firm, how the firm talks about itself, and what common behavioral questions do they engage with for their IB process.”</p>
</blockquote>
<p>Claude responded:</p>
<blockquote class="blockquote">
<p>“I’ll conduct thorough research on Santander CIB, their DCM business, and their interview process. Let me search for information about how they present themselves, their Latin America focus, and common interview questions.”</p>
</blockquote>
<p>It then ran searches for: - “Santander Corporate Investment Banking DCM” (10 results) - Started searching the web for additional information</p>
</section>
<section id="perplexity-deep-dive" class="level3">
<h3 class="anchored" data-anchor-id="perplexity-deep-dive">Perplexity Deep Dive</h3>
<p>I also used Perplexity’s research feature with multiple targeted searches:</p>
<ul>
<li>“Santander CIB debt capital markets”</li>
<li>“Santander investment banking culture values”</li>
<li>“Santander CIB Latin America strategy”</li>
</ul>
<p>Perplexity found 20 sources including: - Debt Capital Markets | Santander Corporate &amp; Investment Banking - From personalization to social values: what is shaking up investment [banking] - Macro &amp; Strategy Research - The past, present and future of debt capital markets - [PDF] Culture Report 2019 - Banco Santander - Santander US Capital Markets</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/012_/perplexity-research-results.jpg" alt="Perplexity Research" style="max-width: 600px; max-height: 350px; object-fit: contain; display: block; margin: 20px auto;"></p>
<p><em>Perplexity gathering and reviewing sources on Santander DCM</em></p>
</section>
</section>
<section id="what-actually-helped" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-helped">What Actually Helped</h2>
<section id="firm-specific-research" class="level3">
<h3 class="anchored" data-anchor-id="firm-specific-research">Firm-Specific Research</h3>
<p>Both tools pulled relevant information about Santander’s positioning: - Their focus on Latin America markets and how that differentiates them - Recent deals and market activity in DCM - Corporate values and culture statements - Strategic priorities in debt capital markets</p>
<p>This gave me talking points for “Why Santander” that were specific rather than generic.</p>
</section>
<section id="understanding-dcm-vs.-other-ib-divisions" class="level3">
<h3 class="anchored" data-anchor-id="understanding-dcm-vs.-other-ib-divisions">Understanding DCM vs.&nbsp;Other IB Divisions</h3>
<p>The AI helped clarify: - What DCM analysts actually do day-to-day - How DCM differs from M&amp;A or equity capital markets - Why someone might choose DCM over other finance paths - Technical concepts I needed to understand (bond pricing, credit ratings, syndication)</p>
</section>
<section id="behavioral-question-preparation" class="level3">
<h3 class="anchored" data-anchor-id="behavioral-question-preparation">Behavioral Question Preparation</h3>
<p>The tools suggested finance-specific behavioral questions that differ from consulting: - “Walk me through a DCF” (technical behavioral) - “Why debt capital markets vs.&nbsp;other finance roles?” - “How do you handle working with difficult clients on tight deadlines?” - “Tell me about a time you analyzed complex financial information”</p>
<p>These are different from consulting’s case-focused approach.</p>
</section>
<section id="identifying-knowledge-gaps" class="level3">
<h3 class="anchored" data-anchor-id="identifying-knowledge-gaps">Identifying Knowledge Gaps</h3>
<p>The research helped me realize what I didn’t know: - Specific debt instruments Santander specializes in - Recent Latin American market trends affecting DCM - Technical terminology I needed to learn - The difference between investment-grade and high-yield debt origination</p>
</section>
</section>
<section id="significant-limitations" class="level2">
<h2 class="anchored" data-anchor-id="significant-limitations">Significant Limitations</h2>
<section id="surface-level-firm-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="surface-level-firm-knowledge">Surface-Level Firm Knowledge</h3>
<p>The biggest problem: AI gives you the information that’s publicly available on corporate websites and general industry sources. It can’t tell you: - What Santander’s DCM team culture is actually like - Specific deals they’re working on that aren’t public - Internal priorities that aren’t in press releases - What actually impresses their interviewers vs.&nbsp;what sounds good on paper</p>
</section>
<section id="generic-behavioral-answers" class="level3">
<h3 class="anchored" data-anchor-id="generic-behavioral-answers">Generic Behavioral Answers</h3>
<p>When I asked Claude to help refine my answers to “Why DCM?”, it produced polished but generic responses: - “I’m drawn to the analytical rigor of debt markets…” - “The complexity of structuring transactions appeals to me…” - “I want to work at the intersection of capital markets and corporate strategy…”</p>
<p>These sound like everyone else’s AI-polished answers. The interviewers at Santander have probably heard variations of these from dozens of candidates using similar tools.</p>
</section>
<section id="cant-teach-technical-skills" class="level3">
<h3 class="anchored" data-anchor-id="cant-teach-technical-skills">Can’t Teach Technical Skills</h3>
<p>AI can explain what a DCF is, but it can’t help you build the muscle memory of actually modeling one under time pressure. It can’t simulate the experience of being asked to walk through a valuation on a whiteboard while someone watches.</p>
<p><a href="https://mergersandinquisitions.com/investment-banking-interview-questions-and-answers/">Finance interview prep resources</a> emphasize that technical skills require hands-on practice with actual models, not just conceptual understanding.</p>
</section>
<section id="outdated-information" class="level3">
<h3 class="anchored" data-anchor-id="outdated-information">Outdated Information</h3>
<p>Some of the sources Perplexity pulled were from 2019 (the Culture Report). The finance industry moves quickly—strategies, priorities, and team structures change. Relying on AI-found sources without verifying recency is risky.</p>
</section>
<section id="misses-networking-insights" class="level3">
<h3 class="anchored" data-anchor-id="misses-networking-insights">Misses Networking Insights</h3>
<p>The most valuable interview prep for finance comes from talking to people who work at the firm or in similar roles. AI can’t replace: - Coffee chats with current Santander analysts - Alumni connections who know the interview process - Understanding what specific interviewers care about - Getting feedback on your story from people in the industry</p>
</section>
</section>
<section id="consulting-prep-vs.-finance-prep-with-ai" class="level2">
<h2 class="anchored" data-anchor-id="consulting-prep-vs.-finance-prep-with-ai">Consulting Prep vs.&nbsp;Finance Prep with AI</h2>
<section id="what-transfers" class="level3">
<h3 class="anchored" data-anchor-id="what-transfers">What Transfers</h3>
<p>Some aspects of using AI for consulting prep apply to finance: - Organizing practice materials and tracking progress - Getting quick explanations of concepts - Structuring answers using frameworks - Identifying areas where you need more preparation</p>
</section>
<section id="whats-different" class="level3">
<h3 class="anchored" data-anchor-id="whats-different">What’s Different</h3>
<p>Finance interviews require different AI usage:</p>
<p><strong>Technical Knowledge:</strong> Consulting is more about frameworks and problem-solving approach. Finance requires specific technical knowledge (financial modeling, valuation methods, market mechanics) that you need to practice hands-on.</p>
<p><strong>Firm Research:</strong> Consulting firms are more about “fit” and problem-solving ability. Finance firms want to know you understand their specific business lines, recent deals, and market positioning.</p>
<p><strong>Answer Style:</strong> Consulting wants structured, MECE thinking demonstrated verbally. Finance wants technical competence demonstrated through modeling and concise, confident answers about markets.</p>
<p><strong>Preparation Balance:</strong> For consulting, AI can handle maybe 40% of prep (frameworks, structure, case types). For finance, it’s more like 20%—you need more hands-on technical practice and human networking.</p>
</section>
</section>
<section id="my-actual-approach" class="level2">
<h2 class="anchored" data-anchor-id="my-actual-approach">My Actual Approach</h2>
<section id="using-ai-for-initial-research-phase" class="level3">
<h3 class="anchored" data-anchor-id="using-ai-for-initial-research-phase">Using AI for Initial Research Phase</h3>
<p>I’m using Claude and Perplexity to: - Get baseline understanding of Santander’s DCM business - Compile a list of recent deals and market trends - Understand basic DCM technical concepts - Draft initial answers to behavioral questions</p>
<p>But I treat this as the starting point, not the final product.</p>
</section>
<section id="following-up-with-human-sources" class="level3">
<h3 class="anchored" data-anchor-id="following-up-with-human-sources">Following Up with Human Sources</h3>
<p>After AI research, I’m: - Reaching out to Santander employees on LinkedIn - Talking to friends in investment banking about DCM - Getting my behavioral answers reviewed by people in finance - Asking specific questions about Santander’s Latin America focus</p>
</section>
<section id="technical-skill-building" class="level3">
<h3 class="anchored" data-anchor-id="technical-skill-building">Technical Skill Building</h3>
<p>For the technical components, AI isn’t much help. I’m: - Working through actual DCF models - Practicing explaining valuation methods out loud - Reviewing recent debt deals and their structures - Doing mock technical questions with finance friends</p>
</section>
<section id="verifying-everything" class="level3">
<h3 class="anchored" data-anchor-id="verifying-everything">Verifying Everything</h3>
<p>Any specific fact or claim from AI research, I verify: - Check Santander’s official investor relations materials - Look up recent news about their DCM business - Confirm market trends with multiple sources - Cross-reference technical concepts with textbooks</p>
<p>The AI can point me toward information, but I don’t trust it without verification.</p>
</section>
</section>
<section id="final-assessment" class="level2">
<h2 class="anchored" data-anchor-id="final-assessment">Final Assessment</h2>
<p>Using AI to pivot from consulting to finance interview prep is helpful but limited. It’s good for: - Quick baseline research on the firm and role - Understanding how finance interviews differ from consulting - Getting initial structure for behavioral answers - Identifying what you don’t know</p>
<p>But it’s insufficient for: - Developing real technical skills - Understanding firm-specific culture and priorities - Creating distinctive, memorable answers - Getting the insider knowledge that networking provides</p>
<p>Finance interviews, even more than consulting, require human connections and hands-on technical practice. AI can accelerate the research phase, but it can’t replace the core preparation activities that actually matter.</p>
<p>The risk is thinking that comprehensive AI research is enough. It’s not. The candidates who get offers at places like Santander DCM are the ones who combine efficient research with deep technical preparation and strong industry networks—things AI can’t provide.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>LLM</category>
  <category>professional</category>
  <category>claude</category>
  <category>perplexity</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/012_/012.html</guid>
  <pubDate>Sun, 05 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/012_/claude-finance-research.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Running a Virtual Focus Group with ChatGPT</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/011_/011.html</link>
  <description><![CDATA[ 





<section id="testing-products-with-ai-generated-focus-groups" class="level2">
<h2 class="anchored" data-anchor-id="testing-products-with-ai-generated-focus-groups">Testing Products with AI-Generated Focus Groups</h2>
<p>For the Cuzco Crunch project, Eury and I needed to test two product concepts before committing to one. Instead of recruiting actual participants for a focus group, we decided to try something experimental: using ChatGPT to simulate a focus group with 10 diverse personas.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/011_/cuzco-crunch-package.jpg" alt="Cuzco Crunch Product" style="max-width: 450px; max-height: 300px; object-fit: cover; object-position: center; display: block; margin: 20px auto;"></p>
<p><em>Cuzco Crunch: Golden plantain slices with Peruvian sal de Maras</em></p>
</section>
<section id="the-experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="the-experimental-design">The Experimental Design</h2>
<section id="two-products-to-test" class="level3">
<h3 class="anchored" data-anchor-id="two-products-to-test">Two Products to Test</h3>
<p><strong>Cuzco Crunch (Product A):</strong> Positioned as premium - golden, ultra-crispy plantain slices with Peruvian sal de Maras for a mineral-salt finish. Natural sweetness from plantain, meant to be versatile. Price: $7 for 1.5 oz.</p>
<p><strong>Plantain Lite (Product B):</strong> Positioned as everyday - lighter snack with delicate crunch and simple seasoning. Emphasizes convenience and portability. Price: $5 for 1.5 oz.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/011_/plantain-lite-package.jpg" alt="Plantain Lite Product" style="max-width: 500px; max-height: 400px; object-fit: cover; object-position: center; display: block; margin: 20px auto;"></p>
<p><em>Plantain Lite: A lighter, everyday plantain chip option</em></p>
</section>
<section id="creating-10-diverse-personas" class="level3">
<h3 class="anchored" data-anchor-id="creating-10-diverse-personas">Creating 10 Diverse Personas</h3>
<p>We built personas across multiple demographic dimensions: - <strong>Gender:</strong> Male/Female - <strong>Age ranges:</strong> 18-25, 26-33, 34-41, 42-50 - <strong>Health conditions:</strong> Hypertension, obesity, heart disease, asthma, food allergies, digestive issues, or none - <strong>Ethnicity:</strong> Latino or Not Latino - <strong>Location:</strong> Urban, suburban, or rural</p>
<p>Examples included: - Young urban health-conscious Latina (18-25, no health conditions) - Middle-aged suburban Latino managing hypertension (42-50) - Young urban non-Latino with food allergies (26-33, gluten/dairy/nuts) - Middle-aged rural non-Latino with obesity (34-41) - Middle-aged rural Latina with multiple conditions (42-50, hypertension + obesity)</p>
<p>The goal was to represent our potential target segments and see how different audiences responded to each product.</p>
</section>
</section>
<section id="the-calibrated-survey" class="level2">
<h2 class="anchored" data-anchor-id="the-calibrated-survey">The Calibrated Survey</h2>
<section id="starting-with-a-benchmark" class="level3">
<h3 class="anchored" data-anchor-id="starting-with-a-benchmark">Starting with a Benchmark</h3>
<p>We calibrated responses by having participants rate Lay’s Classic Potato Chips first as a reference point. This gave us a common baseline to compare against: - 1 = Unacceptable, wouldn’t eat even if free - 3 = Acceptable/Average, meets basic expectations - 5 = Excellent, exceeds expectations</p>
</section>
<section id="comprehensive-rating-categories" class="level3">
<h3 class="anchored" data-anchor-id="comprehensive-rating-categories">Comprehensive Rating Categories</h3>
<p>The survey covered:</p>
<p><strong>A. Overall Satisfaction</strong> (quality, purchase intent, recommendation likelihood)</p>
<p><strong>B. Taste &amp; Flavor</strong> (overall taste, flavor intensity, saltiness, naturalness, aftertaste)</p>
<p><strong>C. Texture &amp; Physical Quality</strong> (crunchiness, thickness, consistency, oiliness, freshness)</p>
<p><strong>D. Visual Appeal</strong> (appearance, color, uniformity, packaging appeal, information clarity)</p>
<p><strong>E. Value &amp; Competitive Positioning</strong> (value for money, price sensitivity, preference vs potato chips and competitors)</p>
<p><strong>F. Product Attributes</strong> (uniqueness, healthiness, suitability for guests, meeting expectations)</p>
<p><strong>G. Usage Context</strong> (purchase frequency, consumption occasions)</p>
<p>Each persona rated 33 quantitative questions plus provided qualitative feedback on likes, improvements, and how they’d describe the product.</p>
</section>
</section>
<section id="what-we-learned-from-the-exercise" class="level2">
<h2 class="anchored" data-anchor-id="what-we-learned-from-the-exercise">What We Learned from the Exercise</h2>
<section id="ai-can-generate-plausible-responses" class="level3">
<h3 class="anchored" data-anchor-id="ai-can-generate-plausible-responses">AI Can Generate Plausible Responses</h3>
<p>ChatGPT was surprisingly good at maintaining consistent personas. The middle-aged rural Latina with hypertension and obesity consistently flagged sodium concerns and price sensitivity across multiple questions. The young urban health-conscious Latina responded positively to premium positioning and cultural connection.</p>
<p>The personas felt internally coherent - their ratings for saltiness, healthiness, and value aligned with their demographic profiles and stated health concerns.</p>
</section>
<section id="but-its-still-simulated-data" class="level3">
<h3 class="anchored" data-anchor-id="but-its-still-simulated-data">But It’s Still Simulated Data</h3>
<p>The fundamental limitation: these aren’t real taste preferences. The AI is generating statistically plausible responses based on stereotypical associations between demographics and preferences.</p>
<p>For example, it “knows” that someone with hypertension should care about sodium, so it rates accordingly. But it can’t actually tell us if our specific salt level tastes good or if the Peruvian sal de Maras provides a noticeably different experience.</p>
</section>
<section id="useful-for-initial-direction" class="level3">
<h3 class="anchored" data-anchor-id="useful-for-initial-direction">Useful for Initial Direction</h3>
<p>Where this exercise helped: - Identifying which demographic segments might prefer premium vs everyday positioning - Spotting potential concerns (price sensitivity in rural markets, sodium levels for health-conscious segments) - Practicing survey design before using it with real participants - Understanding how different personas might prioritize different product attributes</p>
</section>
</section>
<section id="serious-limitations" class="level2">
<h2 class="anchored" data-anchor-id="serious-limitations">Serious Limitations</h2>
<section id="no-actual-sensory-experience" class="level3">
<h3 class="anchored" data-anchor-id="no-actual-sensory-experience">No Actual Sensory Experience</h3>
<p>The biggest problem: ChatGPT hasn’t tasted anything. It can’t tell us if our plantain chips are actually crunchy, if the salt level is genuinely balanced, or if the flavor profile works.</p>
<p>All taste-related responses are based on generic associations (“premium plantain chips should be crunchier,” “simple seasoning means less salty”). These might not match reality.</p>
</section>
<section id="reinforces-stereotypes" class="level3">
<h3 class="anchored" data-anchor-id="reinforces-stereotypes">Reinforces Stereotypes</h3>
<p>The AI generates responses based on demographic patterns it learned from training data. This means it might reproduce stereotypical assumptions rather than capturing actual individual preferences.</p>
<p>A real 42-year-old Latino with hypertension might not care about sodium as much as the persona suggests, or might have completely different taste preferences than “typical” for that demographic.</p>
</section>
<section id="cant-capture-real-market-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="cant-capture-real-market-dynamics">Can’t Capture Real Market Dynamics</h3>
<p>Things the simulation can’t tell us: - Whether people would actually notice our product on shelves - If the packaging design triggers emotional responses - Whether word-of-mouth would happen organically - If there are unexpected use cases we haven’t considered - How brand perception builds over time</p>
</section>
<section id="the-validation-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-validation-problem">The Validation Problem</h3>
<p>We built in validation checks (questions 31-33) to catch inconsistent rating patterns. But when the AI is generating all responses, it’s just validating its own internal consistency, not actual human behavior.</p>
<p>According to <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12234702/">research on AI-generated synthetic data</a>, using LLM outputs as substitutes for human research data can introduce systematic biases that aren’t immediately obvious.</p>
</section>
</section>
<section id="how-were-actually-using-this" class="level2">
<h2 class="anchored" data-anchor-id="how-were-actually-using-this">How We’re Actually Using This</h2>
<section id="initial-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="initial-hypothesis-testing">Initial Hypothesis Testing</h3>
<p>The AI focus group helped us form hypotheses about product positioning: - Cuzco Crunch might appeal more to urban health-conscious consumers willing to pay premium - Plantain Lite could work better for price-sensitive families and convenience-focused shoppers - Both products might face sodium concerns from health-conscious segments</p>
<p>But these are just hypotheses that need real validation.</p>
</section>
<section id="survey-design-practice" class="level3">
<h3 class="anchored" data-anchor-id="survey-design-practice">Survey Design Practice</h3>
<p>Building the comprehensive survey instrument was valuable. We learned: - Which questions provide useful differentiation - How to structure rating scales with proper calibration - What validation checks to include - Which demographic factors might matter most</p>
<p>The survey itself is now ready to use with actual participants.</p>
</section>
<section id="next-steps-with-real-people" class="level3">
<h3 class="anchored" data-anchor-id="next-steps-with-real-people">Next Steps with Real People</h3>
<p>We’re not making product decisions based on AI responses. The plan is: 1. Use the survey with real taste testers 2. Compare actual results to AI predictions 3. Identify where AI assumptions were wrong 4. Make product decisions based on real preferences</p>
<p>The AI exercise was a dress rehearsal, not the actual performance.</p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Running a virtual focus group with AI personas was an interesting experiment in using LLMs for product development. It’s useful for: - Rapid hypothesis generation - Testing survey instruments - Exploring how different demographic segments might respond - Practicing market research methodologies</p>
<p>But it’s dangerous if you: - Trust the responses as actual market data - Skip real human testing because “we already did AI testing” - Make product decisions based on simulated preferences - Assume the AI understands nuanced taste experiences</p>
<p>For Cuzco Crunch, this exercise helped us structure our research approach and form initial hypotheses. But we’re clear that actual product validation requires real people tasting real chips. The AI can simulate responses, but it can’t simulate whether our plantain chips actually taste good.</p>


</section>

 ]]></description>
  <category>branding</category>
  <category>LLM</category>
  <category>entrepreneurship</category>
  <category>creative</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/011_/011.html</guid>
  <pubDate>Fri, 03 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/011_/cuzco-crunch-package.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Using LLMs for Interview Prep</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/010_/010.html</link>
  <description><![CDATA[ 





<section id="building-an-mbb-interview-assistant" class="level2">
<h2 class="anchored" data-anchor-id="building-an-mbb-interview-assistant">Building an MBB Interview Assistant</h2>
<p>With consulting recruiting coming up, I built a custom project in Claude to help with case interview prep. The idea was to have a dedicated space where I could practice cases, track my progress, and get feedback—all in one place.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/010_/interview-preparation.jpg" class="img-fluid" alt="Interview Preparation"> <em>Generic stock photo of a professional interview setting</em></p>
</section>
<section id="how-the-assistant-works" class="level2">
<h2 class="anchored" data-anchor-id="how-the-assistant-works">How the Assistant Works</h2>
<section id="the-setup" class="level3">
<h3 class="anchored" data-anchor-id="the-setup">The Setup</h3>
<p>I created a Claude project called “MBB Interview Assistant” with custom instructions:</p>
<blockquote class="blockquote">
<p>“You will be hearing inputs from MBB interviews. Your role as my highly-paid MBB tutor is to come up with frameworks. Answer questions quickly and brainstorm potential questions, and then… develop a MECE, MBB approach (case structure).”</p>
</blockquote>
<p>The project has become a repository of my case practice—I can see all my past cases listed: UK leisure club market analysis, UK media company revenue challenges, Science magazine revenue decline, Residential cable company alarm services, Kids Place Daycare Capacity Strategy.</p>
</section>
<section id="using-the-voice-recording-feature" class="level3">
<h3 class="anchored" data-anchor-id="using-the-voice-recording-feature">Using the Voice Recording Feature</h3>
<p>The most useful feature has been Claude’s voice recording capability. I can speak through a case out loud, and it transcribes everything accurately and then provides feedback. This simulates the verbal nature of actual case interviews better than typing.</p>
<p>For example, when I was working through the UK leisure club case, I could talk through my framework structure verbally, and Claude would follow along and point out gaps in my logic or areas I hadn’t considered.</p>
</section>
</section>
<section id="what-actually-works" class="level2">
<h2 class="anchored" data-anchor-id="what-actually-works">What Actually Works</h2>
<section id="case-tracking" class="level3">
<h3 class="anchored" data-anchor-id="case-tracking">Case Tracking</h3>
<p>Having all my practice cases in one place is genuinely helpful. I can see which types of cases I’ve worked on and which I need more practice with. The project view shows each case with timestamps, so I can track my prep progress over time.</p>
</section>
<section id="framework-development" class="level3">
<h3 class="anchored" data-anchor-id="framework-development">Framework Development</h3>
<p>Claude is good at helping me structure MECE (Mutually Exclusive, Collectively Exhaustive) frameworks. When I’m stuck on how to break down a problem, it can suggest logical buckets to organize my thinking.</p>
<p>For the daycare capacity strategy case, it helped me think through supply-side factors (staffing, facilities, regulations) and demand-side factors (demographics, competition, pricing) in a structured way.</p>
</section>
<section id="accurate-transcription" class="level3">
<h3 class="anchored" data-anchor-id="accurate-transcription">Accurate Transcription</h3>
<p>The voice recording feature transcribes my verbal case practice accurately. I can review what I actually said rather than what I thought I said, which helps identify verbal tics or unclear explanations.</p>
</section>
<section id="quick-feedback" class="level3">
<h3 class="anchored" data-anchor-id="quick-feedback">Quick Feedback</h3>
<p>It provides immediate feedback on structural issues—missing elements in my framework, calculations I didn’t account for, or assumptions I should have stated explicitly.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/010_/claude-interview-project.jpg" class="img-fluid" alt="Claude Project Interface"> <em>My MBB Interview Assistant project showing case history and files</em></p>
</section>
</section>
<section id="major-limitations-ive-found" class="level2">
<h2 class="anchored" data-anchor-id="major-limitations-ive-found">Major Limitations I’ve Found</h2>
<section id="hallucinations-and-made-up-information" class="level3">
<h3 class="anchored" data-anchor-id="hallucinations-and-made-up-information">Hallucinations and Made-Up Information</h3>
<p>This is the biggest problem. Claude sometimes makes up data points or industry facts that sound plausible but aren’t real. In the media company revenue case, it cited specific market statistics that I later couldn’t verify anywhere.</p>
<p>For interview prep, this is dangerous because you might memorize false information and confidently state it in a real interview. I’ve learned to verify anything that sounds like a specific fact or statistic.</p>
</section>
<section id="going-off-topic" class="level3">
<h3 class="anchored" data-anchor-id="going-off-topic">Going Off Topic</h3>
<p>Sometimes Claude diverges from the specific case question to discuss tangentially related concepts. When working on the cable company alarm services case, it started explaining general IoT trends instead of focusing on the specific competitive positioning question I was asking about.</p>
</section>
<section id="scope-creep" class="level3">
<h3 class="anchored" data-anchor-id="scope-creep">Scope Creep</h3>
<p>The AI occasionally suggests frameworks or analyses that are way too broad for a 20-minute case interview. It might recommend conducting customer surveys or building complex financial models—things that wouldn’t be feasible in an actual interview setting.</p>
</section>
<section id="weird-or-broken-links" class="level3">
<h3 class="anchored" data-anchor-id="weird-or-broken-links">Weird or Broken Links</h3>
<p>When Claude tries to reference sources or suggest additional reading, the links are often fabricated or don’t lead anywhere useful. I’ve clicked on several suggested resources only to find they don’t exist.</p>
</section>
<section id="cant-simulate-real-pressure" class="level3">
<h3 class="anchored" data-anchor-id="cant-simulate-real-pressure">Can’t Simulate Real Pressure</h3>
<p>The fundamental limitation remains: practicing with an AI in my room doesn’t replicate the pressure of a real interviewer. There’s no one judging my confidence, no awkward silences to manage, no reading of facial expressions.</p>
<p><a href="https://www.mckinsey.com/careers/interviewing">Research on case interview preparation</a> emphasizes that the interpersonal dynamics and time pressure are critical elements that can only be practiced with real people.</p>
</section>
</section>
<section id="my-actual-approach" class="level2">
<h2 class="anchored" data-anchor-id="my-actual-approach">My Actual Approach</h2>
<section id="early-stage-framework-practice" class="level3">
<h3 class="anchored" data-anchor-id="early-stage-framework-practice">Early-Stage Framework Practice</h3>
<p>I use the Claude project at the beginning of my prep for each case type. It helps me understand what a good framework looks like and gives me immediate feedback on structural issues.</p>
</section>
<section id="verbal-practice-tool" class="level3">
<h3 class="anchored" data-anchor-id="verbal-practice-tool">Verbal Practice Tool</h3>
<p>The voice recording feature is useful for getting comfortable speaking through cases out loud. I can practice articulating my thinking without the pressure of another person listening.</p>
</section>
<section id="progress-tracking" class="level3">
<h3 class="anchored" data-anchor-id="progress-tracking">Progress Tracking</h3>
<p>The project acts as a log of all the cases I’ve practiced. I can see patterns in which types of cases I struggle with and where I need more work.</p>
</section>
<section id="always-verify-facts" class="level3">
<h3 class="anchored" data-anchor-id="always-verify-facts">Always Verify Facts</h3>
<p>I never trust specific data points or statistics from Claude without verification. If it mentions a market size or industry trend, I look it up independently.</p>
</section>
<section id="real-humans-are-essential" class="level3">
<h3 class="anchored" data-anchor-id="real-humans-are-essential">Real Humans Are Essential</h3>
<p>After using Claude for initial structure practice, I do the same cases with actual people—friends doing consulting recruiting, career services, or case partners. The AI gets me to baseline competence faster, but real practice is what actually prepares you for the interview dynamic.</p>
</section>
</section>
<section id="final-take" class="level2">
<h2 class="anchored" data-anchor-id="final-take">Final Take</h2>
<p>The MBB Interview Assistant project is a useful supplementary tool but comes with significant limitations. It’s good for: - Organizing and tracking case practice - Getting quick structural feedback - Practicing verbal articulation with voice recordings - Understanding framework basics</p>
<p>But it’s actively harmful if you: - Trust its specific facts without verification - Rely on it as your primary practice method - Follow its suggestions when they’re too broad or impractical - Think it can replace practicing with real people</p>
<p>The hallucination issue is serious enough that I treat everything Claude says as a suggestion to verify rather than information to memorize. For actual interview prep, the AI is a starting point, not a replacement for traditional practice methods.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>LLM</category>
  <category>entrepreneurship</category>
  <category>claude</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/010_/010.html</guid>
  <pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/010_/interview-preparation.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Experimenting with Vibe Creation Using LLMs</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/009_/009.html</link>
  <description><![CDATA[ 





<section id="playing-with-atmospheric-prompting" class="level2">
<h2 class="anchored" data-anchor-id="playing-with-atmospheric-prompting">Playing with Atmospheric Prompting</h2>
<p>I’ve been experimenting with what I’m calling “vibe creation” in Claude—essentially asking the LLM to generate or interpret atmospheric descriptions for different contexts. The goal was to see how well these models understand and reproduce subjective, mood-based content rather than factual information.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/009_/vibe-prompting.jpg" class="img-fluid" alt="Vibe Prompting Interface"> <em>Testing different prompts to generate atmospheric descriptions</em></p>
</section>
<section id="the-prompts-i-tested" class="level2">
<h2 class="anchored" data-anchor-id="the-prompts-i-tested">The Prompts I Tested</h2>
<section id="starting-simple" class="level3">
<h3 class="anchored" data-anchor-id="starting-simple">Starting Simple</h3>
<p>My first prompt was straightforward:</p>
<blockquote class="blockquote">
<p>“Describe the vibe of a rainy coffee shop at 3pm on a Tuesday”</p>
</blockquote>
<p>Claude generated a description that hit the expected notes—muted conversations, steam from coffee cups, the rhythmic sound of rain. It was accurate but generic, the kind of description you’d find in any piece of atmospheric writing.</p>
</section>
<section id="adding-specificity" class="level3">
<h3 class="anchored" data-anchor-id="adding-specificity">Adding Specificity</h3>
<p>I tried making the prompt more specific:</p>
<blockquote class="blockquote">
<p>“Describe the vibe of a college library during finals week at 2am. Include sounds, lighting, and the feeling of collective stress”</p>
</blockquote>
<p>This produced better results. The model captured details like the fluorescent lighting, the sound of highlighters on paper, and the “quiet panic” of students. It understood the assignment but still felt somewhat detached—like someone describing a scene they’d read about rather than experienced.</p>
</section>
<section id="testing-negative-space" class="level3">
<h3 class="anchored" data-anchor-id="testing-negative-space">Testing Negative Space</h3>
<p>Here’s where it got interesting. I asked:</p>
<blockquote class="blockquote">
<p>“Describe the vibe of an empty office building at night. Focus on what’s NOT there rather than what is”</p>
</blockquote>
<p>Claude struggled more with this. It could describe absence—no people, no noise—but couldn’t quite capture the uncanny feeling of a space designed for activity sitting dormant. The descriptions remained surface-level. The output focused on the lack of meetings, chatter, talk, noise in the office. But it did not capture the liminal-space-like, vast, expansive (almost scary) vibe of an empty office in the way the show Severance, for instance, can.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/009_/vibe-comparison.jpg" class="img-fluid" alt="Vibe Comparison Results"> <em>Comparing outputs from different prompting approaches</em></p>
</section>
</section>
<section id="what-worked-and-what-didnt" class="level2">
<h2 class="anchored" data-anchor-id="what-worked-and-what-didnt">What Worked and What Didn’t</h2>
<section id="strengths" class="level3">
<h3 class="anchored" data-anchor-id="strengths">Strengths</h3>
<p>The LLM is good at: - Assembling sensory details that conventionally fit a scene - Understanding cultural contexts (“finals week” immediately triggered appropriate stress markers) - Maintaining consistency within a single atmospheric description - Responding to structural prompts (“focus on sounds” vs “focus on lighting”)</p>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<p>Where it falls short: - Generating truly novel atmospheric combinations - Capturing subtle emotional undertones that aren’t explicitly named - Moving beyond stereotypical associations (coffee shop = cozy, library = studious) - Understanding the relationship between physical space and psychological state in non-obvious ways</p>
<p>The model seems to work from a database of common associations rather than synthesizing new atmospheric understanding.</p>
</section>
</section>
<section id="why-this-matters-from-a-skeptical-angle" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-from-a-skeptical-angle">Why This Matters (From a Skeptical Angle)</h2>
<section id="the-homogenization-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-homogenization-problem">The Homogenization Problem</h3>
<p>If everyone starts using LLMs to generate atmospheric descriptions for creative projects, writing, or marketing, we risk creating a feedback loop of averaged-out vibes. The model can only reproduce what it’s seen in training data, which means we get the most statistically likely description of any given mood or setting.</p>
<p>After all, LLMs tend to regress toward mean responses when generating creative content, potentially flattening the diversity of human expression.</p>
</section>
<section id="lost-nuance" class="level3">
<h3 class="anchored" data-anchor-id="lost-nuance">Lost Nuance</h3>
<p>Real atmospheric writing comes from personal observation and specific experience. When I asked Claude to describe my college library during finals, it gave me a generic college library experience. It couldn’t know about the specific smell of old heating systems mixed with energy drinks, or the way light reflects off that one weird pillar in the corner.</p>
</section>
<section id="useful-but-limited-tool" class="level3">
<h3 class="anchored" data-anchor-id="useful-but-limited-tool">Useful But Limited Tool</h3>
<p>This isn’t to say vibe creation with LLMs is useless. It’s good for: - Quick brainstorming when you’re stuck - Getting a baseline description to then personalize - Understanding how certain settings are conventionally described</p>
<p>But treating it as a replacement for actual observation and personal experience would result in flatter, less distinctive creative work.</p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Playing with vibe creation revealed both the capabilities and constraints of current LLMs. They’re sophisticated pattern-matching systems that can assemble convincing atmospheric descriptions from training data, but they lack the experiential knowledge that makes truly evocative writing memorable.</p>
<p>The exercise reinforced my skepticism about over-relying on these tools for creative work. They’re useful for scaffolding and inspiration, but the most interesting atmospheric details still need to come from human observation and experience.</p>
<p>For anyone trying similar experiments: push the model toward specificity and unconventional combinations. The more generic your prompt, the more generic your output.</p>


</section>

 ]]></description>
  <category>AI</category>
  <category>LLM</category>
  <category>creative</category>
  <category>claude</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/009_/009.html</guid>
  <pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/009_/vibe-prompting.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Photo Organization: Finding Pictures I Forgot I Had</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /008.html</link>
  <description><![CDATA[ 





<section id="searching-through-10000-photos" class="level2">
<h2 class="anchored" data-anchor-id="searching-through-10000-photos">Searching Through 10,000 Photos</h2>
<p>I realized I had over 10,000 photos in Google Photos and no way to find specific ones. Today I tried using the AI search features to locate pictures from last year’s vacation, and it actually worked better than expected.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-search.jpg" class="img-fluid" alt="AI Photo Search"> <em>Google Photos AI recognizing objects, people, and locations</em></p>
</section>
<section id="what-the-ai-can-find" class="level2">
<h2 class="anchored" data-anchor-id="what-the-ai-can-find">What the AI Can Find</h2>
<section id="object-recognition" class="level3">
<h3 class="anchored" data-anchor-id="object-recognition">Object Recognition</h3>
<p>I searched for “pizza” and it found every photo with pizza in it, even ones where pizza was just sitting on a table in the background. Same thing worked for “dog,” “beach,” and “birthday cake.” The AI recognizes way more objects than I expected.</p>
</section>
<section id="face-grouping" class="level3">
<h3 class="anchored" data-anchor-id="face-grouping">Face Grouping</h3>
<p>Google Photos automatically groups photos by faces, so I can find all pictures of specific people without having to manually tag them. It even recognizes people as they age or in different lighting.</p>
</section>
<section id="location-and-time" class="level3">
<h3 class="anchored" data-anchor-id="location-and-time">Location and Time</h3>
<p>If you have location data turned on, you can search by place names. I found all my photos from “San Francisco” or “coffee shop” pretty easily. Time-based searches work too - “photos from summer 2024” pulled up the right time period.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-albums.jpg" class="img-fluid" alt="Auto-Generated Albums"> <em>Automatically created albums based on events and trips</em></p>
</section>
</section>
<section id="automatic-albums" class="level2">
<h2 class="anchored" data-anchor-id="automatic-albums">Automatic Albums</h2>
<section id="trip-detection" class="level3">
<h3 class="anchored" data-anchor-id="trip-detection">Trip Detection</h3>
<p>The AI creates albums for trips automatically based on location and date patterns. It figured out my weekend in Portland and grouped all those photos together without me doing anything.</p>
</section>
<section id="event-recognition" class="level3">
<h3 class="anchored" data-anchor-id="event-recognition">Event Recognition</h3>
<p>It also makes albums for things like “Birthday party” or “Graduation” based on the types of photos and timing. Sometimes it gets it wrong - labeled a regular dinner as a “celebration” - but it’s right more often than not.</p>
</section>
<section id="people-albums" class="level3">
<h3 class="anchored" data-anchor-id="people-albums">People Albums</h3>
<p>Creates collections of photos featuring specific people, which is useful for family pictures or when you want to share photos of someone with them.</p>
</section>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<section id="privacy-concerns" class="level3">
<h3 class="anchored" data-anchor-id="privacy-concerns">Privacy Concerns</h3>
<p>All this convenience requires uploading your photos to Google’s servers where they analyze everything. If that bothers you, you can’t really use these features.</p>
</section>
<section id="sometimes-too-smart" class="level3">
<h3 class="anchored" data-anchor-id="sometimes-too-smart">Sometimes Too Smart</h3>
<p>The AI occasionally creates albums for things that weren’t actually events, or groups random photos together based on superficial similarities.</p>
</section>
<section id="search-isnt-perfect" class="level3">
<h3 class="anchored" data-anchor-id="search-isnt-perfect">Search Isn’t Perfect</h3>
<p>Complex searches don’t always work. “Photos of John at the beach” might miss some or include wrong results. Simple, single-concept searches work much better.</p>
<p>It’s genuinely useful for finding old photos you’d never locate otherwise. The search functionality makes having thousands of photos actually manageable instead of just overwhelming.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>organization</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /008.html</guid>
  <pubDate>Sat, 27 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/008_ /ai-photo-search.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Email Management That Actually Works</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/007.html</link>
  <description><![CDATA[ 





<section id="letting-ai-handle-my-inbox" class="level2">
<h2 class="anchored" data-anchor-id="letting-ai-handle-my-inbox">Letting AI Handle My Inbox</h2>
<p>I set up SaneBox to manage my email and it’s been running for about a week now. Instead of manually sorting through everything, the AI decides what’s important and what can wait.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-inbox-sorting.jpg" class="img-fluid" alt="Smart Inbox Sorting"> <em>AI automatically categorizing emails by priority level</em></p>
</section>
<section id="how-it-sorts-things-out" class="level2">
<h2 class="anchored" data-anchor-id="how-it-sorts-things-out">How It Sorts Things Out</h2>
<section id="priority-filtering" class="level3">
<h3 class="anchored" data-anchor-id="priority-filtering">Priority Filtering</h3>
<p>SaneBox learns from which emails I actually open and respond to. Work emails from my team get flagged as important, while newsletters and promotional stuff gets moved to a separate folder. It’s not perfect but catches most of the obvious stuff.</p>
</section>
<section id="smart-scheduling" class="level3">
<h3 class="anchored" data-anchor-id="smart-scheduling">Smart Scheduling</h3>
<p>Gmail’s AI also suggests response times and can schedule emails to send later. I’ve been using it to send emails during business hours even when I’m working late, so I don’t look like I’m always online.</p>
</section>
<section id="quick-replies" class="level3">
<h3 class="anchored" data-anchor-id="quick-replies">Quick Replies</h3>
<p>The suggested responses are actually useful for simple emails. When someone sends a meeting request, it’ll suggest “Looks good” or “Let me check my calendar” which saves typing the same responses over and over.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-email-responses.jpg" class="img-fluid" alt="Email Response Suggestions"> <em>AI-generated reply suggestions for common email types</em></p>
</section>
</section>
<section id="what-ive-noticed" class="level2">
<h2 class="anchored" data-anchor-id="what-ive-noticed">What I’ve Noticed</h2>
<section id="less-time-sorting" class="level3">
<h3 class="anchored" data-anchor-id="less-time-sorting">Less Time Sorting</h3>
<p>The main benefit is spending less time deciding what to read first. Important emails show up in the main inbox, everything else gets organized automatically.</p>
</section>
<section id="fewer-missed-messages" class="level3">
<h3 class="anchored" data-anchor-id="fewer-missed-messages">Fewer Missed Messages</h3>
<p>Before, urgent emails would get buried under promotional stuff. Now they’re separated, so I’m less likely to miss something important.</p>
</section>
<section id="still-need-to-check" class="level3">
<h3 class="anchored" data-anchor-id="still-need-to-check">Still Need to Check</h3>
<p>The AI sometimes gets it wrong - puts important emails in the low-priority folder or flags spam as urgent. You still need to glance through everything, but it’s more organized.</p>
<p>It’s a decent time-saver for people who get a lot of email. Not life-changing, but removes some of the daily friction of inbox management. The filtering works better than I expected, though you need to train it for a few days before it gets your priorities right.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>productivity</category>
  <category>organization</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/007.html</guid>
  <pubDate>Thu, 25 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/007_/smart-inbox-sorting.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Building a Brand with AI: Cuzco Crunch</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/006.html</link>
  <description><![CDATA[ 





<section id="creating-a-brand-with-ai" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-brand-with-ai">Creating a Brand with AI</h2>
<p>Eury and I decided to try building a snack brand called Cuzco Crunch, mostly to see how much of the process we could handle using AI tools. We are just experimenting with what’s possible when you use GPT for everything from naming to packaging concepts.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch.jpg" class="img-fluid" alt="Cuzco Crunch Logo"> <em>Initial logo concepts generated through AI prompting</em></p>
</section>
<section id="what-were-using-ai-for" class="level2">
<h2 class="anchored" data-anchor-id="what-were-using-ai-for">What We’re Using AI For</h2>
<section id="brand-development" class="level3">
<h3 class="anchored" data-anchor-id="brand-development">Brand Development</h3>
<p>The name “Cuzco Crunch” came from asking GPT to suggest names that sounded distinctive but not too weird. We wanted something that hinted at South American flavors without being too on-the-nose. It generated about 30 options and this one felt right.</p>
</section>
<section id="packaging-design-direction" class="level3">
<h3 class="anchored" data-anchor-id="packaging-design-direction">Packaging Design Direction</h3>
<p>We’re using AI to create mood boards and design concepts. Instead of hiring a designer upfront, we’re generating different packaging styles to see what resonates. The AI helps us think through color schemes, typography, and overall brand personality.</p>
</section>
<section id="marketing-copy" class="level3">
<h3 class="anchored" data-anchor-id="marketing-copy">Marketing Copy</h3>
<p>Product descriptions, social media posts, and even this blog post started with AI-generated drafts that we then edited. It’s faster than staring at a blank page, and sometimes the AI suggests angles we wouldn’t have thought of.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch-packaging.jpg" class="img-fluid" alt="Packaging Concepts"> <em>Various packaging design concepts and color schemes</em></p>
</section>
</section>
<section id="whats-working-and-what-isnt" class="level2">
<h2 class="anchored" data-anchor-id="whats-working-and-what-isnt">What’s Working and What Isn’t</h2>
<section id="the-good-stuff" class="level3">
<h3 class="anchored" data-anchor-id="the-good-stuff">The Good Stuff</h3>
<p>Speed is the biggest advantage. We can iterate on ideas quickly without waiting for external feedback or spending money on design consultations. The AI is also good at generating variations - give it one concept and it’ll produce 10 different takes on it.</p>
</section>
<section id="the-limitations" class="level3">
<h3 class="anchored" data-anchor-id="the-limitations">The Limitations</h3>
<p>Everything needs human editing. The AI-generated copy often sounds too generic or tries too hard to be clever. Design concepts look decent but lack the subtle details that make professional packaging stand out on shelves.</p>
<p>Also, the AI doesn’t understand practical constraints. It’ll suggest elaborate packaging designs that would be expensive to produce or flavors that might not actually taste good together.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch-mockups.jpg" class="img-fluid" alt="Package Mockups"> <em>3D mockups and shelf visualization concepts</em></p>
</section>
</section>
<section id="the-reality-check" class="level2">
<h2 class="anchored" data-anchor-id="the-reality-check">The Reality Check</h2>
<section id="still-need-real-skills" class="level3">
<h3 class="anchored" data-anchor-id="still-need-real-skills">Still Need Real Skills</h3>
<p>AI handles the brainstorming and initial concepts, but you still need to understand branding, know your target market, and make business decisions. It’s a tool, not a replacement for actual knowledge about building a brand.</p>
</section>
<section id="cost-vs.-quality-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="cost-vs.-quality-trade-offs">Cost vs.&nbsp;Quality Trade-offs</h3>
<p>We’re probably saving money in the early stages, but there’s a point where you need professional designers and marketers. The question is finding that sweet spot where AI gets you far enough to make informed decisions about what’s worth investing in.</p>
</section>
<section id="learning-experience" class="level3">
<h3 class="anchored" data-anchor-id="learning-experience">Learning Experience</h3>
<p>The most valuable part has been understanding how much work goes into brand development. Using AI to handle the repetitive parts lets us focus on strategy and decision-making instead of getting stuck on execution details.</p>
<p>We’re treating this as an experiment rather than a serious business venture. If Cuzco Crunch turns into something real, great. If not, we’ve learned a lot about using AI for creative projects and brand development.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>branding</category>
  <category>entrepreneurship</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/006.html</guid>
  <pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/006_Cuzco_Crunch/cuzco-crunch.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Fitness Coaching at Home</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/005.html</link>
  <description><![CDATA[ 





<section id="working-out-with-ai-guidance" class="level2">
<h2 class="anchored" data-anchor-id="working-out-with-ai-guidance">Working Out with AI Guidance</h2>
<p>I tried the Freeletics app today instead of going to the gym. It uses your phone’s camera to watch your form and give feedback in real time, which felt like having a trainer watching you.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/ai-form-analysis.jpg" class="img-fluid" alt="AI Form Analysis"> <em>Smartphone analyzing exercise form with real-time feedback</em></p>
</section>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How It Works</h2>
<section id="real-time-form-correction" class="level3">
<h3 class="anchored" data-anchor-id="real-time-form-correction">Real-Time Form Correction</h3>
<p>You prop your phone up and the camera tracks your movements. When I was doing squats, it noticed I wasn’t going low enough and told me to “squat deeper” right as I was doing the exercise. It also caught that I was leaning too far forward.</p>
</section>
<section id="counts-reps-automatically" class="level3">
<h3 class="anchored" data-anchor-id="counts-reps-automatically">Counts Reps Automatically</h3>
<p>The app counts your repetitions so you don’t have to keep track. It only counts reps with proper form, so if your push-up doesn’t go low enough, it won’t count it.</p>
</section>
<section id="adjusts-based-on-performance" class="level3">
<h3 class="anchored" data-anchor-id="adjusts-based-on-performance">Adjusts Based on Performance</h3>
<p>When I started struggling with burpees halfway through, the app suggested switching to a modified version. It seemed to pick up on the fact that my form was getting sloppy and offered an easier variation.</p>
</section>
</section>
<section id="what-works-well" class="level2">
<h2 class="anchored" data-anchor-id="what-works-well">What Works Well</h2>
<section id="form-feedback" class="level3">
<h3 class="anchored" data-anchor-id="form-feedback">Form Feedback</h3>
<p>The corrections are actually helpful. It’s like having someone watch you who knows what proper form looks like. Caught several things I didn’t realize I was doing wrong.</p>
</section>
<section id="no-equipment-needed" class="level3">
<h3 class="anchored" data-anchor-id="no-equipment-needed">No Equipment Needed</h3>
<p>All bodyweight exercises, so you can do it anywhere. The app designs workouts based on what space and time you have available.</p>
</section>
<section id="adapts-to-your-level" class="level3">
<h3 class="anchored" data-anchor-id="adapts-to-your-level">Adapts to Your Level</h3>
<p>Starts with easier exercises and gradually increases difficulty based on how you perform. If you’re struggling, it scales back. If you’re crushing it, it adds more challenging moves.</p>
</section>
<section id="tracks-progress-over-time" class="level3">
<h3 class="anchored" data-anchor-id="tracks-progress-over-time">Tracks Progress Over Time</h3>
<p>Keeps track of how many reps you can do and how your form improves. You can see whether you’re getting stronger or if certain exercises are still difficult.</p>
</section>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<section id="camera-angle-matters" class="level3">
<h3 class="anchored" data-anchor-id="camera-angle-matters">Camera Angle Matters</h3>
<p>You need to position your phone correctly for it to see your whole body. Took a few tries to get the angle right.</p>
</section>
<section id="lighting-requirements" class="level3">
<h3 class="anchored" data-anchor-id="lighting-requirements">Lighting Requirements</h3>
<p>Works better in good lighting. Had trouble tracking movements when the room was too dim.</p>
</section>
<section id="limited-exercise-types" class="level3">
<h3 class="anchored" data-anchor-id="limited-exercise-types">Limited Exercise Types</h3>
<p>Focuses mainly on bodyweight movements. If you want to lift weights or use equipment, you’ll need a different approach.</p>
</section>
<section id="not-always-perfect" class="level3">
<h3 class="anchored" data-anchor-id="not-always-perfect">Not Always Perfect</h3>
<p>Sometimes misses form issues or gives feedback that doesn’t quite match what you’re doing. Still better than working out with no guidance, but not as precise as a human trainer.</p>
<p>It’s a solid option for home workouts when you want some structure and feedback. The form correction feature is genuinely useful, especially for exercises you’re not familiar with.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>fitness</category>
  <category>health</category>
  <category>daily-life</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/005.html</guid>
  <pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/005_AI_Fitness_Coaching_at_Home/ai-form-analysis.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI-Assisted Grocery Shopping and Meal Prep</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/004.html</link>
  <description><![CDATA[ 





<section id="smarter-grocery-shopping" class="level2">
<h2 class="anchored" data-anchor-id="smarter-grocery-shopping">Smarter Grocery Shopping</h2>
<p>I tried out the AnyList grocery app today and it’s different from just writing things down on paper. Instead of my usual scattered notes and forgotten items, the app organizes everything and suggests what I might need.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/smart-grocery-list.jpg" class="img-fluid" alt="Smart Grocery List"> <em>AI-generated grocery list organized by store layout</em></p>
</section>
<section id="what-it-actually-does" class="level2">
<h2 class="anchored" data-anchor-id="what-it-actually-does">What It Actually Does</h2>
<section id="tracks-what-you-need" class="level3">
<h3 class="anchored" data-anchor-id="tracks-what-you-need">Tracks What You Need</h3>
<p>The app learns from your purchase history and can predict when you’re running low on regular items. It suggested I needed milk and bread this week before I even thought about it. Not perfect, but surprisingly accurate for staples I buy regularly.</p>
</section>
<section id="organizes-by-store-layout" class="level3">
<h3 class="anchored" data-anchor-id="organizes-by-store-layout">Organizes by Store Layout</h3>
<p>Instead of jumping around the store, the list is organized by sections - produce, dairy, meat, etc. Some apps even know the specific layout of stores you frequent, so your list follows the actual aisles.</p>
</section>
<section id="meal-planning-integration" class="level3">
<h3 class="anchored" data-anchor-id="meal-planning-integration">Meal Planning Integration</h3>
<p>You can add meals for the week and it automatically generates ingredient lists. When I planned tacos for Tuesday, it added ground beef, tortillas, and lettuce to my list. It also checked what I already had at home based on recent purchases.</p>
</section>
</section>
<section id="practical-benefits" class="level2">
<h2 class="anchored" data-anchor-id="practical-benefits">Practical Benefits</h2>
<section id="less-time-in-store" class="level3">
<h3 class="anchored" data-anchor-id="less-time-in-store">Less Time in Store</h3>
<p>Following an organized list means less wandering around looking for items. I’ve noticed my shopping trips are about 15-20 minutes shorter.</p>
</section>
<section id="fewer-forgotten-items" class="level3">
<h3 class="anchored" data-anchor-id="fewer-forgotten-items">Fewer Forgotten Items</h3>
<p>The app remembers things I consistently buy but often forget to write down, like batteries or cleaning supplies.</p>
</section>
<section id="better-meal-planning" class="level3">
<h3 class="anchored" data-anchor-id="better-meal-planning">Better Meal Planning</h3>
<p>When you can see ingredient costs upfront, it’s easier to plan meals within budget. The app sometimes suggests cheaper alternatives for expensive items.</p>
</section>
<section id="automatic-coupons" class="level3">
<h3 class="anchored" data-anchor-id="automatic-coupons">Automatic Coupons</h3>
<p>Many apps integrate with store loyalty programs and apply relevant coupons automatically. I’ve saved money without having to hunt for deals.</p>
</section>
</section>
<section id="what-doesnt-work-perfectly" class="level2">
<h2 class="anchored" data-anchor-id="what-doesnt-work-perfectly">What Doesn’t Work Perfectly</h2>
<section id="learning-period" class="level3">
<h3 class="anchored" data-anchor-id="learning-period">Learning Period</h3>
<p>It takes a few weeks for the app to understand your shopping patterns. Early suggestions were often wrong.</p>
</section>
<section id="store-specific-features" class="level3">
<h3 class="anchored" data-anchor-id="store-specific-features">Store-Specific Features</h3>
<p>Advanced features like aisle mapping only work with certain grocery chains. Smaller or independent stores usually don’t have this integration.</p>
</section>
<section id="fresh-produce-timing" class="level3">
<h3 class="anchored" data-anchor-id="fresh-produce-timing">Fresh Produce Timing</h3>
<p>The AI isn’t great at predicting when you need fresh items since it depends on how quickly you use them.</p>
<p>Overall, it’s a useful tool that makes grocery shopping more organized. The meal planning aspect is particularly helpful for busy weeks when you need to think ahead. Not essential, but definitely convenient once you get used to it.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>daily-life</category>
  <category>productivity</category>
  <category>health</category>
  <category>daily-life</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/004.html</guid>
  <pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/004_AI-Assisted_Grocery_Shopping_and_Meal_Prep/smart-fridge-inventory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Research with Perplexity AI</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/003.html</link>
  <description><![CDATA[ 





<section id="using-ai-for-research" class="level2">
<h2 class="anchored" data-anchor-id="using-ai-for-research">Using AI for Research</h2>
<p>I’ve been trying out Perplexity AI for research tasks lately. It’s different from regular Google searches because it synthesizes information from multiple sources and gives you one coherent answer with citations.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-research.jpg" class="img-fluid" alt="Perplexity AI Interface"> <em>Perplexity AI interface showing search results with sources</em></p>
</section>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How It Works</h2>
<section id="getting-information-from-multiple-sources" class="level3">
<h3 class="anchored" data-anchor-id="getting-information-from-multiple-sources">Getting Information from Multiple Sources</h3>
<p>Instead of opening multiple tabs and reading through different articles, Perplexity pulls information from various sources and combines it into a single response. When I was researching market trends for a work project, I got a summary that included key points from several industry reports, all with proper citations.</p>
</section>
<section id="follow-up-questions" class="level3">
<h3 class="anchored" data-anchor-id="follow-up-questions">Follow-up Questions</h3>
<p>You can ask follow-up questions that build on your previous search. After asking about “sustainable packaging trends 2025,” I could continue with: - “What are the cost implications?” - “Which companies are leading this transition?” - “How does this compare to 2024 predictions?”</p>
<p>The AI remembers the context, so you don’t need to re-explain what you’re looking for.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-citations.jpg" class="img-fluid" alt="Perplexity Search Results"> <em>Live citations and source integration in action</em></p>
</section>
</section>
<section id="when-its-useful" class="level2">
<h2 class="anchored" data-anchor-id="when-its-useful">When It’s Useful</h2>
<section id="academic-work" class="level3">
<h3 class="anchored" data-anchor-id="academic-work">Academic Work</h3>
<p>Good for getting an overview of research topics and finding relevant studies. Helps identify what’s already been studied and where there might be gaps.</p>
</section>
<section id="business-research" class="level3">
<h3 class="anchored" data-anchor-id="business-research">Business Research</h3>
<p>Useful for market analysis and industry trends. You can ask specific questions and get answers that draw from recent reports and news sources.</p>
</section>
<section id="learning-new-topics" class="level3">
<h3 class="anchored" data-anchor-id="learning-new-topics">Learning New Topics</h3>
<p>When you’re unfamiliar with a subject, it can explain concepts and provide background without having to piece together information from multiple websites.</p>
</section>
<section id="fact-checking" class="level3">
<h3 class="anchored" data-anchor-id="fact-checking">Fact-Checking</h3>
<p>Since it shows sources for each piece of information, it’s easier to verify claims and see where data comes from.</p>
</section>
</section>
<section id="what-ive-found" class="level2">
<h2 class="anchored" data-anchor-id="what-ive-found">What I’ve Found</h2>
<section id="saves-time" class="level3">
<h3 class="anchored" data-anchor-id="saves-time">Saves Time</h3>
<p>The main benefit is speed. You get the key information faster since it’s already compiled from multiple sources. You still need to read the original sources for details, but the initial overview is much quicker.</p>
</section>
<section id="clear-sources" class="level3">
<h3 class="anchored" data-anchor-id="clear-sources">Clear Sources</h3>
<p>Every piece of information comes with citations, so you can see exactly where it came from and verify it if needed.</p>
</section>
<section id="handles-context-well" class="level3">
<h3 class="anchored" data-anchor-id="handles-context-well">Handles Context Well</h3>
<p>The conversation aspect works better than I expected. You can refine questions or explore related topics without starting over.</p>
</section>
<section id="shows-different-viewpoints" class="level3">
<h3 class="anchored" data-anchor-id="shows-different-viewpoints">Shows Different Viewpoints</h3>
<p>When sources disagree, it usually mentions the different perspectives rather than just presenting one view.</p>
<p>It’s a useful tool for the initial stages of research when you need to understand a topic quickly or gather information from multiple sources. Not a replacement for thorough research, but it does help speed up the information gathering process.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <category>research</category>
  <category>productivity</category>
  <category>technology</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/003.html</guid>
  <pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/003_Research_with_Perplexity_AI/perplexity-research.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>AI Do’s and Don’ts: Safe and Effective Usage</title>
  <dc:creator>Raymond Liu Ao</dc:creator>
  <link>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/002.html</link>
  <description><![CDATA[ 





<section id="essential-ai-guidelines" class="level2">
<h2 class="anchored" data-anchor-id="essential-ai-guidelines">Essential AI Guidelines</h2>
<p>AI tools are powerful but require careful usage. These guidelines help you maximize benefits while avoiding common pitfalls.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-safety-guidelines.jpg" class="img-fluid" alt="AI Safety Guidelines"> <em>Key principles for responsible AI usage</em></p>
</section>
<section id="what-to-do" class="level2">
<h2 class="anchored" data-anchor-id="what-to-do">What TO Do</h2>
<section id="verify-important-information" class="level3">
<h3 class="anchored" data-anchor-id="verify-important-information">✅ Verify Important Information</h3>
<p>Always fact-check AI outputs for: - Medical or health advice - Financial decisions - Legal matters - Technical specifications - Current events or recent data</p>
<p>Cross-reference with authoritative sources before acting on AI recommendations.</p>
</section>
<section id="be-specific-in-your-prompts" class="level3">
<h3 class="anchored" data-anchor-id="be-specific-in-your-prompts">✅ Be Specific in Your Prompts</h3>
<p><strong>Instead of:</strong> “Help me with my presentation” <strong>Use:</strong> “Create an outline for a 10-minute sales presentation to executives about Q3 revenue growth”</p>
<p>Specific prompts produce more useful results.</p>
</section>
<section id="use-ai-for-brainstorming-and-drafts" class="level3">
<h3 class="anchored" data-anchor-id="use-ai-for-brainstorming-and-drafts">✅ Use AI for Brainstorming and Drafts</h3>
<p>AI excels at: - Generating initial ideas - Creating first drafts - Organizing thoughts - Providing alternative perspectives</p>
<p>Use AI output as a starting point, not a final product.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-workflow-diagram.jpg" class="img-fluid" alt="AI Workflow Best Practices"> <em>Proper workflow: AI assists, human validates and refines</em></p>
</section>
<section id="maintain-human-judgment" class="level3">
<h3 class="anchored" data-anchor-id="maintain-human-judgment">✅ Maintain Human Judgment</h3>
<p>Keep human oversight for: - Final decision-making - Quality assessment - Ethical considerations - Context that AI might miss</p>
</section>
<section id="ask-follow-up-questions" class="level3">
<h3 class="anchored" data-anchor-id="ask-follow-up-questions">✅ Ask Follow-Up Questions</h3>
<p>Improve results by asking: - “Can you explain this differently?” - “What are potential problems with this approach?” - “Give me three alternatives” - “Make this more specific”</p>
</section>
</section>
<section id="what-not-to-do" class="level2">
<h2 class="anchored" data-anchor-id="what-not-to-do">What NOT to Do</h2>
<section id="dont-share-sensitive-information" class="level3">
<h3 class="anchored" data-anchor-id="dont-share-sensitive-information">❌ Don’t Share Sensitive Information</h3>
<p>Never input: - Passwords or login credentials - Social Security numbers - Credit card details - Proprietary business information - Personal addresses or phone numbers - Private family details</p>
<p>Assume all AI conversations could be stored or accessed by others.</p>
</section>
<section id="dont-rely-on-ai-for-critical-decisions" class="level3">
<h3 class="anchored" data-anchor-id="dont-rely-on-ai-for-critical-decisions">❌ Don’t Rely on AI for Critical Decisions</h3>
<p>Avoid using AI alone for: - Medical diagnoses or treatment - Legal advice or document preparation - Financial investment decisions - Safety-critical calculations - Emergency situations</p>
<p>Consult qualified professionals for these matters.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-security-risks.jpg" class="img-fluid" alt="AI Limitations Warning"> <em>Areas where AI should not be the primary decision maker</em></p>
</section>
<section id="dont-assume-ai-is-always-accurate" class="level3">
<h3 class="anchored" data-anchor-id="dont-assume-ai-is-always-accurate">❌ Don’t Assume AI is Always Accurate</h3>
<p>AI can produce: - Outdated information - Factual errors - Biased responses - Plausible-sounding but incorrect details</p>
<p>Especially problematic for recent events or specialized technical information.</p>
</section>
<section id="dont-use-ai-for-harmful-purposes" class="level3">
<h3 class="anchored" data-anchor-id="dont-use-ai-for-harmful-purposes">❌ Don’t Use AI for Harmful Purposes</h3>
<p>Avoid requesting: - Misleading or false content - Harassment or threatening messages - Plagiarism or academic dishonesty - Illegal activity guidance - Discriminatory content</p>
</section>
<section id="dont-ignore-context-limitations" class="level3">
<h3 class="anchored" data-anchor-id="dont-ignore-context-limitations">❌ Don’t Ignore Context Limitations</h3>
<p>AI doesn’t understand: - Your full personal situation - Unspoken cultural context - Real-time environmental factors - Emotional nuances</p>
<p>Provide necessary context explicitly in your prompts.</p>
</section>
</section>
<section id="implementation-strategy" class="level2">
<h2 class="anchored" data-anchor-id="implementation-strategy">Implementation Strategy</h2>
<section id="start-small" class="level3">
<h3 class="anchored" data-anchor-id="start-small">Start Small</h3>
<p>Begin with low-stakes tasks like email drafting or meal planning before using AI for important projects.</p>
</section>
<section id="build-verification-habits" class="level3">
<h3 class="anchored" data-anchor-id="build-verification-habits">Build Verification Habits</h3>
<p>Develop a routine of checking AI outputs against reliable sources.</p>
</section>
<section id="keep-learning" class="level3">
<h3 class="anchored" data-anchor-id="keep-learning">Keep Learning</h3>
<p>AI capabilities and limitations evolve. Stay informed about updates and new research.</p>
</section>
<section id="document-what-works" class="level3">
<h3 class="anchored" data-anchor-id="document-what-works">Document What Works</h3>
<p>Save effective prompts and note which applications produce reliable results for your needs.</p>
<p><img src="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-usage-tips.jpg" class="img-fluid" alt="AI Usage Tips"> <em>Use these tips and tricks!</em></p>
<p>Following these guidelines ensures you gain AI’s benefits while avoiding common mistakes that can lead to poor decisions or security issues.</p>


</section>
</section>

 ]]></description>
  <category>AI</category>
  <guid>https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/002.html</guid>
  <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://liuaoraymond.github.io/comm4190_F25_Using_LLMs_Blog/posts/002_AI_Dos_And_Donts/ai-safety-guidelines.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
